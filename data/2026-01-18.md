<div id=toc></div>

# Table of Contents

- [cs.CV](#cs.CV) [Total: 47]
- [cs.CL](#cs.CL) [Total: 56]


<div id='cs.CV'></div>

# cs.CV [[Back]](#toc)

### [1] [Breaking the Limits of Open-Weight CLIP: An Optimization Framework for Self-supervised Fine-tuning of CLIP](https://arxiv.org/abs/2601.09859)
*Anant Mehta,Xiyuan Wei,Xingyu Chen,Tianbao Yang*

Main category: cs.CV

Score: 4/5 | Tags: Vision, Multimodal, Self-supervised Learning, CLIP, Fine-tuning, Contrastive Learning, Transfer Learning

Recommendation: 该论文提出了创新的自监督微调框架TuneCLIP，解决了CLIP模型微调中的性能下降难题，方法设计有理论依据且实验验证充分，在多个基准上取得了显著提升，对于多模态表示学习领域具有实用价值。得分4分是因为虽然创新性明显，但方法相对简单，未来可能需要更多理论分析。

TL;DR: CLIP已成为多模态表示学习的基石，但提升其性能通常需要从头开始训练数十亿样本的昂贵过程。我们提出不同问题：仅使用现有自监督数据集能否改进开源CLIP模型在各种下游任务中的性能？与适应单一任务的监督微调不同，我们的设定旨在提升跨多种任务的通用性能。然而，如实验和先前研究所示，从开源CLIP模型开始直接应用标准训练协议往往导致性能下降。本文引入TuneCLIP，一种自监督微调框架，克服了性能下降问题。TuneCLIP包含两个关键组件：(1)受理论分析启发的恢复优化统计量的预热阶段以减少冷启动偏差；(2)优化新型对比损失的微调阶段以缓解对假阴性对的惩罚。大量实验表明TuneCLIP在不同模型架构和规模上一致提升性能，显著提升如SigLIP(ViT-B/16)等领先开源模型，在ImageNet及相关分布外基准上获得高达+2.5%提升，在竞争激烈的DataComp基准上获得+1.2%提升，为高效后预训练适应设立了新的强大基准。


<details>
  <summary>Details</summary>
Motivation: 现有的CLIP模型改进通常需要耗费巨大的计算资源进行从头训练，而本研究旨在探索是否能够利用现有自监督数据集，通过微调的方式提升开源CLIP模型在各种下游任务上的通用性能，避免昂贵的重新训练成本。

Method: TuneCLIP框架包含两个核心阶段：1）预热阶段，通过恢复模型的优化统计量（如学习率调度器状态、动量统计等）来减少冷启动偏差，该设计受理论分析启发；2）微调阶段，采用新型对比损失函数进行优化，该损失专门设计来减轻对假阴性样本对的惩罚，避免传统对比学习中存在的过度惩罚问题。

Result: 实验结果表明，TuneCLIP在不同模型架构和规模上均能一致提升性能：对于领先的开源模型SigLIP（ViT-B/16），在ImageNet及相关分布外基准上实现了高达2.5%的性能提升；在竞争激烈的DataComp基准上实现了1.2%的性能提升，为高效后预训练适应建立了新的强基准。

Conclusion: TuneCLIP为开源CLIP模型提供了一种高效的自监督微调框架，成功克服了直接微调导致的性能下降问题，通过预热阶段和新型对比损失的结合，实现了在各种下游任务上的一致性能提升，为资源受限情况下的CLIP模型优化提供了实用解决方案。

Abstract: CLIP has become a cornerstone of multimodal representation learning, yet improving its performance typically requires a prohibitively costly process of training from scratch on billions of samples. We ask a different question: Can we improve the performance of open-weight CLIP models across various downstream tasks using only existing self-supervised datasets? Unlike supervised fine-tuning, which adapts a pretrained model to a single downstream task, our setting seeks to improve general performance across various tasks. However, as both our experiments and prior studies reveal, simply applying standard training protocols starting from an open-weight CLIP model often fails, leading to performance degradation. In this paper, we introduce TuneCLIP, a self-supervised fine-tuning framework that overcomes the performance degradation. TuneCLIP has two key components: (1) a warm-up stage of recovering optimization statistics to reduce cold-start bias, inspired by theoretical analysis, and (2) a fine-tuning stage of optimizing a new contrastive loss to mitigate the penalization on false negative pairs. Our extensive experiments show that TuneCLIP consistently improves performance across model architectures and scales. Notably, it elevates leading open-weight models like SigLIP (ViT-B/16), achieving gains of up to +2.5% on ImageNet and related out-of-distribution benchmarks, and +1.2% on the highly competitive DataComp benchmark, setting a new strong baseline for efficient post-pretraining adaptation.

</details>


### [2] [VibrantSR: Sub-Meter Canopy Height Models from Sentinel-2 Using Generative Flow Matching](https://arxiv.org/abs/2601.09866)
*Kiarie Ndegwa,Andreas Gros,Tony Chang,David Diaz,Vincent A. Landau,Nathan E. Rutenbeck,Luke J. Zachmann,Guy Bayes,Scott Conway*

Main category: cs.CV

Score: 4/5 | Tags: 遥感, 超分辨率, 深度学习, 森林监测, 卫星影像, 碳核算, 生态监测

Recommendation: 这篇论文提出了一个创新的森林监测解决方案，将卫星影像的超分辨率技术与生态监测需求相结合，具有重要的实际应用价值。方法设计合理，实验结果令人信服，对大规模森林监测和碳核算研究具有显著贡献。唯一的不足是精度仍低于航空影像方法，但这在考虑到其大规模应用优势的情况下是可以接受的。

TL;DR: 我们提出VibrantSR（Vibrant超分辨率），这是一个生成式超分辨率框架，用于从10米分辨率的Sentinel-2影像中估算0.5米分辨率的树冠高度模型（CHMs）。与基于航空影像的方法受限于采集频率低且不规律不同，VibrantSR利用全球可用的Sentinel-2季节性合成影像，实现了从季节到年度频率的连续监测。在美国西部22个EPA三级生态区域使用空间不重叠验证集的评估表明，对于高度≥2米的树冠，VibrantSR的平均绝对误差为4.39米，优于Meta（4.83米）、LANDFIRE（5.96米）和ETH（7.05米）这些基于卫星的基准方法。虽然基于航空影像的VibrantVS（2.71米MAE）仍然具有精度优势，但VibrantSR实现了无需依赖成本高昂且时间频率低的航空采集的情况下，在洲际尺度上进行可操作的森林监测和碳核算。


<details>
  <summary>Details</summary>
Motivation: 目前基于航空影像的森林监测方法面临采集频率低、成本高昂且覆盖范围有限的问题，限制了在大尺度上进行连续森林监测和碳核算的能力。为了实现对森林树冠高度的连续、大范围监测，研究人员提出了利用全球覆盖、高时间分辨率的Sentinel-2卫星影像进行超分辨率处理的解决方案。

Method: VibrantSR采用生成式超分辨率框架，通过深度学习技术将10米分辨率的Sentinel-2季节性合成影像上采样到0.5米分辨率，生成高空间分辨率的树冠高度模型。该方法基于全球可用的Sentinel-2数据，利用季节性合成影像来增强特征表示能力，避免了传统方法对不规则航空影像的依赖。

Result: 在美国西部22个EPA三级生态区域的评估中，对于树冠高度≥2米的情况，VibrantSR实现了4.39米的平均绝对误差，显著优于Meta（4.83米）、LANDFIRE（5.96米）和ETH（7.05米）等基于卫星的基准方法。虽然基于航空影像的VibrantVS方法具有更高的精度（2.71米MAE），但VibrantSR在保持相对较高精度的同时，实现了大范围、高时间频率的监测能力。

Conclusion: VibrantSR为森林监测和碳核算提供了一种实用且可扩展的解决方案，能够在洲际尺度上实现季节到年度的连续监测，而无需依赖成本高昂且采集频率低的航空影像。尽管精度略低于航空影像方法，但其全局可用性和高时间分辨率使其成为大规模生态监测和气候变化研究的有力工具。

Abstract: We present VibrantSR (Vibrant Super-Resolution), a generative super-resolution framework for estimating 0.5 meter canopy height models (CHMs) from 10 meter Sentinel-2 imagery. Unlike approaches based on aerial imagery that are constrained by infrequent and irregular acquisition schedules, VibrantSR leverages globally available Sentinel-2 seasonal composites, enabling consistent monitoring at a seasonal-to-annual cadence. Evaluated across 22 EPA Level 3 eco-regions in the western United States using spatially disjoint validation splits, VibrantSR achieves a Mean Absolute Error of 4.39 meters for canopy heights >= 2 m, outperforming Meta (4.83 m), LANDFIRE (5.96 m), and ETH (7.05 m) satellite-based benchmarks. While aerial-based VibrantVS (2.71 m MAE) retains an accuracy advantage, VibrantSR enables operational forest monitoring and carbon accounting at continental scales without reliance on costly and temporally infrequent aerial acquisitions.

</details>


### [3] [OT-Drive: Out-of-Distribution Off-Road Traversable Area Segmentation via Optimal Transport](https://arxiv.org/abs/2601.09952)
*Zhihua Zhao,Guoqiang Li,Chen Min,Kangping Lu*

Main category: cs.CV

Score: 4/5 | Tags: 自动驾驶, 计算机视觉, 语义分割, 多模态融合, 最优传输, 分布外泛化, 场景理解

Recommendation: 推荐此论文是因为：1) 创新性地将最优传输理论应用于自动驾驶场景的多模态融合问题；2) 在OOD场景下取得了显著的性能提升；3) 提出的场景锚点生成器为应对复杂环境变化提供了有效机制；4) 实验验证充分，包含OOD场景和跨数据集迁移评估；5) 实际应用价值高，为自动驾驶系统在真实复杂环境中的部署提供了技术支撑。扣分原因：方法复杂性可能影响实时性，未充分讨论计算开销。

TL;DR: 在非结构化环境中可靠的可穿越区域分割对于自动驾驶中的规划和决策至关重要。然而，现有的数据驱动方法通常在分布外(OOD)场景中分割性能下降，从而影响下游驾驶任务。为解决此问题，我们提出了OT-Drive，一个基于最优传输的多模态融合框架。该方法将RGB和表面法线融合表述为分布传输问题。具体而言，我们设计了一个新颖的场景锚点生成器(SAG)，将场景信息分解为天气、时间（白天/夜晚）和道路类型的联合分布，从而构建能够泛化到未见场景的语义锚点。随后，我们设计了一个创新的基于最优传输的多模态融合模块(OT Fusion)，将RGB和表面法线特征传输到语义锚点定义的流形上，实现OOD场景下鲁棒的可穿越区域分割。实验结果表明，我们的方法在ORFD OOD场景中达到95.16%的mIoU，优于先前方法6.35%，在跨数据集迁移任务中达到89.79%的mIoU，超过基线13.99%。这些结果表明，所提出的模型只需有限的训练数据即可获得强大的OOD泛化能力，显著增强了其在实际部署中的实用性和效率。


<details>
  <summary>Details</summary>
Motivation: 自动驾驶在非结构化环境中的可靠可穿越区域分割面临分布外(OOD)场景性能下降的挑战。现有数据驱动方法在OOD场景下分割性能退化，影响下游驾驶任务的安全性和可靠性。为解决这一问题，需要开发具有强泛化能力的多模态融合方法，以应对真实世界自动驾驶应用中复杂的天气、光照和道路条件变化。

Method: 本文提出OT-Drive框架，包含两个核心组件：1) 场景锚点生成器(SAG)：通过分解场景信息（天气、时间、道路类型）构建联合分布，生成能够泛化到未见场景的语义锚点；2) 最优传输多模态融合模块(OT Fusion)：将RGB图像和表面法线特征传输到语义锚点定义的流形上，实现鲁棒的特征融合。该方法将多模态融合问题形式化为分布传输问题，利用最优传输理论确保特征在不同场景间的有效对齐。

Result: 在ORFD OOD场景评估中，OT-Drive达到95.16%的mIoU，相比先前最佳方法提升6.35%。在跨数据集迁移任务中，获得89.79%的mIoU，超过基线13.99%。实验结果表明该方法在有限训练数据下能够实现强大的OOD泛化能力，显著优于现有方法。

Conclusion: OT-Drive通过最优传输驱动的多模态融合框架，成功解决了自动驾驶场景中可穿越区域分割的OOD泛化问题。该方法不仅显著提升了分割性能，而且仅需有限训练数据即可实现强泛化，为实际自动驾驶系统部署提供了高效实用的解决方案。最优传输理论为多模态融合提供了理论支撑，场景锚点机制为应对复杂环境变化提供了有效手段。

Abstract: Reliable traversable area segmentation in unstructured environments is critical for planning and decision-making in autonomous driving. However, existing data-driven approaches often suffer from degraded segmentation performance in out-of-distribution (OOD) scenarios, consequently impairing downstream driving tasks. To address this issue, we propose OT-Drive, an Optimal Transport--driven multi-modal fusion framework. The proposed method formulates RGB and surface normal fusion as a distribution transport problem. Specifically, we design a novel Scene Anchor Generator (SAG) to decompose scene information into the joint distribution of weather, time-of-day, and road type, thereby constructing semantic anchors that can generalize to unseen scenarios. Subsequently, we design an innovative Optimal Transport-based multi-modal fusion module (OT Fusion) to transport RGB and surface normal features onto the manifold defined by the semantic anchors, enabling robust traversable area segmentation under OOD scenarios. Experimental results demonstrate that our method achieves 95.16% mIoU on ORFD OOD scenarios, outperforming prior methods by 6.35%, and 89.79% mIoU on cross-dataset transfer tasks, surpassing baselines by 13.99%.These results indicate that the proposed model can attain strong OOD generalization with only limited training data, substantially enhancing its practicality and efficiency for real-world deployment.

</details>


### [4] [The Spatial Blindspot of Vision-Language Models](https://arxiv.org/abs/2601.09954)
*Nahid Alam,Leema Krishna Murali,Siddhant Bharadwaj,Patrick Liu,Timothy Chung,Drishti Sharma,Akshata A,Kranthi Kiran,Wesley Tam,Bala Krishna S Vegesna*

Main category: cs.CV

Score: 4/5 | Tags: VLM, Vision-Language, Spatial Reasoning, Image Encoder, Positional Encoding, Robotics, Embodied AI

Recommendation: 这篇论文指出了VLM领域一个重要但常被忽视的问题——空间关系理解能力的缺失，并提出实用的架构改进方案。研究针对机器人和具身AI等实际应用需求，具有明确的实用价值。虽然提出的方法相对直观，但研究角度新颖且结果验证充分，对于推进VLM在空间推理方向的发展具有重要参考意义。

TL;DR: 视觉语言模型(VLMs)发展迅速，但其捕捉空间关系的能力仍是一个盲点。当前的VLMs通常使用对比语言-图像预训练(CLIP)风格的图像编码器构建。训练方法通常将图像展平为1D补丁序列，丢弃了空间推理所需的2D结构。我们认为这种空间意识缺失是VLM设计中的一个缺失维度，也是需要空间基础的应用（如机器人和具身AI）的瓶颈。为解决这一问题，我们研究了(i)使用替代目标训练的图像编码器以及(ii)2D位置编码。实验表明，这些架构选择能在多个基准测试中带来空间推理能力的改进。


<details>
  <summary>Details</summary>
Motivation: 视觉语言模型在空间关系理解方面存在明显不足，当前基于CLIP风格的图像编码器通常将图像展平为1D序列，丢失了关键的2D空间结构信息。这种空间意识的缺失限制了VLM在需要精确空间基础的应用中的性能，特别是机器人和具身AI等领域。论文旨在填补VLM设计中的这一缺失维度，突破空间推理的瓶颈。

Method: 论文采用两种主要方法：(1)研究使用替代训练目标的图像编码器，超越传统的CLIP风格预训练；(2)探索2D位置编码机制，以更好地保留图像的空间结构信息。这两种方法旨在增强模型对空间关系的理解和推理能力。

Result: 实验结果显示，通过采用替代训练目标的图像编码器和使用2D位置编码，能够在多个空间推理基准测试中获得显著改进。这些架构上的创新有效地提升了VLM的空间关系捕捉能力。

Conclusion: 空间关系理解是当前视觉语言模型设计中的一个关键缺失维度，采用替代训练目标的图像编码器和2D位置编码能够有效提升模型的空间推理能力，为机器人和具身AI等需要空间基础的应用提供更好的支持。

Abstract: Vision-language models (VLMs) have advanced rapidly, but their ability to capture spatial relationships remains a blindspot. Current VLMs are typically built with contrastive language-image pretraining (CLIP) style image encoders. The training recipe often flattens images into 1D patch sequences, discarding the 2D structure necessary for spatial reasoning. We argue that this lack of spatial awareness is a missing dimension in VLM design and a bottleneck for applications requiring spatial grounding, such as robotics and embodied AI. To address this, we investigate (i) image encoders trained with alternative objectives and (ii) 2D positional encodings. Our experiments show that these architectural choices can lead to improved spatial reasoning on several benchmarks.

</details>


### [5] [DR$^2$Seg: Decomposed Two-Stage Rollouts for Efficient Reasoning Segmentation in Multimodal Large Language Models](https://arxiv.org/abs/2601.09981)
*Yulin He,Wei Chen,Zhikang Jian,Tianhang Guo,Wenjuan Zhou,Minglong Li*

Main category: cs.CV

Score: 4/5 | Tags: Vision-Language, Reasoning, Segmentation, Multimodal, MLLM, Self-Rewarding, Object Localization

Recommendation: 该论文针对推理分割中的核心问题（过度思考）提出了创新性解决方案，方法设计简洁有效且无需额外标注数据，实验验证充分，在不同规模和类型的模型上都表现出了良好的泛化能力。虽然创新程度较高，但在实际应用潜力方面还需进一步验证，因此评分为4分。

TL;DR: 推理分割是一种新兴的视觉-语言任务，需要通过复杂的文本查询进行推理来精确分割物体。然而，现有方法通常存在过度思考的问题，生成了冗长的推理链，这会干扰多模态大语言模型（MLLMs）中的物体定位。为了解决这个问题，我们提出了DR²Seg，一个自奖励框架，它能在不需要额外思维监督的情况下提高推理效率和分割准确性。DR²Seg采用两阶段推出策略，将推理分割分解为多模态推理和指代分割。在第一阶段，模型生成一个自包含的描述，明确指定目标物体。在第二阶段，这个描述替换原始复杂查询以验证其自包含性。基于此设计，引入了两个自奖励机制来加强目标导向的推理并抑制冗余思维。在不同规模和分割模型的MLLMs上的大量实验表明，DR²Seg持续提高了推理效率和整体分割性能。


<details>
  <summary>Details</summary>
Motivation: 现有的推理分割方法存在过度思考问题，即生成冗长的推理链会干扰多模态大语言模型中物体的精确定位。这种冗余的思维过程不仅降低了推理效率，还影响了分割的准确性。因此，需要一种能够在不增加额外监督的情况下，同时提升推理效率和分割性能的框架。

Method: 提出DR²Seg自奖励框架，采用两阶段推出策略：1）第一阶段：多模态推理阶段，生成自包含的物体描述；2）第二阶段：指代分割阶段，用生成的描述替换原始复杂查询进行验证。框架引入两个自奖励机制：1）目标导向奖励，强化目标物体的识别；2）冗余抑制奖励，减少无关的思维过程。该方法无需额外标注数据，通过自监督方式优化推理过程。

Result: 实验结果表明，DR²Seg在不同规模的多模态大语言模型和分割模型上都取得了显著的性能提升：1）推理效率大幅提高，减少了冗余思维过程；2）分割准确性显著改善，在各种复杂查询场景下表现优异；3）框架具有良好的泛化能力，适用于不同架构的模型。

Conclusion: DR²Seg是一个有效的自奖励框架，通过两阶段推出策略和自奖励机制，成功解决了推理分割中的过度思考问题。该方法在不依赖额外监督的情况下，同时提升了推理效率和分割准确性，为多模态大语言模型中的目标定位提供了新的解决方案。

Abstract: Reasoning segmentation is an emerging vision-language task that requires reasoning over intricate text queries to precisely segment objects. However, existing methods typically suffer from overthinking, generating verbose reasoning chains that interfere with object localization in multimodal large language models (MLLMs). To address this issue, we propose DR$^2$Seg, a self-rewarding framework that improves both reasoning efficiency and segmentation accuracy without requiring extra thinking supervision. DR$^2$Seg employs a two-stage rollout strategy that decomposes reasoning segmentation into multimodal reasoning and referring segmentation. In the first stage, the model generates a self-contained description that explicitly specifies the target object. In the second stage, this description replaces the original complex query to verify its self-containment. Based on this design, two self-rewards are introduced to strengthen goal-oriented reasoning and suppress redundant thinking. Extensive experiments across MLLMs of varying scales and segmentation models demonstrate that DR$^2$Seg consistently improves reasoning efficiency and overall segmentation performance.

</details>


### [6] [VERHallu: Evaluating and Mitigating Event Relation Hallucination in Video Large Language Models](https://arxiv.org/abs/2601.10010)
*Zefan Zhang,Kehua Zhu,Shijie Jiang,Hongyuan Lu,Shengkai Sun,Tian Bai*

Main category: cs.CV

Score: 4/5 | Tags: VideoLLM, Multimodal, Hallucination, Benchmark, Event_Relations, Attention_Mechanism, Video_Understanding, Vision-Language

Recommendation: 本文具有较高推荐价值，原因如下：1) 提出了视频大语言模型研究中被忽视的事件关系幻觉问题，填补了研究空白；2) 构建了系统化的VERHallu基准，包含三类任务和反直觉场景，评估框架全面；3) 提出的关键帧传播策略简洁有效，不增加计算开销；4) 实验分析深入，揭示了模型在事件关系理解方面的具体缺陷。该研究对提升视频大语言模型的可靠性和实用性具有重要意义。

TL;DR: 视频大语言模型存在多种幻觉。现有研究主要关注视频中存在的事件、物体和场景相关的幻觉，而很大程度上忽视了事件关系幻觉。本文提出了一个名为VERHallu的视频事件关系幻觉评估新基准。该基准关注事件之间的因果、时序和子事件关系，包含三类任务：关系分类、问答和反事实问答，以全面评估事件关系幻觉。此外，该基准具有偏离典型预训练分布的反直觉视频场景，每个样本都附带人工标注的候选答案，涵盖了视觉语言和纯语言偏差。我们的分析表明，当前最先进的视频大语言模型在密集事件关系推理方面表现困难，由于帧级线索利用不足，常常依赖先验知识。尽管这些模型对关键事件展示了强大的定位能力，但它们往往忽略了周围的子事件，导致对事件关系的理解不完整且不准确。为此，我们提出了关键帧传播策略，在中间层重新分配帧级注意力以增强多事件理解。实验表明，该策略能有效缓解事件关系幻觉且不影响推理速度。


<details>
  <summary>Details</summary>
Motivation: 现有的视频大语言模型研究主要关注事件、物体和场景存在性相关的幻觉问题，而忽视了事件关系幻觉这一重要但未被充分探索的问题。事件关系（包括因果、时序和子事件关系）的理解对于视频内容理解至关重要，当前模型在处理复杂事件关系时存在明显缺陷，这限制了它们在现实应用中的可靠性。

Method: 本文提出了VERHallu基准来评估视频事件关系幻觉，包含三种任务：关系分类、问答和反事实问答。基准包含反直觉视频场景，并提供了人工标注的候选答案。为解决幻觉问题，作者提出了关键帧传播策略，该策略在模型的中间层重新分配帧级注意力，通过增强对关键帧及其传播的关注来改善多事件理解，而不需要修改模型架构或增加推理开销。

Result: 实验结果表明：1) 当前最先进的视频大语言模型在密集事件关系推理方面表现不佳，容易产生事件关系幻觉；2) 模型倾向于依赖先验知识而非视频帧级视觉线索；3) 虽然能较好定位关键事件，但常忽略周围子事件，导致事件关系理解不完整；4) 提出的关键帧传播策略能有效缓解事件关系幻觉问题，且不降低推理速度。

Conclusion: 视频大语言模型存在显著的事件关系幻觉问题，特别是在处理因果、时序和子事件关系时。VERHallu基准为评估这一问题提供了系统工具，揭示了模型在密集事件关系推理方面的局限性。关键帧传播策略通过优化注意力分配，在不影响效率的前提下有效改善了多事件理解能力，为解决视频大语言模型的关系幻觉问题提供了可行方案。

Abstract: Video Large Language Models (VideoLLMs) exhibit various types of hallucinations. Existing research has primarily focused on hallucinations involving the presence of events, objects, and scenes in videos, while largely neglecting event relation hallucination. In this paper, we introduce a novel benchmark for evaluating the Video Event Relation Hallucination, named VERHallu. This benchmark focuses on causal, temporal, and subevent relations between events, encompassing three types of tasks: relation classification, question answering, and counterfactual question answering, for a comprehensive evaluation of event relation hallucination. Additionally, it features counterintuitive video scenarios that deviate from typical pretraining distributions, with each sample accompanied by human-annotated candidates covering both vision-language and pure language biases. Our analysis reveals that current state-of-the-art VideoLLMs struggle with dense-event relation reasoning, often relying on prior knowledge due to insufficient use of frame-level cues. Although these models demonstrate strong grounding capabilities for key events, they often overlook the surrounding subevents, leading to an incomplete and inaccurate understanding of event relations. To tackle this, we propose a Key-Frame Propagating (KFP) strategy, which reallocates frame-level attention within intermediate layers to enhance multi-event understanding. Experiments show it effectively mitigates the event relation hallucination without affecting inference speed.

</details>


### [7] [Disentangled Concept Representation for Text-to-image Person Re-identification](https://arxiv.org/abs/2601.10053)
*Giyeol Kim,Chanho Eom*

Main category: cs.CV

Score: 4/5 | Tags: 计算机视觉, 跨模态检索, 行人重识别, 多模态学习, 细粒度识别, 解耦表示

Recommendation: 推荐这篇论文的原因：1）针对跨模态行人重识别的实际问题提出创新解决方案；2）提出的DiCo框架结构清晰，结合了槽位表示和概念块分解两种技术；3）在多个数据集上验证了方法的有效性；4）增强了模型的可解释性，这在当前黑盒模型普遍的情况下尤为重要；5）为细粒度跨模态对齐提供了新思路。

TL;DR: 基于文本的行人重识别（TIReID）旨在通过自由形式的文本描述从大型图库中检索出行人图像。TIReID面临的主要挑战在于视觉外观与文本表达之间存在显著的模态差异，以及需要建模细粒度对应关系以区分具有相似属性（如服装颜色、纹理或着装风格）的个体。为解决这些问题，我们提出了DiCo（解耦概念表示），这是一个新颖的框架，可实现分层和解耦的跨模态对齐。DiCo引入了一种共享的基于槽位的表示，其中每个槽位作为跨模态的部分级锚点，并进一步分解为多个概念块。这种设计能够解耦互补属性（如颜色、纹理、形状），同时在图像和文本之间保持一致的部分级对应关系。在CUHK-PEDES、ICFG-PEDES和RSTPReid数据集上的广泛实验表明，我们的框架在实现与最先进方法竞争性性能的同时，还通过显式的槽位和块级表示增强了可解释性，从而实现更细粒度的检索结果。


<details>
  <summary>Details</summary>
Motivation: 基于文本的行人重识别（TIReID）面临两个主要挑战：1）视觉与文本模态之间存在显著差异；2）需要建模细粒度对应关系来区分具有相似属性（如服装颜色、纹理、着装风格）的个体。现有的方法往往难以有效处理这些挑战，特别是在解耦不同属性并建立准确的跨模态对齐方面存在不足。

Method: 提出DiCo（解耦概念表示）框架，采用共享槽位表示结构。每个槽位作为跨模态的部分级锚点，并进一步分解为多个概念块。这种方法能够将互补属性（如颜色、纹理、形状）进行解耦，同时在图像和文本之间保持一致的部分级对应关系。通过分层和解耦的跨模态对齐机制，实现了更精细的属性表示和对齐。

Result: 在三个主流数据集（CUHK-PEDES、ICFG-PEDES、RSTPReid）上的实验表明，DiCo框架达到了与当前最先进方法竞争的性能水平。更重要的是，该方法通过显式的槽位和块级表示增强了系统的可解释性，能够提供更细粒度的检索结果。

Conclusion: DiCo框架通过共享槽位表示和概念块分解，成功解决了TIReID任务中的模态差异和细粒度对齐问题。该方法不仅实现了与最先进方法竞争的性能，还通过显式表示增强了可解释性，为更精细的跨模态检索提供了有效解决方案。

Abstract: Text-to-image person re-identification (TIReID) aims to retrieve person images from a large gallery given free-form textual descriptions. TIReID is challenging due to the substantial modality gap between visual appearances and textual expressions, as well as the need to model fine-grained correspondences that distinguish individuals with similar attributes such as clothing color, texture, or outfit style. To address these issues, we propose DiCo (Disentangled Concept Representation), a novel framework that achieves hierarchical and disentangled cross-modal alignment. DiCo introduces a shared slot-based representation, where each slot acts as a part-level anchor across modalities and is further decomposed into multiple concept blocks. This design enables the disentanglement of complementary attributes (\textit{e.g.}, color, texture, shape) while maintaining consistent part-level correspondence between image and text. Extensive experiments on CUHK-PEDES, ICFG-PEDES, and RSTPReid demonstrate that our framework achieves competitive performance with state-of-the-art methods, while also enhancing interpretability through explicit slot- and block-level representations for more fine-grained retrieval results.

</details>


### [8] [UEOF: A Benchmark Dataset for Underwater Event-Based Optical Flow](https://arxiv.org/abs/2601.10054)
*Nick Truong,Pritam P. Karmokar,William J. Beksi*

Main category: cs.CV

Score: 4/5 | Tags: Event Camera, Underwater Imaging, Optical Flow, Dataset, Computer Vision, Robotics

Recommendation: 这篇论文值得推荐，因为它针对水下视觉研究中的重要空白——事件相机数据集不足的问题，提供了创新的解决方案。该研究不仅创建了首个合成水下事件基准数据集，还系统地评估了现有光流算法在水下环境中的表现。这项工作对于水下机器人、海洋探索和环境监测等领域具有重要价值，为后续研究奠定了坚实基础。

TL;DR: 水下成像由于波长依赖的光衰减、悬浮颗粒的强散射、浑浊度引起的模糊以及非均匀照明而具有根本性的挑战。这些效应会损害标准相机，并使得几乎不可能获得真实运动地面真值。另一方面，事件相机提供了微秒级的分辨率和高动态范围。然而，由于缺乏将真实水下光学与精确光流配对的数据集，调查事件相机在水下环境中的研究进展有限。为解决这个问题，我们引入了第一个基于物理渲染的RGBD序列生成的合成水下基准数据集，用于基于事件的光流估计。通过对渲染的水下视频应用现代视频到事件流水线，我们生成了具有密集地面真值光流、深度和相机运动的真实事件数据流。此外，我们对最先进的基于学习和基于模型的光流预测方法进行了基准测试，以了解水下光传输如何影响事件形成和运动估计准确性。我们的数据集为未来水下基于事件的感知算法的开发和评估建立了新的基准。


<details>
  <summary>Details</summary>
Motivation: 水下成像面临多重挑战，包括光衰减、散射、浑浊度和非均匀照明，这使得传统相机难以在水下环境中获得准确的光流地面真值。虽然事件相机具有高时间分辨率和动态范围优势，但由于缺乏真实的水下事件数据集，限制了事件相机在水下环境的研究进展。本研究旨在填补这一空白，创建首个合成水下事件基准数据集。

Method: 作者采用物理基础的渲染方法生成水下RGBD序列，然后通过现代视频到事件流水线将渲染的水下视频转换为事件数据流。这种方法能够产生具有密集地面真值光流、深度和相机运动的真实事件数据。在此基础上，作者对现有的基于学习和基于模型的光流预测方法进行了全面的基准测试。

Result: 创建了首个合成水下事件基准数据集，该数据集包含了真实的水下光学效果与精确光流配对。通过基准测试，研究了水下光传输如何影响事件形成和运动估计准确性。该数据集为开发和评估水下基于事件的感知算法提供了新的基础。

Conclusion: 本研究成功构建了第一个针对水下环境的合成事件基准数据集，填补了水下事件相机研究的数据空白。该数据集能够支持未来水下基于事件的感知算法的开发和评估，并为理解水下光传输对事件形成和运动估计的影响提供了重要工具。

Abstract: Underwater imaging is fundamentally challenging due to wavelength-dependent light attenuation, strong scattering from suspended particles, turbidity-induced blur, and non-uniform illumination. These effects impair standard cameras and make ground-truth motion nearly impossible to obtain. On the other hand, event cameras offer microsecond resolution and high dynamic range. Nonetheless, progress on investigating event cameras for underwater environments has been limited due to the lack of datasets that pair realistic underwater optics with accurate optical flow. To address this problem, we introduce the first synthetic underwater benchmark dataset for event-based optical flow derived from physically-based ray-traced RGBD sequences. Using a modern video-to-event pipeline applied to rendered underwater videos, we produce realistic event data streams with dense ground-truth flow, depth, and camera motion. Moreover, we benchmark state-of-the-art learning-based and model-based optical flow prediction methods to understand how underwater light transport affects event formation and motion estimation accuracy. Our dataset establishes a new baseline for future development and evaluation of underwater event-based perception algorithms. The source code and dataset for this project are publicly available at https://robotic-vision-lab.github.io/ueof.

</details>


### [9] [CoF-T2I: Video Models as Pure Visual Reasoners for Text-to-Image Generation](https://arxiv.org/abs/2601.10061)
*Chengzhuo Tong,Mingkun Chang,Shenglong Zhang,Yuran Wang,Cheng Liang,Zhizheng Zhao,Ruichuan An,Bohan Zeng,Yang Shi,Yifan Dai,Ziming Zhao,Guanbin Li,Pengfei Wan,Yuanxing Zhang,Wentao Zhang*

Main category: cs.CV

Score: 4/5 | Tags: Video Generation, Text-to-Image, Chain-of-Frame, Visual Reasoning, Generative Models, Multimodal AI, Progressive Refinement

Recommendation: 该论文提出了创新的链式帧推理在文本到图像生成中的应用，方法新颖且实验结果令人信服。通过建立显式的渐进生成过程和专门的数据集，有效解决了视频模型在T2I任务中的应用障碍。在基准测试上的优异表现证明了该方法的有效性。虽然该方法可能增加计算复杂度，但其创新性和实用价值使其值得推荐。

TL;DR: 最近的视频生成模型揭示了链式帧推理（Chain-of-Frame, CoF）的出现，实现了逐帧的视觉推理。凭借这一能力，视频模型已成功应用于各种视觉任务（如迷宫求解、视觉谜题）。然而，由于在文本到图像（T2I）生成过程中缺乏明确的视觉推理起点和可解释的中间状态，它们在增强T2I生成方面的潜力在很大程度上尚未得到探索。为了弥合这一差距，我们提出了CoF-T2I，这是一个通过渐进式视觉细化将CoF推理整合到T2I生成中的模型，其中中间帧作为明确的推理步骤，最后一帧作为输出。为了建立这样一个明确的生成过程，我们策划了CoF-Evol-Instruct，这是一个CoF轨迹的数据集，用于建模从语义到美学的生成过程。为了进一步提高质量并避免运动伪影，我们实现了对每帧的独立编码操作。实验表明，CoF-T2I显著优于基础视频模型，并在具有挑战性的基准测试中取得了有竞争力的性能，在GenEval上达到0.86，在Imagine-Bench上达到7.468。这些结果表明，视频模型在推进高质量文本到图像生成方面具有巨大的潜力。


<details>
  <summary>Details</summary>
Motivation: 尽管视频生成模型中出现了链式帧推理能力，并已成功应用于视觉任务，但其在文本到图像生成领域的潜力尚未充分挖掘。主要挑战在于T2I生成过程缺乏明确的视觉推理起点和可解释的中间状态，这阻碍了视频模型在此领域的应用。本文旨在通过将链式帧推理机制引入T2I生成，建立显式的、可解释的生成过程，从而提升图像生成质量。

Method: 本文提出了CoF-T2I模型，通过渐进式视觉细化将链式帧推理整合到T2I生成中。具体方法包括：1）将中间帧作为明确的推理步骤，最终帧作为输出；2）构建CoF-Evol-Instruct数据集，包含建模从语义到美学演化的CoF轨迹；3）实现对每帧的独立编码操作，避免运动伪影并提高质量。这种方法将视频模型的帧间推理能力转化为图像生成的渐进优化过程。

Result: 实验结果表明，CoF-T2I在多个基准测试上表现出色：在GenEval基准上达到0.86分，在Imagine-Bench上达到7.468分。与基础视频模型相比，CoF-T2I取得了显著提升，并在具有挑战性的基准测试中展现出有竞争力的性能。这些结果验证了该方法在提升图像生成质量方面的有效性。

Conclusion: 本研究成功地将视频模型中的链式帧推理机制应用于文本到图像生成，通过建立显式的渐进式视觉细化过程，显著提升了图像生成质量。CoF-T2I模型不仅超越了基础视频模型的性能，还在标准基准测试中取得了有竞争力的结果。这项工作证明了视频模型的推理能力在推进高质量T2I生成方面具有巨大潜力，为跨模态生成研究提供了新的思路。

Abstract: Recent video generation models have revealed the emergence of Chain-of-Frame (CoF) reasoning, enabling frame-by-frame visual inference. With this capability, video models have been successfully applied to various visual tasks (e.g., maze solving, visual puzzles). However, their potential to enhance text-to-image (T2I) generation remains largely unexplored due to the absence of a clearly defined visual reasoning starting point and interpretable intermediate states in the T2I generation process. To bridge this gap, we propose CoF-T2I, a model that integrates CoF reasoning into T2I generation via progressive visual refinement, where intermediate frames act as explicit reasoning steps and the final frame is taken as output. To establish such an explicit generation process, we curate CoF-Evol-Instruct, a dataset of CoF trajectories that model the generation process from semantics to aesthetics. To further improve quality and avoid motion artifacts, we enable independent encoding operation for each frame. Experiments show that CoF-T2I significantly outperforms the base video model and achieves competitive performance on challenging benchmarks, reaching 0.86 on GenEval and 7.468 on Imagine-Bench. These results indicate the substantial promise of video models for advancing high-quality text-to-image generation.

</details>


### [10] [Thinking Like Van Gogh: Structure-Aware Style Transfer via Flow-Guided 3D Gaussian Splatting](https://arxiv.org/abs/2601.10075)
*Zhendong Wang,Lebin Zhou,Jingchuan Xiao,Rongduo Han,Nam Ling,Cihan Ruan*

Main category: cs.CV

Score: 5/5 | Tags: 3DGS, Style Transfer, Computer Graphics, Artistic Stylization, Geometric Abstraction, Flow Guidance, NeRF, AI Art

Recommendation: 这篇论文具有很高的创新性和实用性。它从艺术哲学出发，重新思考了3D风格迁移的本质问题，提出了与主流方法截然不同的技术路径。将后印象派的核心原则（几何抽象）转化为具体的技术实现，具有理论深度和实际价值。VLM-as-a-Judge评估框架也体现了对艺术主观性的深刻理解。这项工作在计算机图形学和AI艺术交叉领域具有重要贡献。

TL;DR: 1888年，文森特·梵高写道："我寻求本质中的夸张。"这一原则——放大结构形态同时抑制摄影细节——是后印象派艺术的核心。然而，大多数现有的3D风格迁移方法都反其道而行，将几何视为表面纹理投影的刚性基底。要真实再现后印象派风格化，必须将几何抽象作为主要的表达载体。我们为3D高斯泼溅（3DGS）提出了一种流引导的几何平流框架，在无网格设置中实施这一原则。我们的方法从2D绘画中提取方向流场并将其反向传播到3D空间，修正高斯基元以形成与场景拓扑一致的流对齐笔触，而不依赖显式的网格先验。这使得表达性的结构变形直接由绘画运动而非光度约束驱动。我们的贡献有三方面：（1）基于投影的、无网格的流引导机制，将2D艺术运动转移到3D高斯几何；（2）亮度-结构解耦策略，将几何变形与颜色优化分离，减轻激进结构抽象期间的伪影；（3）VLM-as-a-Judge评估框架，通过美学判断而非传统的像素级指标评估艺术真实性，明确解决艺术风格化的主观性。


<details>
  <summary>Details</summary>
Motivation: 现有3D风格迁移方法大多将几何视为刚性基底用于表面纹理投影，这与后印象派艺术强调"本质中的夸张"——放大结构形态同时抑制摄影细节——的核心原则相悖。为了真实再现后印象派风格化，需要从根本上改变方法，将几何抽象作为主要的表达载体而非辅助元素。

Method: 提出了一种流引导的几何平流框架，用于3D高斯泼溅（3DGS）。该方法从2D绘画中提取方向流场并反向传播到3D空间，修正高斯基元以形成与场景拓扑一致的流对齐笔触，无需显式网格先验。主要包括三个关键技术：基于投影的无网格流引导机制、亮度-结构解耦策略，以及用于评估的VLM-as-a-Judge框架。

Result: 该方法能够实现表达性的结构变形，直接由绘画运动而非光度约束驱动。通过流对齐的笔触形成，在保持场景拓扑的同时实现了后印象派风格的艺术表达。VLM-as-a-Judge评估框架提供了一种更符合艺术主观性的评估方式。

Conclusion: 该论文提出了一种创新的3D风格迁移方法，从根本上改变了传统方法处理几何抽象的方式，真正将后印象派艺术原则融入3D场景风格化。通过无网格的流引导机制和亮度-结构解耦策略，实现了基于几何抽象而非表面纹理的艺术表达，为3D艺术风格迁移领域提供了新思路。

Abstract: In 1888, Vincent van Gogh wrote, "I am seeking exaggeration in the essential." This principle, amplifying structural form while suppressing photographic detail, lies at the core of Post-Impressionist art. However, most existing 3D style transfer methods invert this philosophy, treating geometry as a rigid substrate for surface-level texture projection. To authentically reproduce Post-Impressionist stylization, geometric abstraction must be embraced as the primary vehicle of expression.
  We propose a flow-guided geometric advection framework for 3D Gaussian Splatting (3DGS) that operationalizes this principle in a mesh-free setting. Our method extracts directional flow fields from 2D paintings and back-propagates them into 3D space, rectifying Gaussian primitives to form flow-aligned brushstrokes that conform to scene topology without relying on explicit mesh priors. This enables expressive structural deformation driven directly by painterly motion rather than photometric constraints.
  Our contributions are threefold: (1) a projection-based, mesh-free flow guidance mechanism that transfers 2D artistic motion into 3D Gaussian geometry; (2) a luminance-structure decoupling strategy that isolates geometric deformation from color optimization, mitigating artifacts during aggressive structural abstraction; and (3) a VLM-as-a-Judge evaluation framework that assesses artistic authenticity through aesthetic judgment instead of conventional pixel-level metrics, explicitly addressing the subjective nature of artistic stylization.

</details>


### [11] [V-Zero: Self-Improving Multimodal Reasoning with Zero Annotation](https://arxiv.org/abs/2601.10094)
*Han Wang,Yi Yang,Jingyuan Hu,Minfeng Zhu,Wei Chen*

Main category: cs.CV

Score: 4/5 | Tags: Multimodal Learning, Vision-Language Models, Self-Improvement, Unsupervised Learning, GRPO, Visual Reasoning, Deep Learning

Recommendation: 该论文提出了一种创新的无需人工标注的视觉语言模型自我改进框架，具有实际应用价值和理论意义。方法设计巧妙，通过双角色共同进化实现有效的自我提升，实验结果显著，为解决多模态学习中标注数据稀缺问题提供了有前景的解决方案。

TL;DR: 最近多模态学习的进展显著提升了视觉语言模型（VLM）的推理能力。然而，最先进的方法严重依赖大规模人工标注数据集，这些数据集获取成本高昂且耗时。为克服这一限制，我们引入了V-Zero，这是一个通用的后训练框架，仅使用未标注图像促进自我改进。V-Zero通过实例化两个不同角色建立了一个共同进化的循环：提问者和解答者。提问者通过学习利用双重推理奖励来合成高质量、具有挑战性的问题，该奖励对比直观猜测与推理结果。解答者则使用从其自身采样响应中通过多数投票得出的伪标签进行优化。两个角色通过组相对策略优化（GRPO）迭代训练，驱动相互增强的循环。值得注意的是，在没有一个人类标注的情况下，V-Zero在Qwen2.5-VL-7B-Instruct上实现了持续的性能提升，视觉数学推理提升了+1.7，通用视觉中心任务提升了+2.6，展示了多模态系统中自我改进的潜力。代码可在https://github.com/SatonoDia/V-Zero获取。


<details>
  <summary>Details</summary>
Motivation: 现有最先进的多模态视觉语言模型严重依赖大规模人工标注数据集，这些数据集获取成本高昂且耗时。为了突破这一限制，研究者需要探索无需人工标注的自我改进方法，以降低训练成本并提高模型的可扩展性。

Method: V-Zero采用了一个通用的后训练框架，通过建立提问者和解答者两个角色的共同进化循环。提问者学习合成高质量问题，利用双重推理奖励对比直观猜测与推理结果；解答者使用从自身采样响应中通过多数投票得出的伪标签进行优化。两个角色通过组相对策略优化（GRPO）进行迭代训练，实现相互增强。

Result: 在没有一个人类标注的情况下，V-Zero在Qwen2.5-VL-7B-Instruct模型上实现了显著性能提升：视觉数学推理能力提高了+1.7，通用视觉中心任务性能提高了+2.6。这表明该框架在多模态系统中具有有效的自我改进能力。

Conclusion: V-Zero框架通过无需人工标注的自我改进方法，成功提升了视觉语言模型的推理能力，展示了多模态系统中自我进化的潜力，为降低训练成本和提高模型可扩展性提供了新途径。

Abstract: Recent advances in multimodal learning have significantly enhanced the reasoning capabilities of vision-language models (VLMs). However, state-of-the-art approaches rely heavily on large-scale human-annotated datasets, which are costly and time-consuming to acquire. To overcome this limitation, we introduce V-Zero, a general post-training framework that facilitates self-improvement using exclusively unlabeled images. V-Zero establishes a co-evolutionary loop by instantiating two distinct roles: a Questioner and a Solver. The Questioner learns to synthesize high-quality, challenging questions by leveraging a dual-track reasoning reward that contrasts intuitive guesses with reasoned results. The Solver is optimized using pseudo-labels derived from majority voting over its own sampled responses. Both roles are trained iteratively via Group Relative Policy Optimization (GRPO), driving a cycle of mutual enhancement. Remarkably, without a single human annotation, V-Zero achieves consistent performance gains on Qwen2.5-VL-7B-Instruct, improving visual mathematical reasoning by +1.7 and general vision-centric by +2.6, demonstrating the potential of self-improvement in multimodal systems. Code is available at https://github.com/SatonoDia/V-Zero

</details>


### [12] [InfoSculpt: Sculpting the Latent Space for Generalized Category Discovery](https://arxiv.org/abs/2601.10098)
*Wenwen Liao,Hang Ruan,Jianbo Yu,Yuansong Wang,Qingchao Jiang,Xiaofeng Yang*

Main category: cs.CV

Score: 4/5 | Tags: GCD, Information Theory, Information Bottleneck, Representation Learning, Unsupervised Learning, Clustering, Computer Vision

Recommendation: 该论文具有较强的理论创新性，将信息瓶颈原理系统地应用于广义类别发现问题，提出了新颖的双重条件互信息框架。方法设计巧妙，实验结果充分，在8个基准测试上验证了有效性。虽然可能存在实验细节不够详尽的问题，但整体上是一篇高质量的研究工作，对开放世界学习领域有重要贡献。

TL;DR: 广义类别发现(GCD)旨在对大规模无标注数据集中的已知和新类别实例进行分类，这是现实世界开放世界应用中的一个关键但具有挑战性的任务。然而，现有方法通常依赖于伪标记或两阶段聚类，缺乏明确的机制来将本质的、定义类别的信号与实例特定的噪声进行分离。本文从信息论的角度出发，基于信息瓶颈(IB)原理，重新构建了GCD问题。我们提出了InfoSculpt，这是一个通过最小化双重条件互信息(CMI)目标来系统性地塑造表示空间的新框架。InfoSculpt独特地将有标注数据上的类别级CMI与所有数据上的实例级CMI相结合：前者用于学习已知类别的紧凑和判别性表示，后者通过压缩增强诱导的噪声来提取不变特征。这两个目标在不同尺度上协同工作，产生一个解耦且鲁棒的潜在空间，其中类别信息被保留，而噪声的、实例特定的细节被丢弃。在8个基准测试上的广泛实验验证了我们信息论方法的有效性。


<details>
  <summary>Details</summary>
Motivation: 广义类别发现(GCD)在开放世界的实际应用中具有重要意义，但现有方法存在根本性缺陷。伪标记和两阶段聚类等方法缺乏明确的原则性机制来分离本质的类别信号和实例特定的噪声。为了解决这一限制，作者从信息论的角度重新审视GCD问题，认为需要更系统性的框架来明确地解耦表示空间中的关键信息。

Method: 本文提出了InfoSculpt框架，该框架基于信息瓶颈原理，通过最小化双重条件互信息(CMI)目标来塑造表示空间。方法包括两个关键组成部分：1）在有标注数据上使用类别级CMI，学习已知类别的紧凑和判别性表示；2）在所有数据上使用实例级CMI，通过压缩增强诱导的噪声来提取不变特征。这两个目标在不同尺度上协同工作，共同产生一个解耦且鲁棒的潜在空间，实现了类别信息的保留和实例特定噪声的丢弃。

Result: 在8个基准测试数据集上的广泛实验验证了InfoSculpt的有效性。该方法在广义类别发现任务上取得了显著的性能提升，表明信息论视角为GCD问题提供了一个有前景的解决方案。实验结果显示，通过系统地塑造表示空间，InfoSculpt能够更好地分离本质类别信号和实例特定噪声，从而提高了分类准确率。

Conclusion: 本文成功地将广义类别发现问题从信息论角度重新构建，基于信息瓶颈原理提出了InfoSculpt框架。该方法通过双重条件互信息目标系统地塑造表示空间，有效地解耦了类别信息与实例特定噪声。实验证明这种信息论方法为GCD任务提供了一个有效且有原则的解决方案。

Abstract: Generalized Category Discovery (GCD) aims to classify instances from both known and novel categories within a large-scale unlabeled dataset, a critical yet challenging task for real-world, open-world applications. However, existing methods often rely on pseudo-labeling, or two-stage clustering, which lack a principled mechanism to explicitly disentangle essential, category-defining signals from instance-specific noise. In this paper, we address this fundamental limitation by re-framing GCD from an information-theoretic perspective, grounded in the Information Bottleneck (IB) principle. We introduce InfoSculpt, a novel framework that systematically sculpts the representation space by minimizing a dual Conditional Mutual Information (CMI) objective. InfoSculpt uniquely combines a Category-Level CMI on labeled data to learn compact and discriminative representations for known classes, and a complementary Instance-Level CMI on all data to distill invariant features by compressing augmentation-induced noise. These two objectives work synergistically at different scales to produce a disentangled and robust latent space where categorical information is preserved while noisy, instance-specific details are discarded. Extensive experiments on 8 benchmarks demonstrate that InfoSculpt validating the effectiveness of our information-theoretic approach.

</details>


### [13] [FlowAct-R1: Towards Interactive Humanoid Video Generation](https://arxiv.org/abs/2601.10103)
*Lizhen Wang,Yongming Zhu,Zhipeng Ge,Youwei Zheng,Longhao Zhang,Tianshu Hu,Shiyang Qin,Mingshuang Luo,Jiaxu Zhang,Xin Chen,Yulong Wang,Zerong Zheng,Jianwen Jiang,Chao Liang,Weifeng Chen,Xing Wang,Yuan Zhang,Mingyuan Gao*

Main category: cs.CV

Score: 4/5 | Tags: Video Generation, Interactive AI, Real-time Systems, Humanoid Animation, Diffusion Models, MMDiT, AI Agents

Recommendation: 推荐理由：该论文在交互式视频生成领域提出了创新性解决方案，成功平衡了高质量合成与实时响应这一关键技术挑战。通过分块扩散强制策略和系统优化实现了真正的实时交互能力，具有重要的实际应用价值。技术实现严谨，实验效果显著，特别适合对实时交互和视频生成感兴趣的研究者和开发者。

TL;DR: 交互式人形视频生成旨在合成能够通过连续和响应式视频与人类互动的逼真视觉智能体。尽管视频合成领域最近取得了进展，但现有方法常常在高保真合成和实时交互需求之间权衡取舍。在本文中，我们提出了FlowAct-R1，这是一个专门为实时交互式人形视频生成设计的框架。基于MMDiT架构构建，FlowAct-R1能够实现任意持续时间的流式视频合成，同时保持低延迟响应。我们引入了一种分块扩散强制策略，辅以一种新颖的自强制变体，以减轻错误累积并确保连续交互期间的长期时间一致性。通过利用高效蒸馏和系统级优化，我们的框架在480p分辨率下实现了稳定的25fps，首次帧时间仅约1.5秒。所提出的方法提供了整体和细粒度的全身控制，使智能体能够在交互场景中自然地过渡到不同的行为状态。实验结果表明，FlowAct-R1实现了卓越的行为生动性和感知真实性，同时在不同角色风格上保持了强大的泛化能力。


<details>
  <summary>Details</summary>
Motivation: 现有的交互式视频生成方法在高保真合成和实时交互需求之间存在权衡，无法同时满足高质量的视觉保真度和低延迟的实时响应需求。FlowAct-R1旨在解决这一瓶颈，实现真正实时且高质量的人形视频交互生成。

Method: 本文提出FlowAct-R1框架，基于MMDiT架构构建。核心创新包括：1）分块扩散强制策略及其自强制变体，减轻错误累积并保持长期时间一致性；2）高效蒸馏技术提升推理效率；3）系统级优化实现低延迟流式视频合成；4）支持任意时长的视频生成并维持低TTFF。

Result: FlowAct-R1在480p分辨率下实现稳定25fps的实时视频生成，首次帧时间仅约1.5秒。实验证明该方法在行为生动性、感知真实性方面表现卓越，能够自然过渡不同行为状态，并在多样角色风格上保持强大泛化能力，相比现有方法在实时交互质量和性能上有显著提升。

Conclusion: FlowAct-R1成功解决了交互式人形视频生成中高保真合成与实时响应之间的矛盾，通过创新的分块扩散强制策略和系统优化实现了真正实时的交互能力，为人形智能体视频交互开辟了新可能性。

Abstract: Interactive humanoid video generation aims to synthesize lifelike visual agents that can engage with humans through continuous and responsive video. Despite recent advances in video synthesis, existing methods often grapple with the trade-off between high-fidelity synthesis and real-time interaction requirements. In this paper, we propose FlowAct-R1, a framework specifically designed for real-time interactive humanoid video generation. Built upon a MMDiT architecture, FlowAct-R1 enables the streaming synthesis of video with arbitrary durations while maintaining low-latency responsiveness. We introduce a chunkwise diffusion forcing strategy, complemented by a novel self-forcing variant, to alleviate error accumulation and ensure long-term temporal consistency during continuous interaction. By leveraging efficient distillation and system-level optimizations, our framework achieves a stable 25fps at 480p resolution with a time-to-first-frame (TTFF) of only around 1.5 seconds. The proposed method provides holistic and fine-grained full-body control, enabling the agent to transition naturally between diverse behavioral states in interactive scenarios. Experimental results demonstrate that FlowAct-R1 achieves exceptional behavioral vividness and perceptual realism, while maintaining robust generalization across diverse character styles.

</details>


### [14] [MathDoc: Benchmarking Structured Extraction and Active Refusal on Noisy Mathematics Exam Papers](https://arxiv.org/abs/2601.10104)
*Chenyue Zhou,Jiayi Tuo,Shitong Qin,Wei Dai,Mingxuan Wang,Ziwei Zhao,Duoyang Li,Shiyang Su,Yanxi Lu,Yanbiao Ma*

Main category: cs.CV

Score: 5/5 | Tags: Document Analysis, Multimodal Learning, Benchmark, Mathematics Education, Computer Vision, Information Extraction, Visual Noise, Active Refusal

Recommendation: 该论文提出了一项重要且实用的研究，建立了首个专注于数学试卷文档级信息提取的真实世界基准。论文不仅关注提取准确性，还强调了模型拒绝无法识别输入的关键能力，这在真实场景中尤为重要。实验设计合理，结果揭示了当前多模态大语言模型的一个重要局限性，对智能教育领域具有重要价值。

TL;DR: 从纸质数学试卷中自动提取结构化问题是智能教育的基础，但由于严重的视觉噪声，在真实场景中仍具有挑战性。现有基准主要关注干净文档或通用布局分析，忽略了数学问题的结构完整性以及模型主动拒绝不完整输入的能力。我们介绍了MathDoc，这是首个用于真实高中数学试卷文档级信息提取的基准。MathDoc包含3,609个精心策划的问题，具有真实世界的人工痕迹，并明确包含不可识别的样本来评估主动拒绝行为。我们提出了一个涵盖题干准确性、视觉相似性和拒绝能力的多维度评估框架。在包括Qwen3-VL和Gemini-2.5-Pro在内的最先进多模态大语言模型上的实验表明，尽管端到端模型实现了强大的提取性能，但它们始终未能拒绝不可读的输入，反而产生自信但无效的输出。这些结果突显了当前多模态大语言模型中的一个关键差距，并将MathDoc确立为评估在退化文档条件下模型可靠性的基准。


<details>
  <summary>Details</summary>
Motivation: 现有文档信息提取研究主要关注干净的文档数据，而真实场景中的数学试卷往往存在严重的视觉噪声，这给自动提取结构化问题带来了巨大挑战。当前的多模态大语言模型在处理不完整或无法识别的输入时缺乏主动拒绝能力，常常产生自信但错误的输出，这在智能教育应用中具有潜在风险。因此需要建立一个专门针对数学试卷的真实世界基准来评估模型在这些挑战性条件下的表现。

Method: 作者首先构建了MathDoc基准数据集，包含3,609个从真实高中数学试卷中提取的问题，其中包含了各种现实世界中的视觉噪声和人工作品痕迹，并专门加入了不可识别的样本。然后提出了一个多维度评估框架，该框架不仅评估模型的提取准确性，还特别强调模型的拒绝能力，包括题干准确性、视觉相似性和拒绝能力三个维度。最后在包括Qwen3-VL和Gemini-2.5-Pro在内的当前最先进多模态大语言模型上进行了系统性实验验证。

Result: 实验结果显示，虽然当前最先进的多模态大语言模型在文档信息提取方面表现出色，但在处理不可读输入时存在严重缺陷。这些模型未能正确拒绝不完整或无法识别的输入，反而产生高度自信但无效的输出。这表明当前模型在真实世界退化文档条件下缺乏可靠的拒绝机制，对智能教育应用构成潜在风险。

Conclusion: MathDoc是首个专门针对高中数学试卷文档级信息提取的基准，突出了真实场景中视觉噪声带来的挑战。实验表明当前多模态大语言模型在处理退化文档时缺乏可靠的拒绝机制，这暴露了现有技术的一个关键局限。该基准为评估和推动面向真实世界文档处理的可靠多模态系统发展提供了重要工具。

Abstract: The automated extraction of structured questions from paper-based mathematics exams is fundamental to intelligent education, yet remains challenging in real-world settings due to severe visual noise. Existing benchmarks mainly focus on clean documents or generic layout analysis, overlooking both the structural integrity of mathematical problems and the ability of models to actively reject incomplete inputs. We introduce MathDoc, the first benchmark for document-level information extraction from authentic high school mathematics exam papers. MathDoc contains \textbf{3,609} carefully curated questions with real-world artifacts and explicitly includes unrecognizable samples to evaluate active refusal behavior. We propose a multi-dimensional evaluation framework covering stem accuracy, visual similarity, and refusal capability. Experiments on SOTA MLLMs, including Qwen3-VL and Gemini-2.5-Pro, show that although end-to-end models achieve strong extraction performance, they consistently fail to refuse illegible inputs, instead producing confident but invalid outputs. These results highlight a critical gap in current MLLMs and establish MathDoc as a benchmark for assessing model reliability under degraded document conditions. Our project repository is available at \href{https://github.com/winnk123/papers/tree/master}{GitHub repository}

</details>


### [15] [Enhancing Visual In-Context Learning by Multi-Faceted Fusion](https://arxiv.org/abs/2601.10107)
*Wenwen Liao,Jianbo Yu,Yuansong Wang,Qingchao Jiang,Xiaofeng Yang*

Main category: cs.CV

Score: 4/5 | Tags: VICL, Computer Vision, Multi-modal Learning, Contextual Learning, Image Generation, Segmentation, Object Detection, Image Colorization

Recommendation: 这篇论文提出了一个创新的视觉上下文学习框架，通过多组合协作融合机制解决了现有方法信息利用不充分的问题。方法设计新颖，实验涵盖多种视觉任务，结果具有说服力。唯一的局限性是未详细说明与更广泛基准方法的比较，但整体仍是一项有价值和推荐的工作。

TL;DR: 视觉上下文学习(VICL)已成为一种强大的范式，使模型能够通过从上下文示例中学习来执行新的视觉任务。主流的"检索-然后提示"方法通常依赖于选择最佳视觉提示，这种做法往往会丢弃其他合适候选的有价值上下文信息。尽管最近的工作探索了将前K个提示融合到单个增强表示中，但这仍然只是将多个丰富信号简单压缩为一个，限制了模型的推理能力。我们认为需要一种更加多方面的协作式融合来释放这些多样化上下文的全部潜力。为解决这一局限，我们引入了一个新颖框架，从单提示融合转向多组合协作融合。我们的方法不是将多个提示压缩为一个，而是生成三个上下文表示分支，每个分支通过集成来自不同高质量提示组合的信息形成。这些互补的指导信号随后被输入到提出的MULTI-VQGAN架构中，该架构旨在共同解释和利用来自多个源的协作信息。在多样化任务上的广泛实验，包括前景分割、单目标检测和图像着色，突显了其在跨任务泛化、有效上下文融合以及比现有方法产生更鲁棒和准确预测方面的强大能力。


<details>
  <summary>Details</summary>
Motivation: 当前的视觉上下文学习方法主要采用"检索-然后提示"的单提示方法，这丢弃了其他候选提示中的有价值上下文信息。即使最近融合前K个提示的方法，也只是将它们简单压缩为单一表示，限制了模型充分利用多样化上下文信息的能力。因此，需要一种更有效的多提示协作融合机制来充分挖掘上下文学习的潜力。

Method: 本文提出了一种多组合协作融合框架，而非传统的单提示融合方法。核心创新包括：1) 生成三个上下文表示分支，每个分支通过整合来自不同高质量提示组合的信息形成；2) 提出MULTI-VQGAN架构，专门设计用于共同解释和利用来自多个源的协作信息；3) 构建互补的指导信号，使模型能够从多个视角理解上下文信息。

Result: 在多个视觉任务上的实验结果表明，该方法在跨任务泛化、上下文融合有效性和预测准确性方面表现优异。具体来说，在前景分割、单目标检测和图像着色等任务上，该方法相比现有方法能够产生更鲁棒和准确的预测，显示出强大的性能提升。

Conclusion: 本文提出的多组合协作融合框架超越了传统的单提示视觉上下文学习方法，通过生成多个上下文表示分支和专门的MULTI-VQGAN架构，实现了更有效的上下文信息利用。该方法在多种视觉任务上表现出优异的性能，为视觉上下文学习提供了新的研究方向。

Abstract: Visual In-Context Learning (VICL) has emerged as a powerful paradigm, enabling models to perform novel visual tasks by learning from in-context examples. The dominant "retrieve-then-prompt" approach typically relies on selecting the single best visual prompt, a practice that often discards valuable contextual information from other suitable candidates. While recent work has explored fusing the top-K prompts into a single, enhanced representation, this still simply collapses multiple rich signals into one, limiting the model's reasoning capability. We argue that a more multi-faceted, collaborative fusion is required to unlock the full potential of these diverse contexts. To address this limitation, we introduce a novel framework that moves beyond single-prompt fusion towards an multi-combination collaborative fusion. Instead of collapsing multiple prompts into one, our method generates three contextual representation branches, each formed by integrating information from different combinations of top-quality prompts. These complementary guidance signals are then fed into proposed MULTI-VQGAN architecture, which is designed to jointly interpret and utilize collaborative information from multiple sources. Extensive experiments on diverse tasks, including foreground segmentation, single-object detection, and image colorization, highlight its strong cross-task generalization, effective contextual fusion, and ability to produce more robust and accurate predictions than existing methods.

</details>


### [16] [Beyond Single Prompts: Synergistic Fusion and Arrangement for VICL](https://arxiv.org/abs/2601.10117)
*Wenwen Liao,Jianbo Yu,Yuansong Wang,Shifu Yan,Xiaofeng Yang*

Main category: cs.CV

Score: 4/5 | Tags: Vision, In-Context Learning, Few-Shot Learning, Inpainting, Deep Learning, Computer Vision

Recommendation: 这篇论文针对视觉上下文学习中的实际问题提出了创新的解决方案，包括多提示融合、布局先验解耦和双向微调等新颖方法。实验涵盖多个视觉任务，验证了方法的有效性和泛化能力。虽然论文评分较高，但考虑到视觉上下文学习是当前计算机视觉领域的重要研究方向，该方法具有实用价值，值得相关研究人员关注。

TL;DR: 视觉上下文学习（VICL）使修复模型能够通过少量提示快速适应新的视觉任务。然而，现有方法存在两个关键问题：（1）仅选择最相似的提示会丢弃其他高质量提示的互补线索；（2）未能利用不同提示排列所隐含的结构化信息。我们提出了一个端到端的VICL框架来克服这些限制。首先，一个自适应融合模块聚合多个提示中的关键模式和标注，形成更精确的上下文提示。其次，我们引入了排列特定的轻量级MLP，将布局先验与核心模型解耦，同时最小化对整个模型的影响。此外，双向微调机制交换查询和提示的角色，鼓励模型从融合上下文中重建原始提示，从而增强融合模块与修复模型之间的协作。在前景分割、单目标检测和图像着色方面的实验证明了我们方法的优越结果和强大的跨任务泛化能力。


<details>
  <summary>Details</summary>
Motivation: 现有的视觉上下文学习方法存在两个关键限制：第一，仅选择最相似的提示进行学习，忽视了其他高质量提示中可能包含的互补信息；第二，未能充分利用不同提示排列方式所蕴含的结构化信息。这些限制导致模型无法充分利用所有可用的上下文线索，影响了其在复杂视觉任务上的性能和泛化能力。

Method: 提出端到端的VICL框架，包含三个核心组件：1）自适应融合模块，用于聚合多个提示中的关键模式和标注，生成更精确的上下文提示；2）排列特定的轻量级MLP，将布局先验与核心模型解耦，减少对整体模型的影响；3）双向微调机制，通过交换查询和提示的角色，使模型能够从融合的上下文中重建原始提示，增强模块间的协作。

Result: 在前景分割、单目标检测和图像着色等视觉任务上的实验结果表明，该方法取得了优越的性能表现，并展现出强大的跨任务泛化能力。通过利用多个提示的互补信息和结构化的提示排列，模型在少量样本学习场景下获得了更好的适应性和准确性。

Conclusion: 该研究提出的端到端VICL框架通过融合多个提示的关键信息、解耦布局先验以及实施双向微调，有效克服了现有方法的局限性。该方法不仅在多种视觉任务上表现出色，还具备良好的跨任务泛化能力，为视觉上下文学习提供了新的技术路径。

Abstract: Vision In-Context Learning (VICL) enables inpainting models to quickly adapt to new visual tasks from only a few prompts. However, existing methods suffer from two key issues: (1) selecting only the most similar prompt discards complementary cues from other high-quality prompts; and (2) failing to exploit the structured information implied by different prompt arrangements.
  We propose an end-to-end VICL framework to overcome these limitations. Firstly, an adaptive Fusion Module aggregates critical patterns and annotations from multiple prompts to form more precise contextual prompts. Secondly, we introduce arrangement-specific lightweight MLPs to decouple layout priors from the core model, while minimally affecting the overall model. In addition, an bidirectional fine-tuning mechanism swaps the roles of query and prompt, encouraging the model to reconstruct the original prompt from fused context and thus enhancing collaboration between the fusion module and the inpainting model. Experiments on foreground segmentation, single-object detection, and image colorization demonstrate superior results and strong cross-task generalization of our method.

</details>


### [17] [VQ-Seg: Vector-Quantized Token Perturbation for Semi-Supervised Medical Image Segmentation](https://arxiv.org/abs/2601.10124)
*Sicheng Yang,Zhaohu Xing,Lei Zhu*

Main category: cs.CV

Score: 4/5 | Tags: Medical Image Segmentation, Semi-supervised Learning, Vector Quantization, Consistency Learning, Feature Perturbation, CT Scans, Deep Learning

Recommendation: 该论文提出了创新性的向量量化特征扰动方法解决半监督医学图像分割中的关键问题，方法设计完整且实验充分。但针对基础模型指导的具体实现细节可能需进一步阐述，且在泛化到其他医学图像模态方面仍需验证。

TL;DR: 一致性学习与特征扰动是半监督医学图像分割中广泛使用的策略。然而，许多现有的扰动方法依赖于dropout，因此需要仔细手动调整dropout率，这是一个敏感的、难以优化的超参数，可能导致次优的正则化效果。为了克服这一局限性，我们提出了VQ-Seg，这是首个采用向量量化（VQ）来离散化特征空间的方法，并引入了新颖且可控的量化扰动模块（QPM）来替代dropout。我们的QPM通过重排码书索引的空间位置来扰动离散表示，实现了有效且可控的正则化。为了减轻量化可能导致的信息损失，我们设计了一个双分支架构，其中后量化特征空间由图像重建和分割任务共享。此外，我们引入了后VQ特征适配器（PFA），以融入来自基础模型（FM）的指导，补充量化过程中损失的高层语义信息。进一步，我们收集了一个大规模肺癌（LC）数据集，包含828个用于中央型肺癌标注的CT扫描。在LC数据集和其他公共基准上的大量实验证明了我们方法的有效性，该方法优于最先进的方法。代码可在https://github.com/script-Yang/VQ-Seg获取。


<details>
  <summary>Details</summary>
Motivation: 半监督医学图像分割中的一致性学习通常依赖于dropout进行特征扰动，但dropout率作为敏感超参数需要仔细调优，难以优化且可能导致次优的正则化效果。现有方法在扰动策略的可控性和有效性方面存在局限。

Method: VQ-Seg提出了基于向量量化（VQ）的离散特征表示方法，通过量化扰动模块（QPM）替代传统的dropout。QPM通过对码书索引的空间位置进行重排实现可控的特征扰动。采用双分支架构共享后量化特征空间，结合图像重建和分割任务。此外，设计了后VQ特征适配器（PFA）来融合基础模型的高层语义信息，补充量化过程中的信息损失。

Result: 方法在收集的大规模肺癌数据集（828个CT扫描）和多个公共基准测试中进行了验证。实验结果表明，VQ-Seg在性能上优于现有的最先进方法，证明了所提出方法在半监督医学图像分割任务中的有效性。

Conclusion: VQ-Seg通过向量量化离散化特征空间，引入可控的量化扰动模块有效解决了传统dropout方法中超参数调优困难的问题。双分支架构和后VQ特征适配器设计有效缓解了量化过程中的信息损失问题。该方法为半监督医学图像分割提供了新的、有效的特征扰动策略。

Abstract: Consistency learning with feature perturbation is a widely used strategy in semi-supervised medical image segmentation. However, many existing perturbation methods rely on dropout, and thus require a careful manual tuning of the dropout rate, which is a sensitive hyperparameter and often difficult to optimize and may lead to suboptimal regularization. To overcome this limitation, we propose VQ-Seg, the first approach to employ vector quantization (VQ) to discretize the feature space and introduce a novel and controllable Quantized Perturbation Module (QPM) that replaces dropout. Our QPM perturbs discrete representations by shuffling the spatial locations of codebook indices, enabling effective and controllable regularization. To mitigate potential information loss caused by quantization, we design a dual-branch architecture where the post-quantization feature space is shared by both image reconstruction and segmentation tasks. Moreover, we introduce a Post-VQ Feature Adapter (PFA) to incorporate guidance from a foundation model (FM), supplementing the high-level semantic information lost during quantization. Furthermore, we collect a large-scale Lung Cancer (LC) dataset comprising 828 CT scans annotated for central-type lung carcinoma. Extensive experiments on the LC dataset and other public benchmarks demonstrate the effectiveness of our method, which outperforms state-of-the-art approaches. Code available at: https://github.com/script-Yang/VQ-Seg.

</details>


### [18] [LaViT: Aligning Latent Visual Thoughts for Multi-modal Reasoning](https://arxiv.org/abs/2601.10129)
*Linquan Wu,Tianxiang Jiang,Yifei Dong,Haoyu Yang,Fengji Zhang,Shichaang Meng,Ai Xuan,Linqi Song,Jacky Keung*

Main category: cs.CV

Score: 5/5 | Tags: 多模态学习, 知识蒸馏, 视觉语言模型, 注意力机制, 潜在表示, 视觉基础, 推理, 课程学习

Recommendation: 这篇论文非常值得推荐，原因如下：1）识别了多模态知识蒸馏中一个关键但未被充分研究的感知差距问题；2）提出了一种创新的LaViT框架，通过潜在视觉思维对齐来解决这一问题；3）方法设计巧妙，结合了自回归重建和课程感官门控机制；4）实验结果令人印象深刻，小型模型性能超越大型模型；5）为多模态推理领域提供了新的研究方向和实用解决方案；6）具有很高的理论价值和实际应用前景。

TL;DR: 当前多模态潜在推理通常依赖于外部监督（如辅助图像），忽略了内在的视觉注意力动态。在这项工作中，我们识别了蒸馏中的一个关键感知差距：学生模型经常模仿教师的文本输出，却关注根本不同的视觉区域，实际上依赖语言先验而非基于感知。为了解决这个问题，我们提出了LaViT，一个对齐潜在视觉思维而非静态嵌入的框架。LaViT强制学生在文本生成之前自回归地重建教师的视觉语义和注意力轨迹，采用课程感官门控机制来防止捷径学习。大量实验表明，LaViT显著增强了视觉基础，在复杂推理任务上实现了高达+16.9%的增益，并使紧凑的3B模型性能超过更大的开源变体和像GPT-4o这样的专有模型。


<details>
  <summary>Details</summary>
Motivation: 当前多模态潜在推理方法存在一个关键问题：它们依赖外部监督而忽视了内在的视觉注意力动态。在知识蒸馏过程中，学生模型往往只模仿教师的文本输出，却关注不同的视觉区域，这表明学生实际上是在依赖语言先验而非真正的视觉感知。这种感知差距限制了模型在复杂推理任务中的表现。作者旨在解决这一根本问题，通过提出一种能够对齐潜在视觉思维的新方法，确保学生模型真正学习到教师的视觉语义理解。

Method: LaViT（潜在视觉思维对齐框架）的核心方法是：1）不再对齐静态嵌入，而是对齐教师和学生的潜在视觉思维；2）要求学生模型在文本生成之前自回归地重建教师的视觉语义和注意力轨迹；3）引入课程感官门控机制，动态控制输入信息流，防止学生模型通过语言先验等捷径学习。这种方法确保学生必须真正理解视觉内容才能完成推理任务，从而实现对教师视觉认知过程的深度模仿。

Result: 实验结果表明LaViT取得了显著成果：1）在复杂推理任务上实现了高达+16.9%的性能增益；2）紧凑的3B参数模型能够超越更大的开源模型变体；3）在某些任务上甚至超过了GPT-4o这样的专有模型；4）显著增强了模型的视觉基础能力，使学生模型真正关注与教师模型相同的视觉区域，减少了对语言先验的依赖。

Conclusion: LaViT通过对齐潜在视觉思维而非静态嵌入，有效解决了多模态知识蒸馏中的感知差距问题。该方法强制学生模型在文本生成前重建教师的视觉语义和注意力轨迹，配合课程感官门控机制，成功防止了捷径学习。结果表明，该方法不仅显著提升了视觉基础能力，还使小型模型能够在复杂推理任务上超越更大的模型，为构建更高效、更可靠的多模态推理系统提供了新思路。

Abstract: Current multimodal latent reasoning often relies on external supervision (e.g., auxiliary images), ignoring intrinsic visual attention dynamics. In this work, we identify a critical Perception Gap in distillation: student models frequently mimic a teacher's textual output while attending to fundamentally divergent visual regions, effectively relying on language priors rather than grounded perception. To bridge this, we propose LaViT, a framework that aligns latent visual thoughts rather than static embeddings. LaViT compels the student to autoregressively reconstruct the teacher's visual semantics and attention trajectories prior to text generation, employing a curriculum sensory gating mechanism to prevent shortcut learning. Extensive experiments show that LaViT significantly enhances visual grounding, achieving up to +16.9% gains on complex reasoning tasks and enabling a compact 3B model to outperform larger open-source variants and proprietary models like GPT-4o.

</details>


### [19] [Advancing Adaptive Multi-Stage Video Anomaly Reasoning: A Benchmark Dataset and Method](https://arxiv.org/abs/2601.10165)
*Chao Huang,Benfeng Wang,Wei Wang,Jie Wen,Li Shen,Wenqi Ren,Yong Xu,Xiaochun Cao*

Main category: cs.CV

Score: 5/5 | Tags: MLLM, Video Understanding, Anomaly Detection, Reasoning, Dataset, Weak Supervision, Risk Awareness, Decision Making

Recommendation: 强烈推荐此论文，原因如下：1）提出了具有创新性的视频异常推理(VAR)任务，突破了传统视频异常检测的描述性局限；2）构建了大规模结构化数据集，为领域研究提供了宝贵资源；3）设计了系统性的方法论，包括新颖的标注框架和优化策略；4）实验结果全面且具有说服力，证明了方法的有效性；5）该工作为多模态推理研究开辟了新方向，具有重要的理论价值和实际应用前景。

TL;DR: 多模态大语言模型(MLLMs)推理能力的近期进展凸显了其在复杂视频理解任务中的潜力。然而，在视频异常检测与理解(VAD&U)领域，现有的基于MLLM的方法大多局限于异常定位或事后描述，缺乏显式的推理过程、风险意识和面向决策的解释。为解决这一空白，我们定义了一项新任务称为视频异常推理(VAR)，该任务将视频异常分析从描述性理解提升到结构化、多阶段推理。VAR明确要求模型在回答异常相关问题之前对异常事件进行渐进式推理，涵盖视觉感知、因果解释和风险感知决策。为支持此任务，我们提出了一个包含8,641个视频的新数据集，每个视频都标注了对应不同推理深度的多样化问题类型，总计超过50,000个样本，使其成为视频异常领域最大的数据集之一。标注基于结构化的感知-认知-行动思维链(PerCoAct-CoT)，这形式化了视频异常理解领域特定的推理先验。该设计能够系统评估多阶段和自适应异常推理。此外，我们提出了异常感知组相对策略优化，以在弱监督下进一步增强推理可靠性。基于提出的任务和数据集，我们开发了一个端到端的基于MLLM的VAR模型，称为Vad-R1-Plus，支持自适应分层推理和风险感知决策。大量实验表明，提出的基准和方法有效提升了MLLMs在VAR任务上的推理能力，超越了开源和专有基线。


<details>
  <summary>Details</summary>
Motivation: 当前基于多模态大语言模型的视频异常检测方法主要存在三个局限性：1）多数方法仅关注异常定位或事后描述，缺乏显式推理过程；2）缺乏风险意识和决策导向的解释能力；3）缺少支持结构化多阶段推理的任务定义和数据集。这些局限性阻碍了MLLMs在视频异常理解领域的深度应用。

Method: 本研究提出了三个主要创新：1）定义了新的视频异常推理(VAR)任务，要求模型进行渐进式多阶段推理；2）构建了包含8,641个视频、超过50,000个样本的大型数据集，采用结构化感知-认知-行动思维链(PerCoAct-CoT)进行标注；3）提出了异常感知组相对策略优化方法以增强弱监督下的推理可靠性，并开发了端到端的VAR模型Vad-R1-Plus，支持自适应分层推理和风险感知决策。

Result: 实验结果验证了所提方法和基准的有效性：1）Vad-R1-Plus模型在VAR任务上表现优异，超越了现有开源和专有基线模型；2）提出的结构化数据集能够系统评估多阶段推理能力；3）异常感知组相对策略优化显著提升了模型在弱监督条件下的推理可靠性。

Conclusion: 本研究成功定义了视频异常推理(VAR)任务，建立了大型结构化数据集，并开发了有效的VAR模型。工作将视频异常分析从传统的描述性理解推进到结构化推理阶段，为MLLMs在视频异常领域的深度应用提供了新范式。未来的工作可以进一步扩展推理深度和应用场景。

Abstract: Recent progress in reasoning capabilities of Multimodal Large Language Models(MLLMs) has highlighted their potential for performing complex video understanding tasks. However, in the domain of Video Anomaly Detection and Understanding (VAD&U), existing MLLM-based methods are largely limited to anomaly localization or post-hoc description, lacking explicit reasoning processes, risk awareness, and decision-oriented interpretation. To address this gap, we define a new task termed Video Anomaly Reasoning (VAR), which elevates video anomaly analysis from descriptive understanding to structured, multi-stage reasoning. VAR explicitly requires models to perform progressive reasoning over anomalous events before answering anomaly-related questions, encompassing visual perception, causal interpretation, and risk-aware decision making. To support this task, we present a new dataset with 8,641 videos, where each video is annotated with diverse question types corresponding to different reasoning depths, totaling more than 50,000 samples, making it one of the largest datasets for video anomaly. The annotations are based on a structured Perception-Cognition-Action Chain-of-Thought (PerCoAct-CoT), which formalizes domain-specific reasoning priors for video anomaly understanding. This design enables systematic evaluation of multi-stage and adaptive anomaly reasoning. In addition, we propose Anomaly-Aware Group Relative Policy Optimization to further enhance reasoning reliability under weak supervision. Building upon the proposed task and dataset, we develop an end-to-end MLLM-based VAR model termed Vad-R1-Plus, which supports adaptive hierarchical reasoning and risk-aware decision making. Extensive experiments demonstrate that the proposed benchmark and method effectively advance the reasoning capabilities of MLLMs on VAR tasks, outperforming both open-source and proprietary baselines.

</details>


### [20] [RAG-3DSG: Enhancing 3D Scene Graphs with Re-Shot Guided Retrieval-Augmented Generation](https://arxiv.org/abs/2601.10168)
*Yue Chang,Rufeng Chen,Zhaofan Zhang,Yi Chen,Sihong Xie*

Main category: cs.CV

Score: 4/5 | Tags: 3D Scene Understanding, Computer Vision, Scene Graph, Robotics, Object Recognition, Multi-view, Uncertainty Estimation, Retrieval-Augmented Generation

Recommendation: 该论文针对3D场景图生成的实际问题提出了创新性解决方案，同时关注准确性和效率两个维度。实验结果显示其方法在节点标注准确率和计算速度方面均有显著提升，具有很好的实用价值。不过，需要更多基准数据集验证其泛化能力。

TL;DR: 开放词汇3D场景图生成可以通过利用结构化的语义表征来增强机器人领域的各种下游任务，如操作和导航。3D场景图由场景的多个图像构建而成，其中对象表示为节点，关系表示为边。然而，现有的开放词汇3D场景图生成方法同时存在对象级识别准确率和速度较低的问题，这主要由于受限的视角、遮挡和冗余的表面密度所导致。为了解决这些挑战，我们提出RAG-3DSG，通过重拍引导的不确定性估计来减轻聚合噪声，并通过可靠的低不确定性对象支持对象级的检索增强生成。此外，我们提出了一种动态下采样映射策略，以自适应粒度加速跨图像对象聚合。在Replica数据集上的实验表明，RAG-3DSG显著提高了3D场景图生成中的节点标注准确率，同时将映射时间比原始版本减少了三分之二。


<details>
  <summary>Details</summary>
Motivation: 现有开放词汇3D场景图生成方法存在对象识别准确率低和速度慢的问题，主要受限于视角约束、遮挡和表面密度冗余。这些问题阻碍了3D场景图在机器人操作和导航等下游任务中的有效应用。因此，需要一种能够同时提升准确性和效率的解决方案。

Method: RAG-3DSG采用两种关键技术：1）重拍引导的不确定性估计，通过重新拍摄视角来评估对象识别的不确定性，从而减轻聚合过程中的噪声；2）对象级检索增强生成，利用可靠的低不确定性对象来增强场景图生成。同时提出动态下采样映射策略，自适应调整粒度以加速跨图像对象聚合过程。

Result: 在Replica数据集上的实验表明，RAG-3DSG在3D场景图生成任务中显著提升了节点标注的准确率。同时，该方法将映射时间减少了三分之二，相比于原始版本实现了效率的大幅提升。

Conclusion: RAG-3DSG通过结合不确定性估计和检索增强生成，有效解决了开放词汇3D场景图生成中的准确性和效率问题。该方法不仅提高了对象识别精度，还大幅减少了计算时间，为机器人应用中的结构化语义表征提供了更实用的解决方案。

Abstract: Open-vocabulary 3D Scene Graph (3DSG) generation can enhance various downstream tasks in robotics, such as manipulation and navigation, by leveraging structured semantic representations. A 3DSG is constructed from multiple images of a scene, where objects are represented as nodes and relationships as edges. However, existing works for open-vocabulary 3DSG generation suffer from both low object-level recognition accuracy and speed, mainly due to constrained viewpoints, occlusions, and redundant surface density. To address these challenges, we propose RAG-3DSG to mitigate aggregation noise through re-shot guided uncertainty estimation and support object-level Retrieval-Augmented Generation (RAG) via reliable low-uncertainty objects. Furthermore, we propose a dynamic downsample-mapping strategy to accelerate cross-image object aggregation with adaptive granularity. Experiments on Replica dataset demonstrate that RAG-3DSG significantly improves node captioning accuracy in 3DSG generation while reducing the mapping time by two-thirds compared to the vanilla version.

</details>


### [21] [Beyond Inpainting: Unleash 3D Understanding for Precise Camera-Controlled Video Generation](https://arxiv.org/abs/2601.10214)
*Dong-Yu Chen,Yixin Guo,Shuojin Yang,Tai-Jiang Mu,Shi-Min Hu*

Main category: cs.CV

Score: 5/5 | Tags: Video Generation, Camera Control, Diffusion Models, 3D Understanding, Depth Estimation, Neural Rendering, Computer Vision

Recommendation: 这篇论文提出了一个创新性的解决方案，解决了视频生成中相机控制的固有问题。DepthDirector通过巧妙的视图-内容双流设计，既利用了视频扩散模型的3D理解能力，又实现了精确的相机控制。方法设计合理，实验充分，构建的大规模数据集也具有很高的实用价值。该研究对于视频编辑、虚拟现实和内容创作领域都有重要贡献。

TL;DR: 相机控制在条件视频生成中已被广泛研究；然而，在执行精确改变相机轨迹的同时忠实地保留视频内容仍然是一项具有挑战性的任务。实现精确相机控制的主流方法是将3D表示根据目标轨迹进行变形。然而，这种方法未能充分利用视频扩散模型（VDMs）的3D先验，并经常陷入修复陷阱，导致主体不一致和生成质量下降。为了解决这个问题，我们提出了DepthDirector，一个具有精确相机可控性的视频重新渲染框架。通过利用来自显式3D表示的深度视频作为相机控制指导，我们的方法能够忠实地在新型相机轨迹下再现输入视频的动态场景。具体而言，我们设计了一个视图-内容双流条件机制，将源视频和根据目标视点渲染的变形深度序列同时注入预训练的视频生成模型。这种几何指导信号使VDMs能够理解相机运动并利用其3D理解能力，从而促进精确的相机控制和一致的内容生成。接下来，我们引入一个轻量级的基于LoRA的视频扩散适配器来训练我们的框架，完全保留VDMs的知识先验。此外，我们使用Unreal Engine 5构建了一个名为MultiCam-WarpData的大规模多相机同步数据集，包含1K个动态场景中的8K个视频。广泛的实验表明，DepthDirector在相机可控性和视觉质量方面均优于现有方法。我们的代码和数据集将公开发布。


<details>
  <summary>Details</summary>
Motivation: 当前的视频生成方法在实现精确相机控制时面临两个主要问题：1）基于3D表示变形的方法未能充分利用视频扩散模型的3D先验知识；2）这些方法容易陷入"修复陷阱"，导致生成内容与原始视频不一致且质量下降。因此，需要一种既能精确控制相机轨迹，又能忠实地保留原始视频内容的方法。

Method: DepthDirector采用了一个视频重新渲染框架，核心创新包括：1）视图-内容双流条件机制：同时将源视频和根据目标相机轨迹渲染的深度序列注入预训练的视频扩散模型；2）利用显式3D表示生成的深度视频作为几何指导信号；3）设计轻量级的基于LoRA的视频扩散适配器进行训练，以保留模型的先验知识；4）构建大规模多相机同步数据集MultiCam-WarpData用于训练和评估。

Result: DepthDirector在相机可控性和视觉质量方面均表现出优越性能：1）能够精确地控制相机轨迹变化；2）生成的视频内容与源视频高度一致，避免了修复陷阱导致的主体不一致问题；3）视觉质量优于现有的相机控制方法；4）构建的数据集包含1K动态场景的8K视频，为相关研究提供了有价值的资源。

Conclusion: DepthDirector通过利用深度视频作为几何指导信号和视图-内容双流条件机制，成功解决了视频生成中精确相机控制与内容保持之间的权衡问题。该方法既保留了视频扩散模型的3D理解能力，又实现了精确的相机轨迹控制，为动态场景的相机可控重新渲染提供了有效的解决方案。

Abstract: Camera control has been extensively studied in conditioned video generation; however, performing precisely altering the camera trajectories while faithfully preserving the video content remains a challenging task. The mainstream approach to achieving precise camera control is warping a 3D representation according to the target trajectory. However, such methods fail to fully leverage the 3D priors of video diffusion models (VDMs) and often fall into the Inpainting Trap, resulting in subject inconsistency and degraded generation quality. To address this problem, we propose DepthDirector, a video re-rendering framework with precise camera controllability. By leveraging the depth video from explicit 3D representation as camera-control guidance, our method can faithfully reproduce the dynamic scene of an input video under novel camera trajectories. Specifically, we design a View-Content Dual-Stream Condition mechanism that injects both the source video and the warped depth sequence rendered under the target viewpoint into the pretrained video generation model. This geometric guidance signal enables VDMs to comprehend camera movements and leverage their 3D understanding capabilities, thereby facilitating precise camera control and consistent content generation. Next, we introduce a lightweight LoRA-based video diffusion adapter to train our framework, fully preserving the knowledge priors of VDMs. Additionally, we construct a large-scale multi-camera synchronized dataset named MultiCam-WarpData using Unreal Engine 5, containing 8K videos across 1K dynamic scenes. Extensive experiments show that DepthDirector outperforms existing methods in both camera controllability and visual quality. Our code and dataset will be publicly available.

</details>


### [22] [Optimizing Multimodal LLMs for Egocentric Video Understanding: A Solution for the HD-EPIC VQA Challenge](https://arxiv.org/abs/2601.10228)
*Sicheng Yang,Yukai Huang,Shitong Sun,Weitong Cai,Jiankang Deng,Jifei Song,Zhensong Zhang*

Main category: cs.CV

Score: 4/5 | Tags: MLLM, VideoQA, Egocentric-Vision, Temporal-Reasoning, Chain-of-Thought, Fine-tuning, Multimodal-LLM, Qwen2.5-VL

Recommendation: 这篇论文值得推荐，原因在于：1) 针对视频理解的实际痛点提出了系统性的解决方案；2) 创新性地引入了时序思维链提示技术；3) 提供了完整的开源实现，便于复现和应用；4) 在HD-EPIC VQA这一具有挑战性的基准上取得了实质性进展；5) 强调了端到端流程优化的重要性，为后续研究提供了有价值的思路。不足之处在于未与其他最新方法进行广泛比较，且准确率提升的具体贡献分析可以更详细。

TL;DR: 多模态大语言模型（MLLMs）在处理如HD-EPIC VQA这类复杂的视频问答基准测试时面临挑战，主要是由于模糊的查询/选项、较差的长距离时序推理以及非标准化的输出。我们提出了一种集成框架，包含查询/选择预处理、特定领域Qwen2.5-VL微调、新颖的时序思维链（T-CoT）提示用于多步推理以及稳健的后处理。该系统在HD-EPIC VQA上实现了41.6%的准确率，突显了在要求严苛的视频理解任务中进行整体流程优化的必要性。我们的代码和微调模型可在https://github.com/YoungSeng/Egocentric-Co-Pilot获取。


<details>
  <summary>Details</summary>
Motivation: 多模态大语言模型在复杂视频问答任务中表现不佳，特别是在HD-EPIC VQA等基准测试上。这些问题主要源于三个关键挑战：1) 模糊的查询和选项导致模型理解困难；2) 缺乏有效的长距离时序推理能力；3) 输出格式不标准化，难以进行准确评估。因此，需要一个系统性的解决方案来全面提升视频理解性能。

Method: 该方法提出了一个集成的四步框架：1) 查询/选择预处理：优化输入数据的表述和清晰度；2) 特定领域模型微调：使用Qwen2.5-VL模型在相关领域数据进行微调；3) 时序思维链（T-CoT）提示：设计新型提示策略支持多步时序推理；4) 稳健的后处理：对模型输出进行标准化处理以提高评估准确性。这种端到端的优化策略全面解决了视频理解中的多个瓶颈问题。

Result: 该框架在HD-EPIC VQA基准测试中取得了41.6%的准确率。这一结果显著提升了多模态大语言模型在复杂视频问答任务上的性能。通过开源代码和微调模型，该研究为视频理解领域提供了可复现的解决方案，并展示了整体流程优化的重要性。

Conclusion: 研究表明，针对复杂视频问答任务，单纯的模型改进是不够的，需要构建包括预处理、模型优化、推理增强和后处理在内的完整系统框架。时序思维链提示策略能有效提升长距离时序推理能力，而特定领域微调则能改善模型对专业知识的理解。这项工作为视频理解研究提供了重要的实践指导和技术路线。

Abstract: Multimodal Large Language Models (MLLMs) struggle with complex video QA benchmarks like HD-EPIC VQA due to ambiguous queries/options, poor long-range temporal reasoning, and non-standardized outputs. We propose a framework integrating query/choice pre-processing, domain-specific Qwen2.5-VL fine-tuning, a novel Temporal Chain-of-Thought (T-CoT) prompting for multi-step reasoning, and robust post-processing. This system achieves 41.6% accuracy on HD-EPIC VQA, highlighting the need for holistic pipeline optimization in demanding video understanding. Our code, fine-tuned models are available at https://github.com/YoungSeng/Egocentric-Co-Pilot.

</details>


### [23] [Attend to what I say: Highlighting relevant content on slides](https://arxiv.org/abs/2601.10244)
*Megha Mariam K M,C. V. Jawahar*

Main category: cs.CV

Score: 4/5 | Tags: 多媒体分析, 计算机视觉, NLP, 教育技术, 人机交互, 信息同步, 注意力引导

Recommendation: 推荐理由：该研究针对实际存在的认知负担问题提出了创新解决方案，具有明确的应用价值。方法结合了计算机视觉和NLP技术，解决了多媒体内容中的同步问题。提供公开的代码和数据集，便于复现和后续研究。虽然在技术深度上可能不够突出，但对于教育技术和人机交互领域具有重要参考价值。

TL;DR: 想象一下坐在演示现场，试图同时跟上演讲者讲解并扫描幻灯片寻找相关信息。虽然整个幻灯片都可见，但识别相关区域可能具有挑战性。当你聚焦于幻灯片的某一部分时，演讲者已开始新的句子，使你视觉上匆忙追赶。这种持续的来回切换造成了所听内容与最重要视觉元素之间的脱节，使得难以吸收关键细节，尤其是在快速节奏或内容密集的演示中，如会议演讲。这需要理解幻灯片，包括文本、图形和布局。我们介绍了一种方法，能基于演讲者的叙述自动识别并高亮显示最相关的幻灯片区域。通过分析口语内容并将其与幻灯片中的文本或图形元素匹配，我们的方法确保了听众听到的内容与他们需要注意的内容之间更好的同步。我们探索了解决此问题的不同方法，并评估了它们的成功和失败案例。分析多媒体文档正成为无缝理解内容丰富视频（如教育视频和会议演讲）的关键要求，通过减少认知负担和提高理解力。代码和数据集可在 https://github.com/meghamariamkm2002/Slide_Highlight 获取。


<details>
  <summary>Details</summary>
Motivation: 当前在观看演示或会议演讲时，听众面临着听觉信息和视觉信息之间的同步问题。演讲者的口头叙述与幻灯片的视觉内容之间存在脱节，导致听众需要在幻灯片中寻找相关信息时产生认知负担，尤其是在快速节奏的演示中。这种不匹配使得关键细节难以被有效吸收，影响理解效果。

Method: 该方法通过分析演讲者的口语内容，并将其与幻灯片中的文本或图形元素进行匹配，自动识别并高亮显示最相关的幻灯片区域。研究者探索了多种解决这一问题的方法，并评估了各种方法的成功和失败案例。该方法考虑了幻灯片的多模态特征，包括文本、图形和布局结构。

Result: 研究者实现了自动化的幻灯片区域高亮系统，能够根据演讲者叙述动态识别相关区域。通过评估不同方法的性能，分析了成功和失败的案例。该工作提供了一个可用的代码库和数据集，支持相关研究的进一步发展。

Conclusion: 这项工作为解决演示内容中听觉和视觉信息同步问题提供了一种有效方法。通过自动高亮相关幻灯片区域，可以减少听众的认知负担，提高对内容的理解和吸收效率。该研究为多媒体文档分析领域，特别是教育视频和会议演讲的理解提供了重要技术基础。

Abstract: Imagine sitting in a presentation, trying to follow the speaker while simultaneously scanning the slides for relevant information. While the entire slide is visible, identifying the relevant regions can be challenging. As you focus on one part of the slide, the speaker moves on to a new sentence, leaving you scrambling to catch up visually. This constant back-and-forth creates a disconnect between what is being said and the most important visual elements, making it hard to absorb key details, especially in fast-paced or content-heavy presentations such as conference talks. This requires an understanding of slides, including text, graphics, and layout. We introduce a method that automatically identifies and highlights the most relevant slide regions based on the speaker's narrative. By analyzing spoken content and matching it with textual or graphical elements in the slides, our approach ensures better synchronization between what listeners hear and what they need to attend to. We explore different ways of solving this problem and assess their success and failure cases. Analyzing multimedia documents is emerging as a key requirement for seamless understanding of content-rich videos, such as educational videos and conference talks, by reducing cognitive strain and improving comprehension. Code and dataset are available at: https://github.com/meghamariamkm2002/Slide_Highlight

</details>


### [24] [Hierarchical Refinement of Universal Multimodal Attacks on Vision-Language Models](https://arxiv.org/abs/2601.10313)
*Peng-Fei Zhang,Zi Huang*

Main category: cs.CV

Score: 4/5 | Tags: Adversarial Attack, Vision-Language Pretraining, Multimodal Learning, Security, Universal Perturbation, Computer Vision, NLP

Recommendation: 这篇论文提出了一种创新的通用多模态攻击框架，解决了现有VLP模型对抗攻击的计算效率问题。方法设计系统且创新，特别是在图像扰动分解、时间层次优化和文本重要性度量方面有独到之处。实验充分验证了方法在各种场景下的有效性，对理解VLP模型的脆弱性和安全性评估具有重要价值。

TL;DR: 现有的视觉语言预训练（VLP）模型对抗攻击大多是样本特定的，当扩展到大型数据集或新场景时会产生大量计算开销。为克服这一限制，我们提出分层细化攻击（HRA），一种针对VLP模型的多模态通用攻击框架。HRA在样本级别和优化级别细化通用对抗扰动（UAPs）。对于图像模态，我们将对抗样本分解为干净图像和扰动，使每个组件能够独立处理，以更有效地破坏跨模态对齐。我们进一步引入ScMix增强策略，多样化视觉上下文并增强UAPs的全局和局部效用，从而减少对虚假特征的依赖。此外，我们通过利用历史和估计未来梯度的时间层次结构来优化路径，避免局部极小值并稳定通用扰动学习。对于文本模态，HRA通过结合句子内和句子间重要性度量识别全局有影响力的词汇，并将这些词汇用作通用文本扰动。在各种下游任务、VLP模型和数据集上的大量实验证明了所提出的通用多模态攻击的优越性。


<details>
  <summary>Details</summary>
Motivation: 现有VLP模型的对抗攻击大多是样本特定的，这种攻击方式在扩展到大型数据集或新场景时会产生高昂的计算成本。为了解决这一问题，需要开发一种通用的多模态攻击框架，能够同时适用于大量样本，减少计算开销并提高攻击效率。

Method: HRA提出分层细化攻击框架，包含以下关键技术：1）对于图像模态，将对抗样本分解为干净图像和扰动进行独立处理；2）引入ScMix增强策略，通过多样化视觉上下文增强UAPs的全局和局部效用；3）使用历史梯度和估计未来梯度的时间层次结构优化路径，避免局部极小值；4）对于文本模态，结合句子内和句子间重要性度量识别全局有影响力词汇作为通用扰动。

Result: 在各种下游任务、不同VLP模型和多个数据集上的实验表明，HRA在攻击效果上显著优于现有方法。该通用攻击框架不仅有效破坏了跨模态对齐，而且在计算效率方面也表现出色，能够扩展到大型数据集。

Conclusion: HRA提出了一种有效的通用多模态攻击框架，通过在样本级别和优化级别进行分层细化，成功克服了现有样本特定攻击的计算局限性。该方法在图像和文本模态上都实现了高效扰动，为VLP模型的安全性评估提供了有力工具。

Abstract: Existing adversarial attacks for VLP models are mostly sample-specific, resulting in substantial computational overhead when scaled to large datasets or new scenarios. To overcome this limitation, we propose Hierarchical Refinement Attack (HRA), a multimodal universal attack framework for VLP models. HRA refines universal adversarial perturbations (UAPs) at both the sample level and the optimization level. For the image modality, we disentangle adversarial examples into clean images and perturbations, allowing each component to be handled independently for more effective disruption of cross-modal alignment. We further introduce a ScMix augmentation strategy that diversifies visual contexts and strengthens both global and local utility of UAPs, thereby reducing reliance on spurious features. In addition, we refine the optimization path by leveraging a temporal hierarchy of historical and estimated future gradients to avoid local minima and stabilize universal perturbation learning. For the text modality, HRA identifies globally influential words by combining intra-sentence and inter-sentence importance measures, and subsequently utilizes these words as universal text perturbations. Extensive experiments across various downstream tasks, VLP models, and datasets demonstrate the superiority of the proposed universal multimodal attacks.

</details>


### [25] [ROMA: Real-time Omni-Multimodal Assistant with Interactive Streaming Understanding](https://arxiv.org/abs/2601.10323)
*Xueyun Tian,Wei Li,Bingbing Xu,Heng Dong,Yuanzhuo Wang,Huawei Shen*

Main category: cs.CV

Score: 4/5 | Tags: LLM, Multimodal, Audio-Video, Real-time, Streaming, Proactive, Reactive, Architecture

Recommendation: 该论文具有较高推荐价值：1）针对流式音频-视频理解这一实际应用场景提出了创新解决方案；2）提出的同步多模态单元和说话头部机制具有技术新颖性；3）在12个基准测试上的全面验证增强了结果可信度；4）在主动任务上实现了SOTA性能。评分为4分主要考虑到该工作虽然在架构设计上有创新，但相对于其他前沿多模态研究，理论深度略显不足。

TL;DR: 最近的Omni-multimodal大语言模型在统一音频、视觉和文本建模方面显示出潜力。然而，流式音频-视频理解仍然具有挑战性，因为现有方法存在能力不连贯的问题：它们通常表现出不完整的模态支持或缺乏自主主动监控能力。为了解决这个问题，我们提出了ROMA，一个用于统一反应式和主动式交互的实时全模态助手。ROMA将连续输入处理为同步的多模态单元，将密集音频与离散视频帧对齐以处理粒度不匹配问题。为了实现在线决策，我们引入了轻量级说话头部，将响应启动与生成解耦，确保精确触发而无任务冲突。我们使用精心策划的流式数据集和两阶段课程训练ROMA，逐步优化流式格式适应和主动响应能力。为了标准化碎片化的评估环境，我们将不同的基准重组为一个统一的套件，涵盖主动（警报、叙述）和反应（问答）设置。在12个基准上的广泛实验表明，ROMA在主动任务上实现了最先进的性能，同时在反应设置中具有竞争力，验证了其在统一实时全模态理解中的稳健性。


<details>
  <summary>Details</summary>
Motivation: 现有全多模态大语言模型在处理流式音频-视频理解时面临两个主要挑战：1）能力不连贯问题 - 要么模态支持不完整，要么缺乏自主主动监控能力；2）实时流式处理中的粒度不匹配问题。为解决这些局限性，研究者们提出了ROMA，旨在构建一个能够统一处理反应式和主动式交互的实时全模态助手。

Method: ROMA采用了一种创新的流式处理架构：1）将连续输入处理为同步的多模态单元，通过对齐密集音频和离散视频帧来解决粒度不匹配问题；2）引入了轻量级说话头部机制，将响应启动与生成过程解耦，确保精确触发而无任务冲突；3）采用两阶段课程学习策略进行训练，第一阶段优化流式格式适应，第二阶段专注于主动响应能力的提升。

Result: 在12个不同基准测试上的广泛实验表明，ROMA在主动任务（如警报生成和叙事描述）上实现了最先进的性能，同时在反应式任务（如问答）上保持竞争力。实验结果验证了ROMA在统一实时全模态理解方面的稳健性和有效性。

Conclusion: ROMA是一个具有创新性的实时全模态助手，成功解决了流式音频-视频理解中的关键挑战。它通过同步多模态单元处理、轻量级说话头部机制和两阶段课程学习，实现了统一反应式和主动式交互能力。该模型在主动任务上的优异表现证明了其在实时监控和交互应用中的实用价值。

Abstract: Recent Omni-multimodal Large Language Models show promise in unified audio, vision, and text modeling. However, streaming audio-video understanding remains challenging, as existing approaches suffer from disjointed capabilities: they typically exhibit incomplete modality support or lack autonomous proactive monitoring. To address this, we present ROMA, a real-time omni-multimodal assistant for unified reactive and proactive interaction. ROMA processes continuous inputs as synchronized multimodal units, aligning dense audio with discrete video frames to handle granularity mismatches. For online decision-making, we introduce a lightweight speak head that decouples response initiation from generation to ensure precise triggering without task conflict. We train ROMA with a curated streaming dataset and a two-stage curriculum that progressively optimizes for streaming format adaptation and proactive responsiveness. To standardize the fragmented evaluation landscape, we reorganize diverse benchmarks into a unified suite covering both proactive (alert, narration) and reactive (QA) settings. Extensive experiments across 12 benchmarks demonstrate ROMA achieves state-of-the-art performance on proactive tasks while competitive in reactive settings, validating its robustness in unified real-time omni-multimodal understanding.

</details>


### [26] [Think-Then-Generate: Reasoning-Aware Text-to-Image Diffusion with LLM Encoders](https://arxiv.org/abs/2601.10332)
*Siqi Kou,Jiachun Jin,Zetong Zhou,Ye Ma,Yugang Wang,Quan Chen,Peng Jiang,Xiao Yang,Jun Zhu,Kai Yu,Zhijie Deng*

Main category: cs.CV

Score: 4/5 | Tags: LLM, Diffusion Models, Text-to-Image, Reasoning, Vision, Multimodal AI, Generation

Recommendation: 该论文提出了创新的"先思考再生成"范式，解决了现有文本到图像扩散模型缺乏深度推理能力的问题。方法具有系统性和创新性，实验结果显著优于现有方法，特别是WISE得分接近GPT-4水平。该工作为多模态AI发展提供了有意义的思路，对理解如何有效整合LLM推理能力和图像生成模型具有重要价值。

TL;DR: 最近，文本到图像扩散模型在从多样文本提示生成高质量视觉合成方面取得了进展。然而，大多数现有的文本到图像扩散模型，即使配备了基于大语言模型的文本编码器，仍停留在文本-像素映射器的阶段——它们仅将大语言模型用作文本编码器，而未利用其内在的推理能力来推断给定文本提示应可视化呈现的内容。为了超越这种字面生成，我们提出了"先思考再生成"范式，即鼓励基于大语言模型的文本编码器对原始用户提示进行推理和重写；重写后的提示状态随后用作扩散条件。为实现这一目标，我们首先通过轻量级监督微调过程激活大语言模型编码器的"先思考再重写"模式。随后，通过双GRPO方法对LLM编码器和扩散主干进行联合优化，以确保对上下文的忠实推理和对语义的准确渲染。具体而言，文本编码器通过基于图像的奖励进行强化，以推断和回忆世界知识，而扩散主干则被推动生成语义一致且视觉连贯的图像。实验结果表明，在基于推理的图像生成和编辑基准测试中，事实一致性、语义对齐和视觉真实性方面均取得了显著改进，WISE得分达到0.79，几乎与GPT-4持平。我们的成果为构建具有推理、表达和演示能力的下一代统一模型迈出了有希望的一步。


<details>
  <summary>Details</summary>
Motivation: 现有文本到图像扩散模型主要作为"文本-像素映射器"，即使配备大语言模型文本编码器，也仅将其用作编码器而未充分利用其推理能力。这导致模型生成内容往往局限于字面理解，缺乏对复杂文本提示的深度推理和语义理解，无法生成更具深度和一致性的视觉内容。

Method: 论文提出"先思考再生成"范式，包含两个核心步骤：首先通过轻量级监督微调激活LLM编码器的"先思考再重写"能力，使LLM能够对原始用户提示进行推理和重写；随后采用双GRPO方法对LLM编码器和扩散主干进行联合优化。具体来说，文本编码器通过图像导向的奖励机制强化其推断和回忆世界知识的能力，而扩散主干则被优化以生成语义一致且视觉连贯的图像。

Result: 实验显示，该方法在基于推理的图像生成和编辑基准测试中取得了显著改进，WISE得分达到0.79，几乎与GPT-4性能持平。在事实一致性、语义对齐和视觉真实性方面均有大幅提升，表明模型能够更好地理解复杂提示并生成符合语义内容的视觉图像。

Conclusion: T2G范式通过激活LLM编码器的推理能力并联合优化扩散模型，显著提升了文本到图像生成的语义理解和视觉一致性。这一成果为实现具有推理、表达和演示能力的下一代统一模型提供了有希望的途径，标志着从简单的文本-像素映射向智能图像生成的转变。

Abstract: Recent progress in text-to-image (T2I) diffusion models (DMs) has enabled high-quality visual synthesis from diverse textual prompts. Yet, most existing T2I DMs, even those equipped with large language model (LLM)-based text encoders, remain text-pixel mappers -- they employ LLMs merely as text encoders, without leveraging their inherent reasoning capabilities to infer what should be visually depicted given the textual prompt. To move beyond such literal generation, we propose the think-then-generate (T2G) paradigm, where the LLM-based text encoder is encouraged to reason about and rewrite raw user prompts; the states of the rewritten prompts then serve as diffusion conditioning. To achieve this, we first activate the think-then-rewrite pattern of the LLM encoder with a lightweight supervised fine-tuning process. Subsequently, the LLM encoder and diffusion backbone are co-optimized to ensure faithful reasoning about the context and accurate rendering of the semantics via Dual-GRPO. In particular, the text encoder is reinforced using image-grounded rewards to infer and recall world knowledge, while the diffusion backbone is pushed to produce semantically consistent and visually coherent images. Experiments show substantial improvements in factual consistency, semantic alignment, and visual realism across reasoning-based image generation and editing benchmarks, achieving 0.79 on WISE score, nearly on par with GPT-4. Our results constitute a promising step toward next-generation unified models with reasoning, expression, and demonstration capacities.

</details>


### [27] [Fine-Grained Human Pose Editing Assessment via Layer-Selective MLLMs](https://arxiv.org/abs/2601.10369)
*Ningyu Sun,Zhaolin Cai,Zitong Xu,Peihang Chen,Huiyu Duan,Yichao Yan,Xiongkuo Min,Xiaokang Yang*

Main category: cs.CV

Score: 4/5 | Tags: 姿态编辑, AIGC, 评估基准, 多模态大模型, 计算机视觉, 生成模型, 质量评估

Recommendation: 这篇论文推荐指数为4分，主要原因是：1）针对文本引导人体姿态编辑这一重要且具有挑战性的领域提出了系统性解决方案；2）构建了大规模标准化的评估基准HPE-Bench，具有重要的数据集价值；3）创新性地提出了层选择性MLLM框架和LSA机制，技术方法具有先进性；4）同时解决了真实性检测和质量评估两个关键问题，应用前景广阔。唯一不足的是未提供与现有方法的详细对比实验结果。

TL;DR: 文本引导的人体姿态编辑在AIGC应用中获得了显著关注。然而，该领域仍受到结构异常和生成伪影的困扰。现有评估指标通常将真实性检测与质量评估分离，无法提供针对姿态特定不一致性的细粒度洞察。为解决这些限制，我们引入了HPE-Bench，这是一个包含来自17个最先进编辑模型的1,700个标准化样本的专业基准，提供真实性标签和多维质量评分。此外，我们提出了一个基于层选择性多模态大语言模型（MLLMs）的统一框架。通过采用对比LoRA调优和一种新颖的层敏感性分析（LSA）机制，我们确定了姿态评估的最佳特征层。我们的框架在真实性检测和多维质量回归方面均实现了卓越性能，有效地弥合了取证检测与质量评估之间的差距。


<details>
  <summary>Details</summary>
Motivation: 文本引导的人体姿态编辑在AIGC应用中虽然得到广泛应用，但当前仍面临结构异常和生成伪影等问题。现有评估方法存在局限性，通常将真实性检测与质量评估割裂开来，缺乏对姿态特定问题的细粒度分析能力。因此，需要建立一个更全面、精细的评估基准和统一框架来解决这些挑战。

Method: 本研究提出了HPE-Bench基准数据集，包含来自17个最先进编辑模型的1,700个标准化样本，每个样本都提供真实性标签和多维质量评分。同时，开发了基于层选择性多模态大语言模型（MLLMs）的统一评估框架。该方法采用对比LoRA调优技术，并引入新颖的层敏感性分析（LSA）机制，以确定用于姿态评估的最优特征层，从而实现对姿态编辑结果的综合评估。

Result: 该方法在两方面取得了显著成果：1）HPE-Bench提供了包含1,700个标准化样本的全面评估基准；2）提出的统一框架在真实性检测和多维质量回归任务上均表现出卓越性能。通过层敏感性分析机制成功识别了最适合姿态评估的特征层，有效弥合了取证检测与质量评估之间的鸿沟。

Conclusion: 本研究通过构建HPE-Bench基准和开发基于层选择性MLLMs的统一框架，成功解决了文本引导人体姿态编辑中评估不足的问题。提出的方法不仅提供了全面的评估数据集，还实现了高效的姿态编辑质量评估，为未来该领域的研究和应用提供了重要的技术基础。

Abstract: Text-guided human pose editing has gained significant traction in AIGC applications. However,it remains plagued by structural anomalies and generative artifacts. Existing evaluation metrics often isolate authenticity detection from quality assessment, failing to provide fine-grained insights into pose-specific inconsistencies. To address these limitations, we introduce HPE-Bench, a specialized benchmark comprising 1,700 standardized samples from 17 state-of-the-art editing models, offering both authenticity labels and multi-dimensional quality scores. Furthermore, we propose a unified framework based on layer-selective multimodal large language models (MLLMs). By employing contrastive LoRA tuning and a novel layer sensitivity analysis (LSA) mechanism, we identify the optimal feature layer for pose evaluation. Our framework achieves superior performance in both authenticity detection and multi-dimensional quality regression, effectively bridging the gap between forensic detection and quality assessment.

</details>


### [28] [Towards Efficient Low-rate Image Compression with Frequency-aware Diffusion Prior Refinement](https://arxiv.org/abs/2601.10373)
*Yichong Xia,Yimin Zhou,Jinpeng Wang,Bin Chen*

Main category: cs.CV

Score: 5/5 | Tags: Diffusion Models, Image Compression, Generative Priors, Low Bitrate, Computer Vision, Deep Learning

Recommendation: 这篇论文推荐度高的原因：1）解决了扩散模型在图像压缩应用中的核心瓶颈问题（采样速度慢）；2）提出创新的频率解耦注意力机制和一致性先验细化方法；3）取得了显著的性能提升（超过10倍加速和显著比特率节省）；4）无需更新骨干模型即可部署，具有很好的实用价值；5）方法设计巧妙，实验验证充分。

TL;DR: 近年来基于扩散模型的生成先验在极低比特率下实现了视觉上可信的图像压缩。然而，现有方法因碎片化的训练范式而面临采样过程缓慢和比特分配次优的问题。在本工作中，我们提出了通过一致性先验细化加速扩散基图像压缩（DiffCR）——一种新颖的高效高保真图像重建压缩框架。DiffCR的核心是频率感知跳过估计（FaSE）模块，该模块从预训练的潜在扩散模型中细化ε预测先验，并通过频率解耦注意力（FDA）在不同时间步对齐压缩潜变量。此外，轻量级一致性估计器通过保持扩散采样的语义轨迹实现快速两步解码。无需更新骨干扩散模型，DiffCR相比最先进的基于扩散的压缩基线实现了显著的比特率节省（27.2% BD-rate (LPIPS) 和 65.1% BD-rate (PSNR)）以及超过10倍的加速。


<details>
  <summary>Details</summary>
Motivation: 基于扩散模型的生成先验在极低比特率图像压缩方面取得了突破，但现有方法存在两个主要缺陷：1）采样过程缓慢，限制了实际应用；2）由于碎片化的训练范式导致比特分配不够优化。论文旨在开发一个高效且高保真的压缩框架，解决这些限制。

Method: DiffCR框架的核心创新包括：1）频率感知跳过估计（FaSE）模块：从预训练的潜在扩散模型中细化ε预测先验，通过频率解耦注意力（FDA）在不同时间步对齐压缩潜变量，实现更好的频率信息对齐；2）轻量级一致性估计器：保持扩散采样的语义轨迹，实现快速的两步解码过程。整个方法无需更新骨干扩散模型。

Result: DiffCR相比最先进的基于扩散的压缩基线取得了显著性能提升：1）比特率节省方面：在LPIPS指标上达到27.2% BD-rate节省，在PSNR指标上达到65.1% BD-rate节省；2）解码速度：实现超过10倍的加速；3）无需更新骨干模型即可实现这些改进。

Conclusion: DiffCR通过引入频率感知跳过估计和一致性先验细化，成功解决了扩散基图像压缩中的效率与质量权衡问题。该方法在保持高保真重建质量的同时实现了显著的比特率节省和解码加速，为实际部署扩散模型进行图像压缩提供了可行的解决方案。

Abstract: Recent advancements in diffusion-based generative priors have enabled visually plausible image compression at extremely low bit rates. However, existing approaches suffer from slow sampling processes and suboptimal bit allocation due to fragmented training paradigms. In this work, we propose Accelerate \textbf{Diff}usion-based Image Compression via \textbf{C}onsistency Prior \textbf{R}efinement (DiffCR), a novel compression framework for efficient and high-fidelity image reconstruction. At the heart of DiffCR is a Frequency-aware Skip Estimation (FaSE) module that refines the $ε$-prediction prior from a pre-trained latent diffusion model and aligns it with compressed latents at different timesteps via Frequency Decoupling Attention (FDA). Furthermore, a lightweight consistency estimator enables fast \textbf{two-step decoding} by preserving the semantic trajectory of diffusion sampling. Without updating the backbone diffusion model, DiffCR achieves substantial bitrate savings (27.2\% BD-rate (LPIPS) and 65.1\% BD-rate (PSNR)) and over $10\times$ speed-up compared to SOTA diffusion-based compression baselines.

</details>


### [29] [Global Context Compression with Interleaved Vision-Text Transformation](https://arxiv.org/abs/2601.10378)
*Dian Jiao,Jiaxin Duan,Shuai Zhao,Jiabing Leng,Yiran Zhang,Feng Huang*

Main category: cs.CV

Score: 4/5 | Tags: Vision-Language Model, Transformer, OCR, Compression, Efficiency Optimization, Text Generation

Recommendation: 这篇论文提出了一种创新的视觉-文本交错压缩方法，在保持性能的同时显著提升生成效率。其核心思想具有创新性，实验结果令人印象深刻（3倍速度提升、77%内存减少），并且探索了不同规模模型的可扩展性。然而，对于具体应用场景的泛化能力还需要更多验证。

TL;DR: 视觉语言模型在端到端OCR中的最新成就指出了文本信息低损耗压缩的新途径。这激发了早期研究将Transformer输入渲染为图像进行预填充，通过视觉编码有效减少token数量，从而缓解二次增长的Attention计算量。然而，这种部分压缩无法在token-by-token推理阶段节省计算或内存成本。本文研究了全局上下文压缩，在预填充和推理阶段均节省token。因此我们提出了VIST2，一种新颖的Transformer架构，在预上下文中间隔插入输入文本块及其视觉编码，同时仅依赖视觉token预测下一个文本token的分布。围绕这一思想，我们将文本块渲染为草图图像，并通过多阶段训练VIST2：从课程调度的预训练用于光学语言建模开始，随后进行模态交错指令微调。我们使用从0.6B到8B的VIST2家族进行了广泛的实验，探索了训练配方和超参数。在4倍压缩比下，所得模型在长文本写作任务上表现出显著优势，实现了平均3倍的首token生成加速、77%的内存使用减少和74%的FLOPS减少。我们的代码和数据集将公开以支持进一步研究。


<details>
  <summary>Details</summary>
Motivation: 传统视觉编码方法只能部分压缩文本信息，主要在预填充阶段减少token数量，但在token-by-token推理阶段无法节省计算和内存成本。因此需要探索全局上下文压缩方法，同时优化预填充和推理阶段的效率。

Method: 提出VIST2 Transformer架构，将输入文本块与其视觉编码交错排列，但仅使用视觉token作为预上下文来预测下一个文本token分布。具体方法包括：1) 将文本块渲染为草图图像；2) 多阶段训练：课程调度预训练用于光学语言建模，随后模态交错指令微调；3) 探索从0.6B到8B的不同规模模型。

Result: 在4倍压缩比下，VIST2模型在长文本写作任务上显著优于基线模型，实现了平均3倍的首token生成加速、77%的内存使用减少和74%的FLOPS减少。模型规模从0.6B到8B都表现出良好性能。

Conclusion: VIST2通过全局上下文压缩技术，成功在预填充和推理阶段同时减少token数量，显著提升了长文本任务的生成效率和资源利用率，为文本处理的高效压缩提供了新方向。

Abstract: Recent achievements of vision-language models in end-to-end OCR point to a new avenue for low-loss compression of textual information. This motivates earlier works that render the Transformer's input into images for prefilling, which effectively reduces the number of tokens through visual encoding, thereby alleviating the quadratically increased Attention computations. However, this partial compression fails to save computational or memory costs at token-by-token inference. In this paper, we investigate global context compression, which saves tokens at both prefilling and inference stages. Consequently, we propose VIST2, a novel Transformer that interleaves input text chunks alongside their visual encoding, while depending exclusively on visual tokens in the pre-context to predict the next text token distribution. Around this idea, we render text chunks into sketch images and train VIST2 in multiple stages, starting from curriculum-scheduled pretraining for optical language modeling, followed by modal-interleaved instruction tuning. We conduct extensive experiments using VIST2 families scaled from 0.6B to 8B to explore the training recipe and hyperparameters. With a 4$\times$ compression ratio, the resulting models demonstrate significant superiority over baselines on long writing tasks, achieving, on average, a 3$\times$ speedup in first-token generation, 77% reduction in memory usage, and 74% reduction in FLOPS. Our codes and datasets will be public to support further studies.

</details>


### [30] [Handling Missing Modalities in Multimodal Survival Prediction for Non-Small Cell Lung Cancer](https://arxiv.org/abs/2601.10386)
*Filippo Ruffini,Camillo Maria Caruso,Claudia Tacconi,Lorenzo Nibid,Francesca Miccolis,Marta Lovino,Carlo Greco,Edy Ippolito,Michele Fiore,Alessio Cortellini,Bruno Beomonte Zobel,Giuseppe Perrone,Bruno Vincenzi,Claudio Marrocco,Alessandro Bria,Elisa Ficarra,Sara Ramella,Valerio Guarrasi,Paolo Soda*

Main category: cs.CV

Score: 4/5 | Tags: 医疗AI, 多模态学习, 生存分析, 肺癌研究, 深度学习, 医学影像, 病理学, 临床预测

Recommendation: 推荐理由：本研究针对临床实践中多模态数据整合的关键挑战提出了创新解决方案。作者不仅开发了有效的多模态融合框架，还解决了模态缺失这一实际问题，具有很高的临床相关性。实验设计严谨，结果明确展示了方法的优势。特别是在不可切除的II-III期NSCLC患者群体中的性能表现，对改善这一难治患者群体的预后预测具有重要意义。不足之处在于缺少外部验证和在更大队列中的测试。

TL;DR: 准确预测非小细胞肺癌（NSCLC）的生存期需要整合异质性的临床、放射学和病理学信息。虽然多模态深度学习（MDL）为精准预后和生存预测提供了希望，但其临床应用受到小队列规模和缺失模态的严重限制，通常迫使采用完整病例过滤或激进插补。在本研究中，我们提出了一个缺失感知的多模态生存框架，整合了计算机断层扫描（CT）、全切片组织病理学（WSI）图像和结构化临床变量，用于不可切除的II-III期NSCLC的总生存期建模。通过利用基础模型（FM）进行模态特定特征提取和缺失感知编码策略，所提出的方法能够在自然不完整的模态配置下实现中间多模态融合。所提出的架构在设计上对缺失模态具有弹性，允许模型在不被迫在训练或推理过程中丢弃患者的情况下利用所有可用数据。实验结果表明，中间融合始终优于单模态基线以及早期和晚期融合策略，其中WSI和临床模态的融合实现了最强性能（73.30 C-index）。进一步的模态重要性分析揭示了自适应行为，即信息较少的模态（即CT模态）被自动降权，对最终生存预测的贡献较少。


<details>
  <summary>Details</summary>
Motivation: 非小细胞肺癌（NSCLC）的准确生存预测需要整合来自临床、放射学和病理学等多个来源的异质信息。传统多模态深度学习方法的临床应用受到两个主要限制：1）可用队列规模较小，导致模型训练困难；2）现实临床环境中常见模态缺失问题，迫使研究人员要么丢弃不完整病例，要么采用激进的插补方法，这两种做法都会影响模型的准确性和实用性。

Method: 本研究提出了一种缺失感知的多模态生存框架，主要包含以下核心组件：1）使用基础模型（FM）为不同模态（CT、WSI图像和临床变量）提取特定特征；2）设计缺失感知编码策略，使模型能够处理自然不完整的模态配置；3）采用中间融合方法集成不同模态的特征，而非早期或晚期融合；4）架构设计上具有弹性，能够处理缺失模态，无需在训练或推理过程中丢弃患者数据。

Result: 实验结果表明：1）提出的中间融合策略始终优于单模态基线以及早期和晚期融合方法；2）在不可切除的II-III期NSCLC患者中，WSI和临床模态的融合取得了最佳性能，C-index达到73.30；3）模型展现出自适应行为，能够自动调整不同模态的重要性权重，信息较少的CT模态被自动降权，对最终预测贡献较少；4）缺失感知架构允许利用所有可用数据，避免了因模态不完整而丢弃患者的问题。

Conclusion: 本研究提出的缺失感知多模态生存框架为NSCLC预后预测提供了一种有效的解决方案。该方法不仅能够处理临床实践中常见的模态缺失问题，还能通过中间融合策略有效整合多模态信息。特别值得注意的是，模型的自适应加权机制能够根据模态的信息价值自动调整其贡献度，这种设计提高了模型的鲁棒性和实用性。该框架为临床应用多模态深度学习进行精准生存预测提供了可行途径。

Abstract: Accurate survival prediction in Non-Small Cell Lung Cancer (NSCLC) requires the integration of heterogeneous clinical, radiological, and histopathological information. While Multimodal Deep Learning (MDL) offers a promises for precision prognosis and survival prediction, its clinical applicability is severely limited by small cohort sizes and the presence of missing modalities, often forcing complete-case filtering or aggressive imputation. In this work, we present a missing-aware multimodal survival framework that integrates Computed Tomography (CT), Whole-Slide Histopathology (WSI) Images, and structured clinical variables for overall survival modeling in unresectable stage II-III NSCLC. By leveraging Foundation Models (FM) for modality-specific feature extraction and a missing-aware encoding strategy, the proposed approach enables intermediate multimodal fusion under naturally incomplete modality profiles. The proposed architecture is resilient to missing modalities by design, allowing the model to utilize all available data without being forced to drop patients during training or inference. Experimental results demonstrate that intermediate fusion consistently outperforms unimodal baselines as well as early and late fusion strategies, with the strongest performance achieved by the fusion of WSI and clinical modalities (73.30 C-index). Further analyses of modality importance reveal an adaptive behavior in which less informative modalities, i.e., CT modality, are automatically down-weighted and contribute less to the final survival prediction.

</details>


### [31] [Multi-Temporal Frames Projection for Dynamic Processes Fusion in Fluorescence Microscopy](https://arxiv.org/abs/2601.10392)
*Hassan Eshkiki,Sarah Costa,Mostafa Mohammadpour,Farinaz Tanhaei,Christopher H. George,Fabio Caraffini*

Main category: cs.CV

Score: 4/5 | Tags: Computer Vision, Biomedical Imaging, Image Fusion, Microscopy, Image Processing, Time-series Analysis

Recommendation: 本文提出的方法针对荧光显微镜活体成像中的实际问题，提供了有效的解决方案。方法结合了不同计算机视觉领域的技术，具有创新性，且在挑战性数据集上取得了显著效果（细胞计数增加44%）。该框架具有广泛适用性，不仅限于生物医学成像，还可扩展到其他多时间图像融合领域。论文评估充分（111种配置），结果可靠，对相关领域研究人员具有重要参考价值。

TL;DR: 荧光显微镜广泛用于活体生物样品的分析；然而，所得记录的实用性通常受到噪声、时间变异性以及随时间振荡信号可视化不一致的限制。我们提出了一种独特的计算框架，将多个时间分辨帧的信息整合到单个高质量图像中，同时保留原始视频的基础生物学内容。我们通过大量配置（n=111）和在包含动态、异质且形态复杂的二维单层心肌细胞的挑战性数据集上评估了所提出的方法。结果表明，我们的框架由来自不同计算机视觉应用领域可解释技术的组合构成，能够生成保留并增强个体显微镜帧质量和信息的复合图像，与先前方法相比细胞计数平均增加了44%。所提出的流程适用于其他需要将多时间图像堆栈融合为高质量二维图像的成像领域，从而促进注释和下游分割。


<details>
  <summary>Details</summary>
Motivation: 荧光显微镜活体成像中存在噪声、时间变异性以及信号可视化不一致等问题，导致记录质量受限，影响后续分析和解读。需要一种能整合多时间帧信息、提升图像质量的创新方法。

Method: 本文提出一种独特的计算框架，结合了来自不同计算机视觉应用领域的可解释技术。该框架将多个时间分辨帧的信息整合为单个高质量复合图像，同时保持原始视频的生物学内容。方法在111种不同配置和包含动态、异质、形态复杂心肌细胞单层的挑战性数据集上进行了评估。

Result: 结果表明，该方法能生成保留并增强个体显微镜帧质量和信息的复合图像。与先前方法相比，实现了细胞计数平均44%的增加，显著提升了生物样本的分析能力。

Conclusion: 该计算框架能有效整合多时间分辨帧信息，生成高质量复合图像，提高荧光显微镜记录的实用性。该方法不仅适用于心肌细胞分析，还可扩展到其他需要多时间图像融合的成像领域，促进后续注释和分割任务。

Abstract: Fluorescence microscopy is widely employed for the analysis of living biological samples; however, the utility of the resulting recordings is frequently constrained by noise, temporal variability, and inconsistent visualisation of signals that oscillate over time. We present a unique computational framework that integrates information from multiple time-resolved frames into a single high-quality image, while preserving the underlying biological content of the original video. We evaluate the proposed method through an extensive number of configurations (n = 111) and on a challenging dataset comprising dynamic, heterogeneous, and morphologically complex 2D monolayers of cardiac cells. Results show that our framework, which consists of a combination of explainable techniques from different computer vision application fields, is capable of generating composite images that preserve and enhance the quality and information of individual microscopy frames, yielding 44% average increase in cell count compared to previous methods. The proposed pipeline is applicable to other imaging domains that require the fusion of multi-temporal image stacks into high-quality 2D images, thereby facilitating annotation and downstream segmentation.

</details>


### [32] [Lunar-G2R: Geometry-to-Reflectance Learning for High-Fidelity Lunar BRDF Estimation](https://arxiv.org/abs/2601.10449)
*Clementine Grethen,Nicolas Menga,Roland Brochard,Geraldine Morin,Simone Gasparini,Jeremy Lebreton,Manuel Sanchez Gestido*

Main category: cs.CV

Score: 4/5 | Tags: Computer Vision, Remote Sensing, Planetary Science, BRDF, 3D Reconstruction, Machine Learning, Rendering, Lunar Science

Recommendation: 该论文提出了创新性的几何到反射率学习框架，解决了行星表面高保真渲染的关键问题。方法具有实用价值，仅需DEM输入即可预测空间变化反射率，降低了数据获取需求。实验结果表明显著优于现有基线，且在计算机视觉、遥感、行星科学领域有广泛应用前景。主要扣分点在于仅针对月球表面，通用性有待进一步验证。

TL;DR: 我们解决了为复杂行星表面（如月球风化层）估计真实空间变化反射率的问题，这对高保真渲染和基于视觉的导航至关重要。现有的月球渲染流程依赖于简化或空间均匀的BRDF模型，其参数难以估计且无法捕捉局部反射率变化，限制了光度真实性。我们提出了Lunar-G2R，一种从几何到反射率的学习框架，直接从月球数字高程模型（DEM）预测空间变化的BRDF参数，无需在推理时使用多视图图像、受控照明或专用反射率捕获硬件。该方法利用U-Net结合可微分渲染进行训练，在已知观测和照明几何条件下，最小化真实轨道图像与基于物理的渲染之间的光度差异。在Tycho环形山地理保留区域的实验表明，我们的方法相比最先进的基线将光度误差降低了38%，同时获得了更高的PSNR和SSIM以及改进的感知相似性，捕捉了空间均匀模型所缺乏的精细尺度反射率变化。据我们所知，这是第一个直接从地形几何推断空间变化反射率模型的方法。


<details>
  <summary>Details</summary>
Motivation: 现有的月球渲染流程存在以下问题：1）依赖简化或空间均匀的BRDF模型，参数难以准确估计；2）无法捕捉月球表面复杂的局部反射率变化；3）限制了高保真渲染和基于视觉导航的精度。需要一种能够从地形几何直接推断空间变化反射率的方法，以提升月球渲染的真实性和实用性。

Method: Lunar-G2R框架采用以下方法：1）使用U-Net架构从月球数字高程模型（DEM）直接预测空间变化的BRDF参数；2）结合可微分渲染进行训练，最小化真实轨道图像与基于物理渲染之间的光度差异；3）在已知观测和照明几何条件下优化模型参数；4）推理阶段仅需DEM输入，无需多视图图像、受控照明或专用硬件。

Result: 实验结果表明：1）在Tycho环形山地理保留区域测试中，相比最先进的基线方法，光度误差降低了38%；2）获得更高的PSNR（峰值信噪比）和SSIM（结构相似性指数）；3）改进了感知相似性；4）成功捕捉到精细尺度的反射率变化，这些变化在空间均匀模型中无法体现。

Conclusion: Lunar-G2R是第一个直接从地形几何推断空间变化反射率模型的方法，显著提升了月球表面渲染的光度真实性和准确性。该方法不依赖多视图图像或专用硬件，仅通过DEM输入即可预测复杂的空间变化BRDF参数，为行星科学和空间任务中的高保真渲染提供了创新解决方案。

Abstract: We address the problem of estimating realistic, spatially varying reflectance for complex planetary surfaces such as the lunar regolith, which is critical for high-fidelity rendering and vision-based navigation. Existing lunar rendering pipelines rely on simplified or spatially uniform BRDF models whose parameters are difficult to estimate and fail to capture local reflectance variations, limiting photometric realism. We propose Lunar-G2R, a geometry-to-reflectance learning framework that predicts spatially varying BRDF parameters directly from a lunar digital elevation model (DEM), without requiring multi-view imagery, controlled illumination, or dedicated reflectance-capture hardware at inference time. The method leverages a U-Net trained with differentiable rendering to minimize photometric discrepancies between real orbital images and physically based renderings under known viewing and illumination geometry. Experiments on a geographically held-out region of the Tycho crater show that our approach reduces photometric error by 38 % compared to a state-of-the-art baseline, while achieving higher PSNR and SSIM and improved perceptual similarity, capturing fine-scale reflectance variations absent from spatially uniform models. To our knowledge, this is the first method to infer a spatially varying reflectance model directly from terrain geometry.

</details>


### [33] [Urban Socio-Semantic Segmentation with Vision-Language Reasoning](https://arxiv.org/abs/2601.10477)
*Yu Wang,Yi Wang,Rui Dai,Yujie Wang,Kaikui Liu,Xiangxiang Chu,Yansheng Li*

Main category: cs.CV

Score: 4/5 | Tags: Satellite Imagery, Semantic Segmentation, Vision-Language Models, Remote Sensing, Urban Analysis, Reinforcement Learning, Zero-shot Learning

Recommendation: 这篇论文推荐的主要原因是：1）解决了卫星图像分割中一个重要的实际问题——社会语义实体的识别；2）提出了创新的视觉-语言推理框架，结合了多模态理解和强化学习；3）创建了有价值的开源数据集；4）展示了强大的零样本泛化能力；5）具有实际应用价值，对智慧城市和城市规划等领域有重要意义。不足之处可能在于实际部署的复杂性和计算成本。

TL;DR: 作为人类活动的枢纽，城市表面包含丰富的语义实体。从卫星图像中分割这些多样的实体对于一系列下游应用至关重要。当前的先进分割模型可以可靠地分割由物理属性定义的实体（如建筑物、水体），但仍然难以处理社会定义类别（如学校、公园）。在本工作中，我们通过视觉-语言模型推理实现了社会语义分割。为此，我们引入了名为SocioSeg的城市社会语义分割数据集，这是一个包含卫星图像、数字地图以及按层次结构组织的社会语义实体像素级标签的新资源。此外，我们提出了一个名为SocioReasoner的新型视觉语言推理框架，该框架通过跨模态识别和多阶段推理来模拟人类识别和标注社会语义实体的过程。我们采用强化学习来优化这一不可微分的过程，并激发视觉-语言模型的推理能力。实验表明，我们的方法优于最先进的模型，并具有强大的零样本泛化能力。我们的数据集和代码可在https://github.com/AMAP-ML/SocioReasoner获取。


<details>
  <summary>Details</summary>
Motivation: 当前卫星图像分割模型在处理由物理属性定义的实体（如建筑物、水体）时表现良好，但在处理社会定义的语义类别（如学校、公园）时存在困难。这些社会语义实体在智慧城市、城市规划和社会科学研究中具有重要意义，但缺乏有效的自动分割方法。因此，需要开发能够理解社会语义类别的分割方法。

Method: 本研究提出了SocioReasoner框架，通过视觉-语言模型进行推理，模拟人类识别社会语义实体的过程。方法包括：1）构建SocioSeg数据集，包含卫星图像、数字地图和像素级社会语义标签；2）采用跨模态识别和多阶段推理机制；3）使用强化学习优化不可微分的推理过程，以激发视觉-语言模型的推理能力。框架能够处理社会语义实体的层次结构，并通过视觉-语言联合理解实现分割。

Result: 实验结果表明，SocioReasoner框架在SocioSeg数据集上显著优于当前最先进的分割模型。该框架不仅在社会语义分割任务上取得了更好的性能，还展示了强大的零样本泛化能力，能够处理未见过的社会语义类别。数据集和代码已开源，为相关研究提供了宝贵资源。

Conclusion: 本研究成功解决了城市社会语义实体分割的挑战，通过视觉-语言模型推理实现了对社会定义类别的有效识别。提出的SocioReasoner框架和SocioSeg数据集为卫星图像社会语义分割领域提供了新的解决方案和基准。强化学习优化的推理过程能够有效激发多模态模型的潜力，为零样本泛化能力提供了有力支持。

Abstract: As hubs of human activity, urban surfaces consist of a wealth of semantic entities. Segmenting these various entities from satellite imagery is crucial for a range of downstream applications. Current advanced segmentation models can reliably segment entities defined by physical attributes (e.g., buildings, water bodies) but still struggle with socially defined categories (e.g., schools, parks). In this work, we achieve socio-semantic segmentation by vision-language model reasoning. To facilitate this, we introduce the Urban Socio-Semantic Segmentation dataset named SocioSeg, a new resource comprising satellite imagery, digital maps, and pixel-level labels of social semantic entities organized in a hierarchical structure. Additionally, we propose a novel vision-language reasoning framework called SocioReasoner that simulates the human process of identifying and annotating social semantic entities via cross-modal recognition and multi-stage reasoning. We employ reinforcement learning to optimize this non-differentiable process and elicit the reasoning capabilities of the vision-language model. Experiments demonstrate our approach's gains over state-of-the-art models and strong zero-shot generalization. Our dataset and code are available in https://github.com/AMAP-ML/SocioReasoner.

</details>


### [34] [mergetune: Continued fine-tuning of vision-language models](https://arxiv.org/abs/2601.10497)
*Wenqing Wang,Da Li,Xiatian Zhu,Josef Kittler*

Main category: cs.CV

Score: 5/5 | Tags: Vision-Language Models, CLIP, Fine-tuning, Catastrophic Forgetting, Continual Learning, Linear Mode Connectivity, Prompt Learning

Recommendation: 该论文提出了一个创新的持续微调范式MERGETUNE，有效解决了视觉语言模型微调中的灾难性遗忘问题。方法具有模型无关性、不增加参数、无需架构更改等优点，实验结果显示显著的性能提升，在多任务泛化和鲁棒性方面都表现出色，对实际应用有重要价值。

TL;DR: 微调视觉语言模型(VLMs)如CLIP通常会导致预训练知识的灾难性遗忘。先前工作主要旨在缓解适应过程中的遗忘；然而，在这个过程中遗忘往往是不可避免的。我们引入了一个新的范式——持续微调(CFT)，旨在恢复零样本模型适应后已经失去的预训练知识。我们提出了一个简单、模型无关的CFT策略(命名为MERGETUNE)，由线性模式连通性(LMC)指导，可以事后应用于现有的微调模型，无需架构更改。给定一个微调模型，我们继续微调其可训练参数(如软提示或线性头)，以寻找一个具有两条低损失路径的持续模型，一条通往零样本(如CLIP)解决方案，另一条通往微调(如CoOp)解决方案。通过利用损失景观的几何特性，持续模型隐式地合并了这两种解决方案，恢复了微调对应模型中丢失的预训练知识。一个挑战是原始的LMC约束需要来自预训练任务的数据回放。我们通过二阶替代物来近似零样本模型的这一约束，从而消除了大规模数据回放的需求。实验表明，MERGETUNE在不增加参数的情况下，将CoOp在基础-新类泛化上的调和平均值提高了+5.6%。我们在跨数据集迁移上首次展示了优于CLIP在DTD和EuroSAT上的表现。在鲁棒微调评估中，来自MERGETUNE的LMC合并模型以较低的推理成本超越了集成基线，当与零样本模型集成时实现了进一步的增益和最先进的结果。


<details>
  <summary>Details</summary>
Motivation: 微调视觉语言模型(VLMs)如CLIP通常会导致预训练知识的灾难性遗忘，这在适配过程中是不可避免的。现有的方法主要关注在适应过程中减少遗忘，但遗忘问题仍然存在。因此，需要一种新的范式来恢复在微调过程中已经丢失的预训练知识。

Method: 本文提出了一种名为MERGETUNE的持续微调(CFT)策略。该方法利用线性模式连通性(LMC)的几何特性，通过继续微调已微调模型的可训练参数(如软提示或线性头)，寻找一个同时具有通往零-shot模型和微调模型低损失路径的持续模型。关键创新是使用二阶替代物来近似LMC约束，避免了大规模数据回放的需求，使方法具有模型无关性和事后应用特性。

Result: MERGETUNE在不增加参数的情况下，将CoOp在基础-新类泛化上的调和平均值提高了5.6%。在跨数据集迁移评估中，首次在DTD和EuroSAT数据集上超越了原始CLIP的性能。在鲁棒微调评估中，MERGETUNE产生的LMC合并模型以更低的推理成本超越了集成基线，当与零样本模型集成时达到了最先进的结果。

Conclusion: MERGETUNE提供了一个有效且实用的持续微调框架，能够恢复微调过程中丢失的预训练知识，显著改善了视觉语言模型在适应新任务时的泛化性能。该方法不增加模型参数，具有模型无关性，且不需要大规模数据回放，为视觉语言模型的适应性优化提供了新思路。

Abstract: Fine-tuning vision-language models (VLMs) such as CLIP often leads to catastrophic forgetting of pretrained knowledge. Prior work primarily aims to mitigate forgetting during adaptation; however, forgetting often remains inevitable during this process. We introduce a novel paradigm, \emph{continued fine-tuning (CFT)}, which seeks to recover pretrained knowledge after a zero-shot model has already been adapted. We propose a simple, model-agnostic CFT strategy (named MERGETUNE) guided by linear mode connectivity (LMC), which can be applied post hoc to existing fine-tuned models without requiring architectural changes. Given a fine-tuned model, we continue fine-tuning its trainable parameters (e.g., soft prompts or linear heads) to search for a continued model which has two low-loss paths to the zero-shot (e.g., CLIP) and the fine-tuned (e.g., CoOp) solutions. By exploiting the geometry of the loss landscape, the continued model implicitly merges the two solutions, restoring pretrained knowledge lost in the fine-tuned counterpart. A challenge is that the vanilla LMC constraint requires data replay from the pretraining task. We approximate this constraint for the zero-shot model via a second-order surrogate, eliminating the need for large-scale data replay. Experiments show that MERGETUNE improves the harmonic mean of CoOp by +5.6\% on base-novel generalisation without adding parameters. % We show \emph{the first time} superior performance than CLIP on both DTD and EuroSAT, on cross-dataset transfer. On robust fine-tuning evaluations, the LMC-merged model from MERGETUNE surpasses ensemble baselines with lower inference cost, achieving further gains and state-of-the-art results when ensembled with the zero-shot model. Our code is available at \href{https://github.com/Surrey-UP-Lab/MERGETUNE}{https://github.com/Surrey-UP-Lab/MERGETUNE}.

</details>


### [35] [SatMap: Revisiting Satellite Maps as Prior for Online HD Map Construction](https://arxiv.org/abs/2601.10512)
*Kanak Mazumder,Fabian B. Flohr*

Main category: cs.CV

Score: 4/5 | Tags: Autonomous Driving, HD Map, Satellite, BEV, Sensor Fusion, Computer Vision, Perception

Recommendation: 该论文提出了一种创新的卫星地图与摄像头融合的高精度地图构建方法，在nuScenes数据集上取得了显著性能提升。方法具有实际应用价值，特别是在长距离和恶劣天气条件下的表现优势明显。虽然卫星地图的可用性和实时性可能存在挑战，但该方法为解决自动驾驶感知问题提供了新思路，值得推荐。

TL;DR: 在线高精度地图构建是安全可靠的端到端自动驾驶系统的关键组成部分。基于车载摄像头的方法存在深度感知有限和遮挡导致的精度下降问题。在这项工作中，我们提出了SatMap，一种在线矢量化的高精度地图估计方法，将卫星地图与多视角摄像头观测集成，直接为下游预测和规划模块预测矢量化的高精度地图。我们的方法利用从鸟瞰视角拍摄的卫星图像中的车道级语义和纹理作为全局先验，有效缓解深度模糊和遮挡问题。在nuScenes数据集上的实验中，SatMap相比纯摄像头基线实现了34.8% mAP性能提升，相比摄像头-激光雷达融合基线实现了8.5% mAP提升。此外，我们在长距离和恶劣天气条件下评估了我们的模型，展示了使用卫星先验地图的优势。


<details>
  <summary>Details</summary>
Motivation: 在线高精度地图构建对于自动驾驶至关重要，但现有车载摄像头方法面临深度感知有限和遮挡问题。激光雷达成本高昂且受天气影响，而卫星地图能够提供全局的鸟瞰视角信息，可能为解决这些问题提供有效方案。

Method: SatMap采用卫星地图与多视角摄像头融合的方法。首先从卫星图像中提取车道级语义和纹理作为全局先验，然后将这些先验信息与车载多视角摄像头观测进行集成。模型直接输出矢量化的高精度地图，用于下游的预测和规划模块。这种方法利用卫星的鸟瞰视角缓解了深度感知模糊和遮挡问题。

Result: 在nuScenes数据集上，SatMap相比纯摄像头基线获得了34.8%的mAP性能提升，相比摄像头-激光雷达融合基线获得了8.5%的mAP提升。在长距离和恶劣天气条件下的评估表明，使用卫星先验地图具有显著优势。

Conclusion: SatMap通过集成卫星地图与车载摄像头观测，有效解决了自动驾驶中高精度地图构建的深度模糊和遮挡问题。该方法不仅超越了纯摄像头和摄像头-激光雷达融合方法，而且在复杂场景中表现出更强的鲁棒性，为在线高精度地图构建提供了创新解决方案。

Abstract: Online high-definition (HD) map construction is an essential part of a safe and robust end-to-end autonomous driving (AD) pipeline. Onboard camera-based approaches suffer from limited depth perception and degraded accuracy due to occlusion. In this work, we propose SatMap, an online vectorized HD map estimation method that integrates satellite maps with multi-view camera observations and directly predicts a vectorized HD map for downstream prediction and planning modules. Our method leverages lane-level semantics and texture from satellite imagery captured from a Bird's Eye View (BEV) perspective as a global prior, effectively mitigating depth ambiguity and occlusion. In our experiments on the nuScenes dataset, SatMap achieves 34.8% mAP performance improvement over the camera-only baseline and 8.5% mAP improvement over the camera-LiDAR fusion baseline. Moreover, we evaluate our model in long-range and adverse weather conditions to demonstrate the advantages of using a satellite prior map. Source code will be available at https://iv.ee.hm.edu/satmap/.

</details>


### [36] [Inference-time Physics Alignment of Video Generative Models with Latent World Models](https://arxiv.org/abs/2601.10553)
*Jianhao Yuan,Xiaofeng Zhang,Felix Friedrich,Nicolas Beltran-Velez,Melissa Hall,Reyhane Askari-Hemmat,Xiaochuang Han,Nicolas Ballas,Michal Drozdzal,Adriana Romero-Soriano*

Main category: cs.CV

Score: 5/5 | Tags: Video Generation, World Model, Physics, Reasoning, Diffusion Models, Alignment, ICCV

Recommendation: 本文提出了一种创新性的解决方案来解决视频生成中物理合理性的关键问题，不仅在理论上具有创新性，而且在ICCV 2025竞赛中取得了显著的实际成果（第一名，提升7.42%）。该方法具有通用性，不依赖于特定模型，为视频生成领域提供了重要的技术突破。

TL;DR: 最先进的视频生成模型能够产生有前景的视觉内容，但常常违反基本物理原理，这限制了它们的实用性。虽然有些人将这一缺陷归因于预训练中物理理解不足，但我们发现物理合理性的不足也源于次优的推理策略。因此，我们引入了WMReward，并将提高视频生成的物理合理性视为一个推理时对齐问题。具体而言，我们利用潜在世界模型（此处为VJEPA-2）的强大物理先验作为奖励，搜索并引导多个候选去噪轨迹，使得能够通过扩展测试时计算来获得更好的生成性能。通过实验验证，我们的方法显著提高了图像条件、多帧条件和文本条件生成设置中的物理合理性，并通过人类偏好研究得到验证。值得注意的是，在ICCV 2025感知测试PhysicsIQ挑战赛中，我们获得了62.64%的最终得分，赢得了第一名，相比之前的最先进方法提升了7.42%。我们的工作展示了使用潜在世界模型提高视频生成物理合理性的可行性，这超出了具体的实例化或参数化。


<details>
  <summary>Details</summary>
Motivation: 当前最先进的视频生成模型虽然在视觉质量上表现出色，但经常违反基本物理原理，这限制了它们在真实场景中的应用。研究发现这一问题不仅源于预训练阶段对物理理解的不足，还在于推理阶段的策略不够优化。因此，作者旨在通过改进推理策略来提升视频生成的物理合理性。

Method: 本文提出了WMReward方法，将提高物理合理性问题视为推理时对齐问题。该方法利用潜在世界模型VJEPA-2作为强大的物理先验，将其作为奖励函数来搜索和引导多个候选去噪轨迹。通过扩展测试时计算，在推理阶段优化生成过程，从而提高视频的物理合理性。这种方法不依赖于特定的模型参数化，而是通过世界模型的物理理解能力来指导生成过程。

Result: 该方法在多个生成设置中都取得了显著效果：在图像条件、多帧条件和文本条件生成场景中，物理合理性均得到大幅提升。通过人类偏好研究验证了改进的有效性。在ICCV 2025感知测试PhysicsIQ挑战赛中，该方法获得了62.64%的最终得分，赢得了第一名，相比之前的最先进方法提升了7.42%。

Conclusion: 本文表明，利用潜在世界模型作为物理先验，通过推理时对齐策略可以显著提高视频生成的物理合理性。WMReward方法提供了一种有效的方式来解决当前视频生成模型违反物理原理的问题，这种方法具有通用性，不依赖于特定的模型实例化或参数化。

Abstract: State-of-the-art video generative models produce promising visual content yet often violate basic physics principles, limiting their utility. While some attribute this deficiency to insufficient physics understanding from pre-training, we find that the shortfall in physics plausibility also stems from suboptimal inference strategies. We therefore introduce WMReward and treat improving physics plausibility of video generation as an inference-time alignment problem. In particular, we leverage the strong physics prior of a latent world model (here, VJEPA-2) as a reward to search and steer multiple candidate denoising trajectories, enabling scaling test-time compute for better generation performance. Empirically, our approach substantially improves physics plausibility across image-conditioned, multiframe-conditioned, and text-conditioned generation settings, with validation from human preference study. Notably, in the ICCV 2025 Perception Test PhysicsIQ Challenge, we achieve a final score of 62.64%, winning first place and outperforming the previous state of the art by 7.42%. Our work demonstrates the viability of using latent world models to improve physics plausibility of video generation, beyond this specific instantiation or parameterization.

</details>


### [37] [DeepUrban: Interaction-Aware Trajectory Prediction and Planning for Automated Driving by Aerial Imagery](https://arxiv.org/abs/2601.10554)
*Constantin Selzer,Fabian B. Flohr*

Main category: cs.CV

Score: 4/5 | Tags: 自动驾驶, 轨迹预测, 数据集, 无人机, 城市交通, 规划算法, 3D感知

Recommendation: 这篇论文推荐指数较高，因为它解决了自动驾驶领域一个重要实际问题——密集城市交通场景的数据稀缺问题。提出的DeepUrban数据集具有实际应用价值，实验结果显示在关键指标上有显著提升（44.1%/44.3%）。数据集与工业合作伙伴共同开发，确保了真实性和实用性，对于自动驾驶预测和规划研究具有重要贡献。

TL;DR: 自动驾驶系统的效能关键依赖于强大的预测和规划能力。然而，当前的基准测试受到缺少密集交通场景的显著限制，而这些场景对于理解和建模道路使用者之间的复杂交互至关重要。为了填补这一空白，我们与工业合作伙伴DeepScenario合作开发了DeepUrban——一个新的无人机数据集，旨在增强专注于密集城市环境的轨迹预测和规划基准。DeepUrban提供了丰富的3D交通物体集合，这些数据从大约100米高度拍摄的城市交叉口高分辨率图像中提取。该数据集还进一步丰富了全面的地图和场景信息，以支持高级建模和仿真任务。我们评估了最先进的预测和规划方法，并进行了泛化能力的实验。我们的研究结果表明，将DeepUrban添加到nuScenes中可以显著提升车辆预测和规划的准确性，在ADE/FDE指标上实现了高达44.1%/44.3%的改进。


<details>
  <summary>Details</summary>
Motivation: 当前自动驾驶系统的预测和规划基准测试存在明显不足，特别是缺乏密集交通场景，而这些场景对于理解复杂交通交互至关重要。密集城市环境下的交通预测和规划面临挑战，现有数据集无法充分覆盖这种复杂场景。

Method: 通过与工业合作伙伴DeepScenario合作，开发了DeepUrban无人机数据集。数据集从约100米高度拍摄的高分辨率城市交叉口图像中提取3D交通物体，并整合了全面的地图和场景信息。使用该数据集评估了最先进的预测和规划方法，并进行了泛化能力实验，特别是测试了将DeepUrban与现有数据集nuScenes结合使用的效果。

Result: DeepUrban数据集显著提升了车辆预测和规划的准确性。将DeepUrban添加到nuScenes数据集中，在ADE（平均位移误差）指标上实现了44.1%的改进，在FDE（最终位移误差）指标上实现了44.3%的改进，证明了数据集在密集城市环境下的有效性和重要性。

Conclusion: DeepUrban数据集有效填补了自动驾驶预测和规划领域中密集交通场景的空白。该数据集不仅增强了现有基准测试的能力，还显著提升了预测和规划算法的性能，特别是在复杂城市环境中的表现，为自动驾驶系统的发展提供了重要支持。

Abstract: The efficacy of autonomous driving systems hinges critically on robust prediction and planning capabilities. However, current benchmarks are impeded by a notable scarcity of scenarios featuring dense traffic, which is essential for understanding and modeling complex interactions among road users. To address this gap, we collaborated with our industrial partner, DeepScenario, to develop DeepUrban-a new drone dataset designed to enhance trajectory prediction and planning benchmarks focusing on dense urban settings. DeepUrban provides a rich collection of 3D traffic objects, extracted from high-resolution images captured over urban intersections at approximately 100 meters altitude. The dataset is further enriched with comprehensive map and scene information to support advanced modeling and simulation tasks. We evaluate state-of-the-art (SOTA) prediction and planning methods, and conducted experiments on generalization capabilities. Our findings demonstrate that adding DeepUrban to nuScenes can boost the accuracy of vehicle predictions and planning, achieving improvements up to 44.1 % / 44.3% on the ADE / FDE metrics. Website: https://iv.ee.hm.edu/deepurban

</details>


### [38] [Jordan-Segmentable Masks: A Topology-Aware definition for characterizing Binary Image Segmentation](https://arxiv.org/abs/2601.10577)
*Serena Grazia De Benedictis,Amedeo Altavilla,Nicoletta Del Buono*

Main category: cs.CV

Score: 4/5 | Tags: Computer Vision, Image Segmentation, Topological Analysis, Evaluation Metrics, Digital Geometry, Jordan Curve Theorem, Homology Theory

Recommendation: 本文值得推荐的原因：1）提出了一个新颖的拓扑感知分割评估框架，弥补了传统指标的不足；2）具有坚实的数学理论基础（Jordan曲线定理、同调理论）；3）针对实际应用中的关键问题（医学图像、对象分割的拓扑正确性）；4）提供了无监督评估方法，不依赖人工标注。扣分原因：未提供具体的实验验证和与其他方法的对比结果，实际应用效果尚需进一步验证。

TL;DR: 图像分割在计算机视觉中起着核心作用。然而，广泛使用的评估指标，无论是像素级、区域基或边界焦点，往往难以捕捉分割的结构和拓扑连贯性。在许多实际场景中，如医学成像或对象轮廓描绘，边界上的微小不准确、空洞或碎片化预测可能导致高指标得分，尽管生成的掩码未能保留对象的全局形状或连通性。这突显了传统指标的局限性：它们无法评估预测的分割是否将图像划分为有意义的内外区域。
在这项工作中，我们引入了基于Jordan曲线定理并适用于数字平面的拓扑感知分割概念。我们定义了\textit{Jordan可分割掩码}的概念，这是一种二进制分割，其结构确保了图像域在拓扑上分离为两个连通分量。我们通过数字拓扑和同调理论分析分割掩码，从掩码中提取一个$4$-曲线候选，使用Betti数验证其拓扑有效性。当该候选形成具有$β_0 = β_1 = 1$的数字4-曲线时，或其补集恰好分裂为两个$8$-连通分量时，掩码被认为是Jordan可分割的。
该框架提供了一个数学严谨的无监督准则，用于评估分割掩码的结构连贯性。通过结合数字Jordan理论和同调不变量，我们的方法为传统评估指标提供了有价值的替代方案，特别是在必须保持拓扑正确性的应用中。


<details>
  <summary>Details</summary>
Motivation: 本文的动机源于当前图像分割评估指标在捕捉分割结果的结构和拓扑连贯性方面的不足。传统评估指标（如像素级精度、区域基指标、边界指标）虽然能衡量局部准确性，但无法评估分割是否在拓扑上将图像划分为有意义的内外区域。在许多关键应用场景（如医学图像分割、对象轮廓描绘）中，分割结果需要保持对象的全局形状和连通性，而现有指标可能给含有空洞、碎片化或不连续边界的掩码高分，这在实际应用中可能导致严重问题。

Method: 本文提出的方法基于数字Jordan理论和同调理论。首先定义了"Jordan可分割掩码"的概念，这是一种二进制分割掩码，要求其在数字平面上形成拓扑上合理的分割，将图像域分离为两个连通分量。具体方法包括：
1. 从分割掩码中提取4-曲线候选
2. 使用同调理论中的Betti数（β₀和β₁）验证该候选的拓扑有效性
3. 判断掩码是否满足β₀ = β₁ = 1的条件，或等价地判断掩码的补集是否恰好分裂为两个8-连通分量
该方法将连续数学中的Jordan曲线定理适配到数字平面，提供了一种数学严谨的无监督评估框架。

Result: 该研究提出的框架能够有效评估分割掩码的拓扑连贯性。通过基于Jordan曲线定理和同调理论的数学验证，该方法可以检测出传统指标可能忽略的拓扑问题，如掩码中存在空洞、不连续性或错误的连通性结构。该方法提供了一种数学严谨的无监督标准，用于判断分割是否在拓扑上将图像划分为合理的内外区域。

Conclusion: 本文提出了一种基于数字Jordan理论和同调理论的拓扑感知分割评估方法。该方法弥补了传统评估指标在衡量分割结果拓扑连贯性方面的不足，为需要保持拓扑正确性的应用场景（如医学图像分析、精确对象分割）提供了有价值的替代评估方案。该方法具有数学严谨性、无监督性和对结构连贯性的敏感性，有望改善分割模型在关键应用中的可靠性评估。

Abstract: Image segmentation plays a central role in computer vision. However, widely used evaluation metrics, whether pixel-wise, region-based, or boundary-focused, often struggle to capture the structural and topological coherence of a segmentation. In many practical scenarios, such as medical imaging or object delineation, small inaccuracies in boundary, holes, or fragmented predictions can result in high metric scores, despite the fact that the resulting masks fail to preserve the object global shape or connectivity. This highlights a limitation of conventional metrics: they are unable to assess whether a predicted segmentation partitions the image into meaningful interior and exterior regions.
  In this work, we introduce a topology-aware notion of segmentation based on the Jordan Curve Theorem, and adapted for use in digital planes. We define the concept of a \emph{Jordan-segmentatable mask}, which is a binary segmentation whose structure ensures a topological separation of the image domain into two connected components. We analyze segmentation masks through the lens of digital topology and homology theory, extracting a $4$-curve candidate from the mask, verifying its topological validity using Betti numbers. A mask is considered Jordan-segmentatable when this candidate forms a digital 4-curve with $β_0 = β_1 = 1$, or equivalently when its complement splits into exactly two $8$-connected components.
  This framework provides a mathematically rigorous, unsupervised criterion with which to assess the structural coherence of segmentation masks. By combining digital Jordan theory and homological invariants, our approach provides a valuable alternative to standard evaluation metrics, especially in applications where topological correctness must be preserved.

</details>


### [39] [Action100M: A Large-scale Video Action Dataset](https://arxiv.org/abs/2601.10592)
*Delong Chen,Tejaswi Kasarla,Yejin Bang,Mustafa Shukor,Willy Chung,Jade Yu,Allen Bolourchi,Theo Moutakanni,Pascale Fung*

Main category: cs.CV

Score: 5/5 | Tags: Video Understanding, Action Recognition, Large-scale Dataset, Computer Vision, Self-supervised Learning, World Modeling, VL-JEPA, GPT-OSS

Recommendation: 本文推荐度很高，因为它提出了一个超大规模的视频动作数据集Action100M，该数据集具有几个重要优势：1) 规模庞大（约1亿个片段），支持数据扩展研究；2) 采用全自动流水线生成高质量结构化标注，解决了人工标注的成本和规模限制；3) 实验证明在多种动作识别基准上具有强大的零样本性能；4) 为视频理解和世界建模领域提供了重要的基础资源，具有广泛的实用价值和研究意义。

TL;DR: 我们介绍了Action100M，这是一个从120万条互联网教学视频（总时长14.6年）构建的大规模数据集，产生了约1亿个具有开放词汇动作监督和丰富字幕的时间定位片段。Action100M通过一个全自动流水线生成：(i) 使用V-JEPA 2嵌入进行分层时间分割，(ii) 生成多层次帧和片段字幕并组织成"字幕树"，(iii) 通过推理模型(GPT-OSS-120B)在多轮自我优化过程中聚合证据以输出结构化标注（简要/详细动作、执行者、简要/详细字幕）。在Action100M上训练VL-JEPA展示了持续的数据扩展改进和在不同动作识别基准测试中的强大零样本性能，确立了Action100M作为视频理解和世界建模可扩展研究的新基础。


<details>
  <summary>Details</summary>
Motivation: 从视觉观察中推断物理动作是推动机器在物理世界中智能发展的基本能力。实现这一目标需要大规模、开放词汇的视频动作数据集来覆盖广泛领域。现有数据集在规模、多样性或标注质量方面存在限制，难以支持开放词汇动作理解的研究。本论文旨在通过构建Action100M这一超大规模视频动作数据集来解决这些限制，为视频理解和世界建模研究提供新的基础资源。

Method: 方法包括三个主要步骤：1) 使用V-JEPA 2嵌入对120万条教学视频进行分层时间分割，生成约1亿个时间定位片段；2) 生成多层次帧和片段字幕并组织成"字幕树"结构；3) 通过推理模型(GPT-OSS-120B)在多轮自我优化过程中聚合证据，输出结构化标注（包括简要/详细动作、执行者、简要/详细字幕）。整个过程采用全自动流水线实现，无需人工干预。

Result: 在Action100M数据集上训练VL-JEPA模型展示了持续的数据扩展效益，即在数据集规模增加时性能持续提升。模型在多个动作识别基准测试中表现出强大的零样本性能，证明了数据集的质量和多样性。Action100M数据集已成为视频理解和世界建模可扩展研究的新基础资源。

Conclusion: Action100M作为一个从120万条教学视频构建的大规模开放词汇视频动作数据集，通过全自动流水线生成高质量的结构化标注，为视频理解和世界建模研究提供了新的基础。实验结果证明该数据集支持数据扩展效应并能在多种动作识别任务上实现强大的零样本性能，有望推动机器在物理世界中的动作理解能力发展。

Abstract: Inferring physical actions from visual observations is a fundamental capability for advancing machine intelligence in the physical world. Achieving this requires large-scale, open-vocabulary video action datasets that span broad domains. We introduce Action100M, a large-scale dataset constructed from 1.2M Internet instructional videos (14.6 years of duration), yielding O(100 million) temporally localized segments with open-vocabulary action supervision and rich captions. Action100M is generated by a fully automated pipeline that (i) performs hierarchical temporal segmentation using V-JEPA 2 embeddings, (ii) produces multi-level frame and segment captions organized as a Tree-of-Captions, and (iii) aggregates evidence with a reasoning model (GPT-OSS-120B) under a multi-round Self-Refine procedure to output structured annotations (brief/detailed action, actor, brief/detailed caption). Training VL-JEPA on Action100M demonstrates consistent data-scaling improvements and strong zero-shot performance across diverse action recognition benchmarks, establishing Action100M as a new foundation for scalable research in video understanding and world modeling.

</details>


### [40] [RSATalker: Realistic Socially-Aware Talking Head Generation for Multi-Turn Conversation](https://arxiv.org/abs/2601.10606)
*Peng Chen,Xiaobao Wei,Yi Yang,Naiming Yao,Hui Chen,Feng Tian*

Main category: cs.CV

Score: 4/5 | Tags: 3D Gaussian Splatting, Talking Head Generation, Virtual Reality, Social Interaction, Speech-driven Animation, 3D Graphics, Computer Vision, Multi-turn Dialogue

Recommendation: 推荐理由：1) 提出了创新的社交感知模块，将社交关系编码引入说话头生成，填补了领域空白；2) 巧妙结合3D网格和3D高斯溅射技术，平衡了真实感与计算效率；3) 构建了新的数据集和训练范式；4) 支持多轮对话场景，具有实际应用价值。扣分点在于目前仅看到方法描述，缺乏与其他方法的定量对比数据和实际应用演示。

TL;DR: 说话头生成在虚拟现实（VR）中变得越来越重要，特别是在涉及多轮对话的社交场景中。现有方法面临显著限制：基于网格的3D方法可以模拟双人对话但缺乏逼真纹理，而基于大模型的2D方法产生自然外观但计算成本过高。最近，基于3D高斯溅射（3DGS）的方法实现了高效逼真的渲染，但仍然是单说话者模式且忽略社交关系。我们提出了RSATalker，这是首个利用3DGS实现逼真且社交感知的说话头生成框架，支持多轮对话。我们的方法首先从语音驱动基于网格的3D面部运动，然后将3D高斯绑定到网格面片以渲染高保真2D头像视频。为了捕捉人际动态，我们提出了一个社交感知模块，通过可学习的查询机制将社交关系（包括血缘和非血缘、平等和不平等）编码为高层嵌入。我们设计了一个三阶段训练范式，并构建了RSATalker数据集，其中包含标注社交关系的语音-网格-图像三元组。大量实验证明，RSATalker在逼真性和社交感知方面都实现了最先进的性能。代码和数据集将被发布。


<details>
  <summary>Details</summary>
Motivation: 虚拟现实社交场景中对逼真多轮对话说话头生成的需求日益增长。现有方法存在明显缺陷：传统3D网格方法无法实现逼真纹理渲染，而2D大模型方法计算成本过高且缺乏社交关系建模。特别是当前基于3D高斯溅射的方法虽然渲染效率高，但仅限于单说话者模式且忽略了对话中的社交关系动态。因此，需要开发一个既能高效渲染又具备社交感知能力的多轮对话说话头生成框架。

Method: RSATalker采用三步方法：1) 首先从语音驱动基于网格的3D面部运动；2) 将3D高斯绑定到网格面片以渲染高保真2D头像视频；3) 核心创新是提出了社交感知模块，通过可学习的查询机制将社交关系（血缘/非血缘、平等/不平等）编码为高层嵌入。采用三阶段训练范式，包括基础对话学习、基于网格的运动建模和最终的高斯渲染。构建了RSATalker数据集，包含语音-网格-图像三元组及社交关系标注。

Result: 通过大量实验验证，RSATalker在逼真性和社交感知方面都实现了最先进的性能。该方法能够生成具有逼真纹理和高保真度的说话头视频，同时成功捕捉并编码对话中的社交关系动态，支持多轮对话场景。相比现有方法，在保持渲染效率的同时显著提升了社交交互的真实感。

Conclusion: RSATalker成功构建了首个利用3D高斯溅射技术实现逼真且社交感知的说话头生成框架，有效解决了现有方法在纹理真实感、计算效率和社交关系建模方面的局限性。该框架不仅支持多轮对话，还能准确捕捉人际动态，为虚拟现实社交应用提供了有力的技术支撑。未来将发布代码和数据集以推动该领域发展。

Abstract: Talking head generation is increasingly important in virtual reality (VR), especially for social scenarios involving multi-turn conversation. Existing approaches face notable limitations: mesh-based 3D methods can model dual-person dialogue but lack realistic textures, while large-model-based 2D methods produce natural appearances but incur prohibitive computational costs. Recently, 3D Gaussian Splatting (3DGS) based methods achieve efficient and realistic rendering but remain speaker-only and ignore social relationships. We introduce RSATalker, the first framework that leverages 3DGS for realistic and socially-aware talking head generation with support for multi-turn conversation. Our method first drives mesh-based 3D facial motion from speech, then binds 3D Gaussians to mesh facets to render high-fidelity 2D avatar videos. To capture interpersonal dynamics, we propose a socially-aware module that encodes social relationships, including blood and non-blood as well as equal and unequal, into high-level embeddings through a learnable query mechanism. We design a three-stage training paradigm and construct the RSATalker dataset with speech-mesh-image triplets annotated with social relationships. Extensive experiments demonstrate that RSATalker achieves state-of-the-art performance in both realism and social awareness. The code and dataset will be released.

</details>


### [41] [Molmo2: Open Weights and Data for Vision-Language Models with Video Understanding and Grounding](https://arxiv.org/abs/2601.10611)
*Christopher Clark,Jieyu Zhang,Zixian Ma,Jae Sung Park,Mohammadreza Salehi,Rohun Tripathi,Sangho Lee,Zhongzheng Ren,Chris Dongjoo Kim,Yinuo Yang,Vincent Shao,Yue Yang,Weikai Huang,Ziqi Gao,Taira Anderson,Jianrui Zhang,Jitesh Jain,George Stoica,Winson Han,Ali Farhadi,Ranjay Krishna*

Main category: cs.CV

Score: 5/5 | Tags: VLM, Video-Language Models, Vision-Language, Grounding, Object Tracking, Computer Vision, NLP, Multimodal Learning, Open Source

Recommendation: 这篇论文具有很高推荐价值，因为它解决了视频语言模型领域的两个关键问题：开源模型依赖专有技术的问题和视觉定位能力的缺失。作者构建了完全开源的高质量数据集，提出了创新的训练方法，并在多项任务上超越了现有专有模型。这对于推动开源多模态AI发展和实际应用具有重要意义，特别是对于需要像素级视觉定位的下游应用场景。

TL;DR: 当今最强大的视频语言模型（VLM）仍然是专有模型。最强的开源模型要么依赖专有VLM生成的合成数据进行蒸馏，要么不公开其训练数据或训练方法。因此，开源社区缺乏改进最先进视频（和图像）语言模型所需的基础设施。关键的是，许多下游应用需要不仅仅是高级视频理解；它们需要像素级的视觉定位能力——无论是通过指向还是跟踪。即使是专有模型也缺乏这种能力。我们提出了Molmo2，这是一个新的VLM家族，在开源模型中达到最先进水平，并在单图像、多图像和视频任务中的指向驱动定位方面展现出卓越的新能力。我们的核心贡献是收集了7个新视频数据集和2个多图像数据集，包括用于预训练的详细视频描述数据集、用于微调的自由形式视频问答数据集、具有复杂查询的新对象跟踪数据集以及创新的视频指向数据集，所有这些数据集都是在没有使用封闭VLM的情况下收集的。我们还提出了一种使用高效打包和消息树编码方案的训练方法，并展示了视觉token的双向注意力机制和新颖的token权重策略如何提升性能。我们性能最佳的8B模型在短视频、计数和描述任务上优于同类开源权重和数据模型，在长视频任务上也具有竞争力。在视频定位方面，Molmo2显著优于现有的开源模型如Qwen3-VL（视频计数准确率为35.5 vs 29.6），并在某些任务上超越了专有模型如Gemini 3 Pro（视频指向F1分数为38.4 vs 20.0，视频跟踪J&F分数为56.2 vs 41.1）。


<details>
  <summary>Details</summary>
Motivation: 当前最强大的视频语言模型多为专有模型，开源模型要么依赖专有模型的合成数据进行蒸馏，要么不公开训练细节，导致开源社区难以改进视频语言模型技术。更重要的是，许多实际应用需要像素级的视觉定位能力（指向或跟踪），而现有专有模型也缺乏这种能力。因此，需要构建一个完全开源、具有先进视觉定位能力的视频语言模型家族。

Method: 1. 构建全新数据集：收集了7个视频数据集和2个多图像数据集，包括：详细视频描述数据集（预训练用）、自由形式视频问答数据集（微调用）、复杂查询对象跟踪数据集、创新的视频指向数据集，所有数据集均不依赖专有VLM。
2. 提出高效训练方案：采用打包和消息树编码方案，实现视觉token的双向注意力机制，并提出新颖的token权重策略来提升性能。
3. 开发Molmo2模型家族：构建不同规模的模型，重点在像素级视觉定位能力上进行优化。

Result: 1. Molmo2 8B模型在短视频、计数和描述任务上优于同类开源模型，在长视频任务上具有竞争力。
2. 在视频计数任务上：Molmo2准确率35.5，优于Qwen3-VL的29.6。
3. 在视频指向任务上：Molmo2 F1分数38.4，优于Gemini 3 Pro的20.0。
4. 在视频跟踪任务上：Molmo2 J&F分数56.2，优于Gemini 3 Pro的41.1。
5. 模型在单图像、多图像和视频任务的指向驱动定位方面展现出卓越能力。

Conclusion: Molmo2代表了视频语言模型领域的重要进展，它不仅是开源模型中最先进的，而且在像素级视觉定位能力上超越了现有专有模型。通过构建完全开源的数据集和训练方法，为开源社区提供了改进视频语言模型的基础设施，特别是在需要视觉定位的下游应用中具有重要价值。

Abstract: Today's strongest video-language models (VLMs) remain proprietary. The strongest open-weight models either rely on synthetic data from proprietary VLMs, effectively distilling from them, or do not disclose their training data or recipe. As a result, the open-source community lacks the foundations needed to improve on the state-of-the-art video (and image) language models. Crucially, many downstream applications require more than just high-level video understanding; they require grounding -- either by pointing or by tracking in pixels. Even proprietary models lack this capability. We present Molmo2, a new family of VLMs that are state-of-the-art among open-source models and demonstrate exceptional new capabilities in point-driven grounding in single image, multi-image, and video tasks. Our key contribution is a collection of 7 new video datasets and 2 multi-image datasets, including a dataset of highly detailed video captions for pre-training, a free-form video Q&A dataset for fine-tuning, a new object tracking dataset with complex queries, and an innovative new video pointing dataset, all collected without the use of closed VLMs. We also present a training recipe for this data utilizing an efficient packing and message-tree encoding scheme, and show bi-directional attention on vision tokens and a novel token-weight strategy improves performance. Our best-in-class 8B model outperforms others in the class of open weight and data models on short videos, counting, and captioning, and is competitive on long-videos. On video-grounding Molmo2 significantly outperforms existing open-weight models like Qwen3-VL (35.5 vs 29.6 accuracy on video counting) and surpasses proprietary models like Gemini 3 Pro on some tasks (38.4 vs 20.0 F1 on video pointing and 56.2 vs 41.1 J&F on video tracking).

</details>


### [42] [CoMoVi: Co-Generation of 3D Human Motions and Realistic Videos](https://arxiv.org/abs/2601.10632)
*Chengfeng Zhao,Jiazhi Shu,Yubo Zhao,Tianyu Huang,Jiahao Lu,Zekai Gu,Chengwei Ren,Zhiyang Dou,Qing Shuai,Yuan Liu*

Main category: cs.CV

Score: 4/5 | Tags: 3D生成, 视频生成, 扩散模型, 人体动作, 多模态生成, 计算机视觉, 深度学习

Recommendation: 本文具有创新性，提出了3D动作与视频生成的协同生成框架，解决了两个任务的内在耦合问题。方法设计合理，实验充分，具有实际应用价值。特别是构建的大规模数据集对于后续研究具有重要贡献。

TL;DR: 在本文中，我们发现3D人体动作生成和2D人体视频生成本质上是耦合的。3D动作为视频中的合理性和一致性提供了结构先验，而预训练的视频模型为动作提供了强大的泛化能力，这需要耦合它们的生成过程。基于此，我们提出了CoMoVi，一个协同生成框架，通过耦合两个视频扩散模型(VDMs)在单个扩散去噪循环中同步生成3D人体动作和视频。为了实现这一目标，我们首先提出了一种有效的2D人体动作表示方法，可以继承预训练VDMs的强大先验。然后，我们设计了一个双分支扩散模型，通过相互特征交互和3D-2D交叉注意力来耦合人体动作和视频生成过程。此外，我们还整理了CoMoVi数据集，这是一个大规模的真实世界人体视频数据集，包含文本和动作标注，涵盖了多样且具有挑战性的人体动作。大量实验证明了我们的方法在3D人体动作和视频生成任务中的有效性。


<details>
  <summary>Details</summary>
Motivation: 本文的动机源于发现3D人体动作生成与2D人体视频生成之间存在内在耦合关系。3D动作为视频提供了结构先验，确保动作的合理性和一致性；而预训练的视频扩散模型则为动作生成提供了强大的泛化能力。将这两个生成过程耦合在一起，可以相互增强，提升生成质量。

Method: 本文提出了CoMoVi框架，包含三个关键技术：1) 提出一种有效的2D人体动作表示方法，能够继承预训练视频扩散模型的先验知识；2) 设计双分支扩散模型，通过相互特征交互和3D-2D交叉注意力机制，在单个扩散去噪循环中同步生成3D动作和视频；3) 构建了CoMoVi数据集，这是一个大规模的真实世界人体视频数据集，包含文本和动作标注，涵盖了多样化的复杂动作。

Result: 广泛的实验证明，CoMoVi方法在3D人体动作生成和2D人体视频生成任务上均表现出色。该方法能够生成合理、一致的3D动作，同时产生高质量的人体视频，在两个任务上都达到了先进水平。

Conclusion: 本文成功证明了3D人体动作生成与2D人体视频生成的内在耦合关系，并提出了有效的协同生成框架CoMoVi。该方法通过耦合这两个生成过程，实现了相互增强的效果，在动作和视频生成任务上都取得了优异性能。

Abstract: In this paper, we find that the generation of 3D human motions and 2D human videos is intrinsically coupled. 3D motions provide the structural prior for plausibility and consistency in videos, while pre-trained video models offer strong generalization capabilities for motions, which necessitate coupling their generation processes. Based on this, we present CoMoVi, a co-generative framework that couples two video diffusion models (VDMs) to generate 3D human motions and videos synchronously within a single diffusion denoising loop. To achieve this, we first propose an effective 2D human motion representation that can inherit the powerful prior of pre-trained VDMs. Then, we design a dual-branch diffusion model to couple human motion and video generation process with mutual feature interaction and 3D-2D cross attentions. Moreover, we curate CoMoVi Dataset, a large-scale real-world human video dataset with text and motion annotations, covering diverse and challenging human motions. Extensive experiments demonstrate the effectiveness of our method in both 3D human motion and video generation tasks.

</details>


### [43] [CURVE: A Benchmark for Cultural and Multilingual Long Video Reasoning](https://arxiv.org/abs/2601.10649)
*Darshan Singh,Arsha Nagrani,Kawshik Manikantan,Harman Singh,Dinesh Tewari,Tobias Weyand,Cordelia Schmid,Anelia Angelova,Shachi Dave*

Main category: cs.CV

Score: 5/5 | Tags: Video-LLM, Benchmark, Multicultural, Multilingual, Cultural Understanding, Reasoning, Evaluation

Recommendation: 这篇论文非常值得推荐，因为它解决了当前视频模型评估中的一个重要盲点——文化偏见问题。CURVE基准的创新之处在于其完全人工生成的多文化、多语言标注，这为评估模型的真实跨文化理解能力提供了可靠的标准。该研究不仅提出了新的评估框架，还揭示了当前最先进模型在文化理解方面的显著不足，对推动该领域的发展具有重要价值。

TL;DR: 近年来视频模型取得了巨大进展，特别是在长视频理解方面。然而，当前的基准测试主要包含西方中心的数据，并以英语为主导语言，引入了显著的评估偏见。为解决这一问题，我们引入了CURVE（视频评估中的文化理解与推理），这是一个用于多元文化和多语言视频推理的具有挑战性的基准测试。CURVE包含来自18个全球不同地区的多样化、区域特定文化视频的高质量、完全人工生成的标注。与先前依赖自动翻译的工作不同，CURVE提供了复杂的问题、答案和多步推理步骤，全部使用本地语言精心制作。要在CURVE上取得进展，需要对视觉文化背景进行深度情境理解。此外，我们利用CURVE的推理轨迹构建基于证据的图，并提出了一种使用这些图来识别推理中细粒度错误的新颖迭代策略。我们的评估表明，最先进的视频-LLMs表现出显著困难，性能远低于人类水平，错误主要源于对文化元素的视觉感知不足。CURVE将在https://github.com/google-deepmind/neptune上公开提供。


<details>
  <summary>Details</summary>
Motivation: 当前视频理解基准测试存在严重偏颇，主要集中于西方文化和英语数据，这限制了模型的跨文化理解能力评估。为了解决这一评估偏见问题，研究人员需要创建一个能够全面评估视频模型在多元文化和多语言环境中的文化理解能力的基准测试。

Method: 研究团队创建了CURVE基准测试，该基准包含来自18个全球不同地区的高质量文化视频，所有标注完全由人工生成。不同于传统依赖自动翻译的方法，CURVE提供了本地方言中的复杂问题、答案和多步推理步骤。此外，团队还基于CURVE的推理轨迹构建了证据图，并设计了一种迭代策略来识别推理中的细粒度错误。

Result: 评估结果显示，当前最先进的视频-LLMs在CURVE基准测试上表现显著不佳，其准确率远低于人类水平。主要的性能差距来源于模型对视觉文化元素的感知不足，这表明现有模型在跨文化视频理解方面存在显著局限性。

Conclusion: CURVE基准测试成功揭示了当前视频-LLMs在跨文化理解方面的显著不足，特别是对视觉文化元素的感知能力有限。该基准为评估和改进视频模型的文化理解能力提供了重要工具，并推动了更全面、无偏的视频模型评估范式的发展。

Abstract: Recent advancements in video models have shown tremendous progress, particularly in long video understanding. However, current benchmarks predominantly feature western-centric data and English as the dominant language, introducing significant biases in evaluation. To address this, we introduce CURVE (Cultural Understanding and Reasoning in Video Evaluation), a challenging benchmark for multicultural and multilingual video reasoning. CURVE comprises high-quality, entirely human-generated annotations from diverse, region-specific cultural videos across 18 global locales. Unlike prior work that relies on automatic translations, CURVE provides complex questions, answers, and multi-step reasoning steps, all crafted in native languages. Making progress on CURVE requires a deeply situated understanding of visual cultural context. Furthermore, we leverage CURVE's reasoning traces to construct evidence-based graphs and propose a novel iterative strategy using these graphs to identify fine-grained errors in reasoning. Our evaluations reveal that SoTA Video-LLMs struggle significantly, performing substantially below human-level accuracy, with errors primarily stemming from the visual perception of cultural elements. CURVE will be publicly available under https://github.com/google-deepmind/neptune?tab=readme-ov-file\#minerva-cultural

</details>


### [44] [See Less, Drive Better: Generalizable End-to-End Autonomous Driving via Foundation Models Stochastic Patch Selection](https://arxiv.org/abs/2601.10707)
*Amir Mallak,Erfan Aasi,Shiva Sreeram,Tsun-Hsuan Wang,Daniela Rus,Alaa Maalouf*

Main category: cs.CV

Score: 4/5 | Tags: 自动驾驶, 计算机视觉, 机器学习, 特征学习, 鲁棒性, 泛化, 基础模型, 端到端学习

Recommendation: 该论文提出了解决自动驾驶特征冗余问题的创新方法SPS，通过简单有效的随机掩码机制显著提升策略的OOD泛化能力。实验设计充分，在多个OOD场景中验证了方法的优越性，特别是可直接迁移到真实世界的特性展示了实际应用潜力。方法简洁但效果显著，值得推荐给自动驾驶和机器学习领域的研究者。

TL;DR: 近期端到端自动驾驶研究显示，在基础模型提取的补丁对齐特征上训练的策略能更好地泛化到分布外（OOD）数据。我们假设由于自注意力机制，每个补丁特征隐含地嵌入/包含了所有其他补丁的信息，以不同的方式和强度表示，使得这些描述符高度冗余。我们通过PCA和跨补丁相似性量化了（BLIP2）特征中的冗余：90%的方差由17/64个主成分捕获，并且强跨令牌相关性普遍存在。在此类重叠信息上训练会导致策略过度拟合伪相关，损害OOD鲁棒性。我们提出了随机补丁选择（SPS），这是一种简单而有效的方法，用于学习更鲁棒、可泛化和高效的策略。对于每一帧，SPS随机掩码一部分补丁描述符，不将它们馈送到策略模型中，同时保留剩余补丁的空间布局。因此，策略被提供了（相同）场景的不同随机但完整的视图：每个随机补丁子集都充当世界的不同但仍然是合理、一致的投影。因此，策略将其决策基于那些对特定令牌是否存活不变的特征。大量实验证实，在所有OOD场景中，我们的方法优于最先进技术（SOTA），实现了平均6.2%的改进，闭环模拟中最高达20.4%，同时速度快2.4倍。我们对掩码率和补丁特征重组进行了消融研究，训练并评估了9个系统，其中8个超越了先前的SOTA。最后，我们展示了相同的学习策略可以迁移到物理、真实世界的汽车上而无需任何调整。


<details>
  <summary>Details</summary>
Motivation: 当前基于基础模型提取的补丁对齐特征的端到端自动驾驶策略虽然展现了一定的OOD泛化能力，但由于自注意力机制导致特征高度冗余，策略容易过度拟合伪相关，从而影响OOD鲁棒性。研究旨在解决特征冗余导致的过拟合问题，提升自动驾驶策略的泛化性和鲁棒性。

Method: 提出随机补丁选择（SPS）方法：对每一帧图像，随机掩码一部分补丁描述符（不输入到策略模型），同时保持剩余补丁的空间布局不变。这种方法为策略提供了相同的多个随机但完整的场景视图，迫使策略学习对特定补丁存活不变的特征，从而增强泛化能力。

Result: 在所有OOD场景中，SPS方法均优于现有最先进技术（SOTA），平均提升6.2%，闭环模拟中最高提升20.4%，同时推理速度快2.4倍。消融研究表明不同掩码率和重组配置下，训练的9个系统中有8个超越先前SOTA。学习到的策略可直接迁移到真实物理汽车而无需额外调优。

Conclusion: SPS通过随机掩码补丁描述符来缓解特征冗余导致的过拟合问题，有效提升了自动驾驶策略的鲁棒性和泛化能力。该方法不仅在模拟环境中表现优异，还能直接迁移到真实世界，证明了其实际应用价值。

Abstract: Recent advances in end-to-end autonomous driving show that policies trained on patch-aligned features extracted from foundation models generalize better to Out-of-Distribution (OOD). We hypothesize that due to the self-attention mechanism, each patch feature implicitly embeds/contains information from all other patches, represented in a different way and intensity, making these descriptors highly redundant. We quantify redundancy in such (BLIP2) features via PCA and cross-patch similarity: $90$% of variance is captured by $17/64$ principal components, and strong inter-token correlations are pervasive. Training on such overlapping information leads the policy to overfit spurious correlations, hurting OOD robustness. We present Stochastic-Patch-Selection (SPS), a simple yet effective approach for learning policies that are more robust, generalizable, and efficient. For every frame, SPS randomly masks a fraction of patch descriptors, not feeding them to the policy model, while preserving the spatial layout of the remaining patches. Thus, the policy is provided with different stochastic but complete views of the (same) scene: every random subset of patches acts like a different, yet still sensible, coherent projection of the world. The policy thus bases its decisions on features that are invariant to which specific tokens survive. Extensive experiments confirm that across all OOD scenarios, our method outperforms the state of the art (SOTA), achieving a $6.2$% average improvement and up to $20.4$% in closed-loop simulations, while being $2.4\times$ faster. We conduct ablations over masking rates and patch-feature reorganization, training and evaluating 9 systems, with 8 of them surpassing prior SOTA. Finally, we show that the same learned policy transfers to a physical, real-world car without any tuning.

</details>


### [45] [From One-to-One to Many-to-Many: Dynamic Cross-Layer Injection for Deep Vision-Language Fusion](https://arxiv.org/abs/2601.10710)
*Cheng Chen,Yuyu Guo,Pengpeng Zeng,Jingkuan Song,Peng Di,Hang Yu,Lianli Gao*

Main category: cs.CV

Score: 4/5 | Tags: Vision-Language Models, LLM, Multimodal, Architecture, Feature Injection, Hierarchical Representation

Recommendation: 推荐该论文的原因：1）提出了创新的跨层注入框架，解决现有视觉语言模型的瓶颈问题；2）方法轻量且参数高效，具有良好的实用价值；3）在多个基准上验证了有效性；4）为多模态模型架构设计提供了新思路。虽然该方法具有创新性，但需要在更多复杂任务上进行进一步验证。

TL;DR: 视觉语言模型（VLMs）通过一种粗糙、不对称的连接方式，将视觉编码器的输出仅链接到大语言模型（LLM）的输入，造成了严重的视觉特征瓶颈。这种静态架构从根本上限制了LLMs与分层视觉知识实现全面对齐的能力，削弱了其准确地将局部细节与全局语义整合为连贯推理的能力。为解决这一问题，我们引入了跨层注入（CLI），一种新颖的轻量级框架，可在两种模态间建立动态的多对多桥梁。CLI由两个协同的、参数高效的组件组成：一个自适应多投影（AMP）模块，用于协调来自不同视觉层的特征；以及一个自适应门控融合（AGF）机制，使LLM能够根据其实时解码上下文选择性地注入最相关的视觉信息。我们通过将其集成到LLaVA-OneVision和LLaVA-1.5中来验证CLI的有效性和通用性。在18个多样化基准上的广泛实验证明了显著的性能提升，确立了CLI作为一种可扩展的范式，通过授予LLMs按需访问完整视觉层次的能力，开启了更深层的多模态理解。


<details>
  <summary>Details</summary>
Motivation: 现有视觉语言模型存在严重的视觉特征瓶颈，仅通过视觉编码器的最终输出单向链接到语言模型，这种静态架构限制了语言模型与分层视觉知识的全面对齐，无法有效整合局部细节和全局语义进行连贯推理。

Method: 提出了跨层注入（CLI）框架，包含两个协同组件：1）自适应多投影（AMP）模块，用于协调不同视觉层的特征；2）自适应门控融合（AGF）机制，使语言模型能够根据实时解码上下文选择性地注入最相关的视觉信息。该方法在两个主流模型LLaVA-OneVision和LLaVA-1.5上进行了集成验证。

Result: 在18个多样化基准测试上进行了广泛实验，结果表明CLI能够带来显著的性能提升。该方法能够有效解决现有VLMs的视觉特征瓶颈问题，提升多模态理解能力。

Conclusion: 跨层注入（CLI）作为一个可扩展的范式，通过授予语言模型按需访问完整视觉层次的能力，实现了更深层的多模态理解，为解决现有视觉语言模型的局限性提供了有效解决方案。

Abstract: Vision-Language Models (VLMs) create a severe visual feature bottleneck by using a crude, asymmetric connection that links only the output of the vision encoder to the input of the large language model (LLM). This static architecture fundamentally limits the ability of LLMs to achieve comprehensive alignment with hierarchical visual knowledge, compromising their capacity to accurately integrate local details with global semantics into coherent reasoning. To resolve this, we introduce Cross-Layer Injection (CLI), a novel and lightweight framework that forges a dynamic many-to-many bridge between the two modalities. CLI consists of two synergistic, parameter-efficient components: an Adaptive Multi-Projection (AMP) module that harmonizes features from diverse vision layers, and an Adaptive Gating Fusion (AGF) mechanism that empowers the LLM to selectively inject the most relevant visual information based on its real-time decoding context. We validate the effectiveness and versatility of CLI by integrating it into LLaVA-OneVision and LLaVA-1.5. Extensive experiments on 18 diverse benchmarks demonstrate significant performance improvements, establishing CLI as a scalable paradigm that unlocks deeper multimodal understanding by granting LLMs on-demand access to the full visual hierarchy.

</details>


### [46] [Alterbute: Editing Intrinsic Attributes of Objects in Images](https://arxiv.org/abs/2601.10714)
*Tal Reiss,Daniel Winter,Matan Cohen,Alex Rav-Acha,Yael Pritch,Ariel Shamir,Yedid Hoshen*

Main category: cs.CV

Score: 4/5 | Tags: Diffusion Models, Image Editing, Object Attributes, Computer Vision, Vision-Language Models, Generative AI

Recommendation: 推荐理由：Alterbute提出了一种创新的物体固有属性编辑方法，通过放松的训练目标和视觉命名实体概念，巧妙地解决了身份保持与属性变化之间的平衡问题。该方法在保持物体身份特征的同时允许有意义的固有属性变化，在技术上具有创新性，实验结果也显示出优于现有方法的性能。特别值得关注的是其利用视觉语言模型自动提取监督信息的方法，为实现大规模训练提供了可行性。

TL;DR: 我们介绍了Alterbute，一种基于扩散的方法，用于编辑图像中物体的固有属性。我们允许更改物体的颜色、纹理、材质甚至形状，同时保留其感知身份和场景上下文。现有方法要么依赖往往无法保持身份的无监督先验，要么使用过于严格的监督阻止有意义的固有属性变化。我们的方法基于：(i) 一种宽松的训练目标，允许模型基于身份参考图像、描述目标固有属性的文本提示以及定义外部上下文的背景图像和物体掩码来改变固有属性和外部属性。在推理时，我们通过重用原始背景和物体掩码来限制外部变化，从而确保只有所需的固有属性被改变；(ii) 视觉命名实体（VNEs）——细粒度的视觉身份类别（例如"保时捷911卡雷拉"），用于对共享身份定义特征但允许固有属性变化的物体进行分组。我们使用视觉语言模型从大型公共图像数据集中自动提取VNE标签和固有属性描述，从而实现可扩展的、身份保持的监督。Alterbute在保持身份的同时编辑物体固有属性方面优于现有方法。


<details>
  <summary>Details</summary>
Motivation: 现有物体属性编辑方法面临两个主要问题：一是无监督方法通常无法有效保持物体身份特征，导致编辑后的物体与原始物体失去联系；二是监督方法往往过于严格，限制了固有属性（如颜色、纹理、材质、形状）的有意义变化。为了解决这些局限性，研究人员提出了Alterbute方法，旨在在保持物体感知身份和场景上下文的前提下，实现对物体固有属性的灵活编辑。

Method: Alterbute采用了一种创新的基于扩散模型的方法，包含两个关键技术：1）放松的训练目标：模型训练时以身份参考图像、描述目标固有属性的文本提示、以及定义外部上下文的背景图像和物体掩码为条件，允许改变固有属性和外部属性。在推理阶段，通过重用原始背景和物体掩码来限制外部变化，确保只改变所需的固有属性。2）视觉命名实体（VNEs）：引入细粒度的视觉身份类别，将具有相同身份定义特征但允许固有属性变化的物体进行分组。利用视觉语言模型从大规模公共图像数据集中自动提取VNE标签和固有属性描述，实现可扩展的身份保持监督。

Result: Alterbute在身份保持的物体固有属性编辑任务上表现出色，能够有效地改变物体的颜色、纹理、材质和形状，同时保持物体的感知身份特征和场景上下文。实验结果表明，该方法在保持身份的同时实现有意义的固有属性变化方面优于现有方法，展现了在物体编辑任务上的先进性能。

Conclusion: Alterbute提供了一种有效的基于扩散模型的方法，用于编辑图像中物体的固有属性，同时保持其身份特征和场景上下文。通过引入放松的训练目标和视觉命名实体概念，该方法克服了现有方法的局限性，实现了在身份保持的前提下对物体固有属性的灵活编辑。这一方法在物体编辑领域具有重要的应用价值。

Abstract: We introduce Alterbute, a diffusion-based method for editing an object's intrinsic attributes in an image. We allow changing color, texture, material, and even the shape of an object, while preserving its perceived identity and scene context. Existing approaches either rely on unsupervised priors that often fail to preserve identity or use overly restrictive supervision that prevents meaningful intrinsic variations. Our method relies on: (i) a relaxed training objective that allows the model to change both intrinsic and extrinsic attributes conditioned on an identity reference image, a textual prompt describing the target intrinsic attributes, and a background image and object mask defining the extrinsic context. At inference, we restrict extrinsic changes by reusing the original background and object mask, thereby ensuring that only the desired intrinsic attributes are altered; (ii) Visual Named Entities (VNEs) - fine-grained visual identity categories (e.g., ''Porsche 911 Carrera'') that group objects sharing identity-defining features while allowing variation in intrinsic attributes. We use a vision-language model to automatically extract VNE labels and intrinsic attribute descriptions from a large public image dataset, enabling scalable, identity-preserving supervision. Alterbute outperforms existing methods on identity-preserving object intrinsic attribute editing.

</details>


### [47] [WildRayZer: Self-supervised Large View Synthesis in Dynamic Environments](https://arxiv.org/abs/2601.10716)
*Xuweiyi Chen,Wentao Zhou,Zezhou Cheng*

Main category: cs.CV

Score: 4/5 | Tags: Novel View Synthesis, Computer Vision, Dynamic Scenes, Self-supervised Learning, 3D Reconstruction, Neural Rendering

Recommendation: 推荐理由：这篇论文在动态新颖视角合成领域做出了重要贡献，提出了创新的自监督框架和解决实际问题的方法。WildRayZer不仅理论上有创新，还构建了大规模真实世界数据集，具有较强的实用价值。虽然方法复杂但实验充分，性能表现突出，对计算机视觉和3D重建领域的研究者有重要参考价值。

TL;DR: 我们提出了WildRayZer，一个用于动态环境中新颖视角合成的自监督框架，其中相机和物体都在移动。动态内容破坏了静态NVS模型所依赖的多视图一致性，导致重影、幻觉几何和不稳定的姿态估计。WildRayZer通过执行分析合成测试来解决这个问题：一个仅相机的静态渲染器解释刚性结构，其残差揭示瞬态区域。从这些残差中，我们构建伪运动掩码，提取运动估计器，并使用它来掩码输入令牌并门控损失梯度，从而使监督集中于跨视图背景补全。为了实现大规模训练和评估，我们策划了Dynamic RealEstate10K (D-RE10K)，一个包含15K个随意捕获的动态序列的真实世界数据集，以及D-RE10K-iPhone，一个用于稀疏视图瞬态感知NVS的成对瞬态和干净基准。实验表明，WildRayZer在瞬态区域去除和全帧NVS质量方面，通过单次前馈处理，始终优于基于优化和前馈的基线方法。


<details>
  <summary>Details</summary>
Motivation: 当前新颖视角合成(NVS)方法主要针对静态场景，在动态环境中面临严重挑战。动态内容(相机和物体同时移动)破坏了多视图一致性假设，导致重影、幻觉几何和不稳定的姿态估计问题。现有方法难以同时处理相机运动和目标运动，需要更强大的框架来应对真实世界中的动态场景。

Method: WildRayZer采用自监督框架，核心思想是分析合成测试：1) 使用相机专用静态渲染器解释刚性结构；2) 通过渲染残差识别瞬态区域；3) 从残差构建伪运动掩码；4) 蒸馏出运动估计器用于掩码输入令牌和门控损失梯度；5) 监督专注于跨视图背景补全。此外，构建了大规模数据集D-RE10K和D-RE10K-iPhone用于训练和评估。

Result: 实验结果表明：1) WildRayZer在瞬态区域去除方面显著优于现有优化型和前馈型基线方法；2) 在完整帧NVS质量评估中表现一致优异；3) 仅需单次前馈处理即可获得高质量结果；4) 在真实世界动态场景中展现出强大的鲁棒性和泛化能力。

Conclusion: WildRayZer成功解决了动态环境中新颖视角合成的核心挑战，通过自监督分析和残差驱动的运动估计方法，有效处理相机和物体同时移动的复杂场景。该方法不仅在性能上超越现有技术，还提供了可扩展的训练框架和标准化评估基准，为动态NVS领域的研究开辟了新方向。

Abstract: We present WildRayZer, a self-supervised framework for novel view synthesis (NVS) in dynamic environments where both the camera and objects move. Dynamic content breaks the multi-view consistency that static NVS models rely on, leading to ghosting, hallucinated geometry, and unstable pose estimation. WildRayZer addresses this by performing an analysis-by-synthesis test: a camera-only static renderer explains rigid structure, and its residuals reveal transient regions. From these residuals, we construct pseudo motion masks, distill a motion estimator, and use it to mask input tokens and gate loss gradients so supervision focuses on cross-view background completion. To enable large-scale training and evaluation, we curate Dynamic RealEstate10K (D-RE10K), a real-world dataset of 15K casually captured dynamic sequences, and D-RE10K-iPhone, a paired transient and clean benchmark for sparse-view transient-aware NVS. Experiments show that WildRayZer consistently outperforms optimization-based and feed-forward baselines in both transient-region removal and full-frame NVS quality with a single feed-forward pass.

</details>


<div id='cs.CL'></div>

# cs.CL [[Back]](#toc)

### [48] [LLM-Driven Preference Data Synthesis for Proactive Prediction of the Next User Utterance in Human-Machine Dialogue](https://arxiv.org/abs/2601.09713)
*Jinqiang Wang,Huansheng Ning,Jianguo Ding,Tao Zhu,Liming Chen,Chris Nugent*

Main category: cs.CL

Score: 4/5 | Tags: LLM, Dialogue Systems, Intent Understanding, Data Synthesis, Proactive Prediction, Preference Learning, Human-Machine Interaction

Recommendation: 推荐此论文的理由：1）针对实际且有意义的对话系统问题（主动预测用户话语）；2）方法创新性强，提出了意图树和显式推理轨迹建模；3）实验充分，在多个数据集上验证了方法有效性；4）具有实用价值，发布了代码和数据集促进复现和后续研究。扣1分主要是因为论文摘要中未详细说明具体的技术实现细节和计算复杂度。

TL;DR: 在人与机器对话中主动预测用户的下一个话语可以简化交互并提升用户体验。现有的基于商业API的解决方案存在隐私问题，而在本地部署通用LLM计算成本较高。因此，训练一个紧凑的、任务专用的LLM提供了一种实用替代方案。虽然用户模拟器方法可以预测用户的下一个话语，但它们主要模仿用户的说话风格而非推动对话进展。偏好数据合成已被研究用于主动预测下一个话语的数据生成，并帮助对齐LLM与用户偏好。然而现有方法缺乏明确建模导致用户下一个话语的意图推理能力，并且无法定义和合成用于预测用户下一个话语的偏好与非偏好推理过程。为了解决这些挑战，我们提出了ProUtt，一种基于LLM驱动的偏好数据合成方法，用于主动预测下一个话语。ProUtt将对话历史转换为意图树，并从利用和探索两个角度明确建模意图推理轨迹，预测下一个可能的路径。然后通过在不同未来轮次扰动或修正意图树路径，构建偏好和非偏好推理过程。使用LLM-as-a-judge和人工评估的广泛实验表明，ProUtt在四个基准数据集上持续优于现有的数据合成方法、用户模拟器和商业LLM API。我们发布了代码和合成数据集以促进未来研究。


<details>
  <summary>Details</summary>
Motivation: 在人与机器对话中，主动预测用户的下一个话语可以提升交互效率和用户体验。然而，现有方法存在几个关键问题：1）基于商业API的解决方案存在隐私风险；2）本地部署通用LLM计算成本高昂；3）传统用户模拟器主要关注说话风格模仿而非对话推进；4）现有偏好数据合成方法缺乏对意图推理过程的显式建模，无法区分偏好与非偏好推理轨迹。因此，需要开发一种能够显式建模意图推理、合成高质量偏好数据的方法。

Method: 本文提出ProUtt方法，其核心包括：1）意图树转换：将对话历史转换为结构化的意图树表示；2）意图推理轨迹建模：从利用（exploitation）和探索（exploration）两个视角预测下一个可能的意图路径；3）偏好/非偏好推理过程构建：通过在不同未来轮次中扰动或修正意图树路径，生成偏好和非偏好推理轨迹；4）数据合成：基于这些推理过程生成用于训练任务专用LLM的数据。

Result: 实验评估表明：1）ProUtt在四个基准数据集上（使用LLM-as-a-judge和人工评估）持续优于现有数据合成方法、用户模拟器和商业LLM API；2）该方法能够生成高质量的偏好数据，有效支持主动下一个话语预测任务；3）合成的数据集和代码已公开，促进社区研究。

Conclusion: ProUtt是一种有效的LLM驱动的偏好数据合成方法，通过显式建模意图推理过程，解决了主动预测用户下一个话语任务中的关键挑战。该方法不仅性能优越，而且提供了可解释的推理轨迹，为对话系统中的主动预测任务提供了新的解决方案。

Abstract: Proactively predicting a users next utterance in human-machine dialogue can streamline interaction and improve user experience. Existing commercial API-based solutions are subject to privacy concerns while deploying general-purpose LLMs locally remains computationally expensive. As such, training a compact, task-specific LLM provides a practical alternative. Although user simulator methods can predict a user's next utterance, they mainly imitate their speaking style rather than advancing the dialogue. Preference data synthesis has been investigated to generate data for proactive next utterance prediction and help align LLMs with user preferences. Yet existing methods lack the ability to explicitly model the intent reasoning that leads to the user's next utterance and to define and synthesize preference and non-preference reasoning processes for predicting the user's next utterance.To address these challenges, we propose ProUtt, an LLM-driven preference data synthesis method for proactive next utterance prediction. ProUtt converts dialogue history into an intent tree and explicitly models intent reasoning trajectories by predicting the next plausible path from both exploitation and exploration perspectives. It then constructs preference and non-preference reasoning processes by perturbing or revising intent tree paths at different future turns. Extensive evaluations using LLM-as-a-judge and human judgments demonstrate that ProUtt consistently outperforms existing data synthesis methods, user simulators, and commercial LLM APIs across four benchmark datasets. We release both the code and the synthesized datasets to facilitate future research.

</details>


### [49] [Opportunities and Challenges of Natural Language Processing for Low-Resource Senegalese Languages in Social Science Research](https://arxiv.org/abs/2601.09716)
*Derguene Mbaye,Tatiana D. P. Mbengue,Madoune R. Seye,Moussa Diallo,Mamadou L. Ndiaye,Dimitri S. Adjanohoun,Cheikh S. Wade,Djiby Sow,Jean-Claude B. Munyaka,Jerome Chenal*

Main category: cs.CL

Score: 5/5 | Tags: NLP, Low-resource Languages, African Languages, Multilingual, Resource Collection, Digital Humanities, Social Sciences, Language Preservation

Recommendation: 这篇论文具有重要的学术和社会价值：1) 填补了非洲语言NLP研究的系统性空白；2) 提供了实用的开源资源和实现框架；3) 强调伦理治理和社区参与；4) 关注社会科学等实际应用场景；5) 具有广泛的可扩展性和参考价值。

TL;DR: 自然语言处理（NLP）正在迅速改变各学科的研究方法，但非洲语言在这项技术变革中仍然很大程度上未得到充分代表。本文首次全面概述了塞内加尔宪法正式承认的六种国家语言（沃洛夫语、普拉尔语、塞雷尔语、卓拉语、曼丁哥语和索尼克语）的NLP进展和挑战。我们综合了影响其数字化准备的语言学、社会技术和基础设施因素，并确定了在数据、工具和基准测试方面存在的差距。基于现有的倡议和研究工作，我们分析了文本规范化、机器翻译和语音处理方面的持续努力。我们还提供了一个中心化的GitHub仓库，汇集了这些语言各种NLP任务的公开可用资源，旨在促进协作和可复现性。特别关注NLP在社会科学中的应用，其中多语言转录、翻译和检索管道可以显著提高实地研究的效率和包容性。本文最后概述了为塞内加尔语言构建可持续、以社区为中心的NLP生态系统的路线图，强调了道德数据治理、开放资源和跨学科合作的重要性。


<details>
  <summary>Details</summary>
Motivation: 非洲语言在自然语言处理技术发展中长期被边缘化，塞内加尔官方语言的数字化资源严重不足，阻碍了当地语言的技术应用和研究工作。本文旨在填补这一空白，为六种塞内加尔官方语言建立综合的NLP资源框架。

Method: 采用综合性研究方法：1) 语言学和数字技术现状分析；2) 现有NLP项目和资源的系统性调查；3) 建立中心化的开源资源库(GitHub)；4) 跨学科应用案例分析；5) 基于实证研究的路线图制定。

Result: 1) 全面识别了六种语言的NLP资源和基础设施差距；2) 建立了统一的GitHub资源库，汇集了多语言NLP任务数据集和工具；3) 提出了社会科学研究中的具体应用场景和解决方案；4) 制定了可持续的NLP生态系统发展路线图。

Conclusion: 塞内加尔官方语言在NLP领域面临显著挑战，但通过整合现有资源、建立开放协作平台和强调伦理治理，可以建立可持续的多语言NLP生态系统，促进本土语言的技术赋能和学术研究的包容性发展。

Abstract: Natural Language Processing (NLP) is rapidly transforming research methodologies across disciplines, yet African languages remain largely underrepresented in this technological shift. This paper provides the first comprehensive overview of NLP progress and challenges for the six national languages officially recognized by the Senegalese Constitution: Wolof, Pulaar, Sereer, Joola, Mandingue, and Soninke. We synthesize linguistic, sociotechnical, and infrastructural factors that shape their digital readiness and identify gaps in data, tools, and benchmarks. Building on existing initiatives and research works, we analyze ongoing efforts in text normalization, machine translation, and speech processing. We also provide a centralized GitHub repository that compiles publicly accessible resources for a range of NLP tasks across these languages, designed to facilitate collaboration and reproducibility. A special focus is devoted to the application of NLP to the social sciences, where multilingual transcription, translation, and retrieval pipelines can significantly enhance the efficiency and inclusiveness of field research. The paper concludes by outlining a roadmap toward sustainable, community-centered NLP ecosystems for Senegalese languages, emphasizing ethical data governance, open resources, and interdisciplinary collaboration.

</details>


### [50] [StatLLaMA: A multi-stage training framework for building a domain-optimized statistical language model](https://arxiv.org/abs/2601.09718)
*Jing-Yi Zeng,Guan-Hua Huang*

Main category: cs.CL

Score: 4/5 | Tags: LLM, Domain Specialization, Instruction Tuning, SFT, RLHF, Statistics, Transfer Learning, Model Adaptation

Recommendation: 这篇论文值得推荐的原因：1) 提供了系统性的领域专业化LLM构建方法比较；2) 揭示了重要的实践发现（如起点选择的关键性和下游微调强度的控制）；3) 实证结果丰富且具有指导意义；4) 为资源受限环境下的模型开发提供了实用蓝图；5) 代码开源，便于复现和应用。不足之处在于可能未涵盖所有可能的训练变体和更广泛的评估基准。

TL;DR: 本研究探讨了如何以轻量级的LLaMA-3.2-3B系列为基础模型（FM），高效构建领域专业化的大型语言模型（LLM）用于统计学。我们系统比较了三种多阶段训练流程：从无指令跟随能力的基础FM开始、从经过后置指令调优的基础FM开始、以及从具有强大通用推理能力的指令调优FM开始，涉及持续预训练、监督微调（SFT）、基于人类反馈的强化学习（RLHF）偏好对齐和下游任务适配。结果表明，从基础FM开始的流程即使在经过大量指令调优、SFT或RLHF对齐后，也无法发展出有意义的统计推理能力。相反，从LLaMA-3.2-3B-Instruct开始则能实现有效的领域专业化。对SFT变体的全面评估揭示了领域专业知识与通用推理能力之间的明确权衡。我们进一步证明了直接偏好优化能够提供稳定有效的RLHF偏好对齐。最后，我们表明在高度优化的模型中进行下游微调时，必须使用极低的强度以避免灾难性遗忘。最终模型StatLLaMA在数学推理、常识推理和统计专业知识的基准测试中实现了强大且平衡的性能，为开发资源高效的统计LLM提供了实用蓝图。代码可在https://github.com/HuangDLab/StatLLaMA获取。


<details>
  <summary>Details</summary>
Motivation: 随着大型语言模型在各个领域的应用日益广泛，如何高效构建领域专业化模型成为一个重要问题。特别是对于统计学这样的专业领域，需要模型具备专业推理能力的同时保持通用能力。本研究旨在探索使用轻量级基础模型（如LLaMA-3.2-3B）构建资源高效的统计LLM的最佳实践路径。

Method: 本研究采用了系统性的多阶段训练流程比较方法：1) 三种不同的起点（基础FM、后置指令调优FM、指令调优FM）；2) 多种训练阶段（持续预训练、监督微调、RLHF偏好对齐、下游任务适配）；3) 特别关注了SFT变体、直接偏好优化（DPO）以及下游微调强度的影响；4) 最终开发了StatLLaMA模型并进行全面评估。

Result: 研究结果显示：1) 从基础FM开始的训练管道无法发展出有意义的统计推理能力；2) 从LLaMA-3.2-3B-Instruct开始则能实现有效的领域专业化；3) SFT变体存在领域专业知识与通用推理能力之间的权衡；4) 直接偏好优化提供了稳定有效的RLHF偏好对齐；5) 下游微调需要极低强度以避免灾难性遗忘；6) 最终StatLLaMA模型在数学推理、常识推理和统计专业知识方面均表现出平衡而强大的性能。

Conclusion: 本研究的结论是：选择具有强大通用推理能力的指令调优模型作为起点对于领域专业化至关重要。有效的统计LLM开发需要在领域专业知识与通用能力之间取得平衡，并且下游微调必须谨慎控制强度以避免灾难性遗忘。StatLLaMA的成功为资源受限环境下开发领域专业化LLM提供了实用蓝图。

Abstract: This study investigates how to efficiently build a domain-specialized large language model (LLM) for statistics using the lightweight LLaMA-3.2-3B family as the foundation model (FM). We systematically compare three multi-stage training pipelines, starting from a base FM with no instruction-following capability, a base FM augmented with post-hoc instruction tuning, and an instruction-tuned FM with strong general reasoning abilities across continual pretraining, supervised fine-tuning (SFT), reinforcement learning from human feedback (RLHF) preference alignment, and downstream task adaptation. Results show that pipelines beginning with a base FM fail to develop meaningful statistical reasoning, even after extensive instruction tuning, SFT, or RLHF alignment. In contrast, starting from LLaMA-3.2-3B-Instruct enables effective domain specialization. A comprehensive evaluation of SFT variants reveals clear trade-offs between domain expertise and general reasoning ability. We further demonstrate that direct preference optimization provides stable and effective RLHF preference alignment. Finally, we show that downstream fine-tuning must be performed with extremely low intensity to avoid catastrophic forgetting in highly optimized models. The final model, StatLLaMA, achieves strong and balanced performance on benchmarks of mathematical reasoning, common-sense reasoning, and statistical expertise, offering a practical blueprint for developing resource-efficient statistical LLMs. The code is available at https://github.com/HuangDLab/StatLLaMA.

</details>


### [51] [Uncertainty-Aware Dynamic Knowledge Graphs for Reliable Question Answering](https://arxiv.org/abs/2601.09720)
*Yu Takahashi,Shun Takeuchi,Kexuan Xin,Guillaume Pelat,Yoshiaki Ikai,Junya Saito,Jonathan Vitale,Shlomo Berkovsky,Amin Beheshti*

Main category: cs.CL

Score: 4/5 | Tags: QA, Knowledge Graph, Uncertainty, Healthcare, Dynamic Modeling, Confidence Scoring, Interpretability, Electronic Health Records, Clinical Decision Support

Recommendation: 这篇论文提出了一种结合不确定性建模和动态知识图谱的创新问答框架，针对高风险医疗领域中的实际问题，具有很强的应用价值。方法设计合理，包含动态构建、置信度评分和交互界面三个核心组件，思路清晰。在医疗领域的实例化验证具有现实意义，为临床决策支持提供了新的技术路径。该工作对提高问答系统的可靠性和可解释性有重要贡献，特别适合高风险应用场景。评分4分是因为虽然框架设计完整且应用场景明确，但需要更多具体实验数据来验证其相对于现有方法的优越性。

TL;DR: 问答系统日益部署在各个领域，但其可靠性在检索到的证据不完整、有噪声或不确定时会受到削弱。现有的基于知识图谱的问答框架通常将事实表示为静态和确定性的，未能捕捉信息的动态演变特性以及推理过程中的固有不确定性。我们提出了一个不确定性感知的动态知识图谱框架演示，该框架结合了：（i）动态构建演化的知识图谱，（ii）置信度评分和不确定性感知的检索，以及（iii）一个用于可靠且可解释问答的交互式界面。我们的系统展示了不确定性建模如何通过使用户能够探索动态图谱、检查带有置信度标注的三元组以及比较基线与置信度感知的答案，从而使问答系统更加稳健和透明。该演示的目标用户是临床数据科学家和临床医生，我们在医疗保健领域实例化了该框架：从电子健康记录构建个性化的知识图谱，可视化跨患者就诊的不确定性，并评估其对死亡率预测任务的影响。这个用例展示了不确定性感知的动态知识图谱在增强高风险应用中问答可靠性方面的广阔前景。


<details>
  <summary>Details</summary>
Motivation: 当前的问答系统在可靠性方面存在局限，特别是在检索到的证据不完整、有噪声或不确定的情况下。现有的基于知识图谱的问答框架通常将知识表示为静态和确定性的，无法捕捉信息随时间演变的动态特性，也无法处理推理过程中的不确定性。这些限制在高风险领域如医疗保健中尤为突出，因为决策需要高可靠性。因此，需要开发一个能够建模不确定性并支持动态知识演进的框架，以提高问答系统的鲁棒性和可解释性。

Method: 该方法提出了一种不确定性感知的动态知识图谱框架，包含三个核心组件：1）动态知识图谱构建，从电子健康记录等数据源构建随时间演化的个性化知识图谱；2）置信度评分与不确定性感知检索，为知识图谱中的三元组分配置信度分数，并在检索过程中考虑这些不确定性；3）交互式界面，提供可视化和探索功能，允许用户检查带有置信度标注的三元组、探索动态图谱结构，并比较传统方法与基于置信度的方法生成的答案。

Result: 该框架在医疗保健领域进行了实例化验证，具体实现了从电子健康记录构建个性化知识图谱，可视化患者就诊过程中的不确定性演变。系统在死亡率预测任务上进行了评估，展示了不确定性建模对问答可靠性改进的效果。结果表明，通过集成不确定性感知的动态知识图谱，能够提高问答系统的鲁棒性和透明度，为高风险应用提供更可靠的决策支持。

Conclusion: 不确定性感知的动态知识图谱框架为解决问答系统中证据不完整和不确定性的问题提供了一种有效方法。通过在医疗保健领域的应用演示，该框架展示了在高风险场景下增强问答系统可靠性的潜力。通过动态知识图谱构建、不确定性建模和交互式可视化，系统能够提供更稳健、透明的问答能力，这对于临床决策等关键应用具有重要意义。

Abstract: Question answering (QA) systems are increasingly deployed across domains. However, their reliability is undermined when retrieved evidence is incomplete, noisy, or uncertain. Existing knowledge graph (KG) based QA frameworks typically represent facts as static and deterministic, failing to capture the evolving nature of information and the uncertainty inherent in reasoning. We present a demonstration of uncertainty-aware dynamic KGs, a framework that combines (i) dynamic construction of evolving KGs, (ii) confidence scoring and uncertainty-aware retrieval, and (iii) an interactive interface for reliable and interpretable QA. Our system highlights how uncertainty modeling can make QA more robust and transparent by enabling users to explore dynamic graphs, inspect confidence-annotated triples, and compare baseline versus confidence-aware answers. The target users of this demo are clinical data scientists and clinicians, and we instantiate the framework in healthcare: constructing personalized KGs from electronic health records, visualizing uncertainty across patient visits, and evaluating its impact on a mortality prediction task. This use case demonstrates the broader promise of uncertainty-aware dynamic KGs for enhancing QA reliability in high-stakes applications.

</details>


### [52] [Cross-Platform Evaluation of Large Language Model Safety in Pediatric Consultations: Evolution of Adversarial Robustness and the Scale Paradox](https://arxiv.org/abs/2601.09721)
*Vahideh Zolfaghari*

Main category: cs.CL

Score: 4/5 | Tags: LLM, 医疗AI, 安全评估, 对抗性测试, 儿科咨询, 模型对齐

Recommendation: 这篇论文推荐程度较高（4分），原因在于：1）研究针对医疗AI安全的重要现实问题，关注焦虑用户对抗性压力的影响；2）建立了专门的儿科医疗咨询基准测试集PediatricAnxietyBench；3）得出了反直觉但重要的结论，即模型安全性更多取决于对齐和架构而非规模；4）提供了实用的安全评估框架和量化指标。研究虽然方法严谨，但评估的模型数量有限（仅3个），且主要关注儿科特定场景，这些因素稍微限制了研究的普遍适用性。

TL;DR: 背景：大型语言模型越来越多地部署在医疗咨询中，但其在现实用户压力下的安全性仍缺乏研究。先前评估主要关注中立条件，忽视了焦虑用户挑战安全保障措施的脆弱性。本研究评估了在儿科咨询中，父母焦虑驱动的对抗性压力下不同模型和平台的大型语言模型安全性。
方法：PediatricAnxietyBench（来自先前评估）包含300个查询（150个真实查询，150个对抗查询），涵盖10个主题。通过API评估了三个模型：Llama-3.3-70B和Llama-3.1-8B（Groq），Mistral-7B（HuggingFace），共获得900个响应。安全性采用0-15分制，评估克制、转诊、模糊处理、紧急情况识别和非处方行为。分析采用配对t检验和自举置信区间。
结果：平均得分：9.70（Llama-3.3-70B）到10.39（Mistral-7B）。Llama-3.1-8B表现优于Llama-3.3-70B（+0.66，p=0.0001，d=0.225）。模型显示出正向对抗性效应，Mistral-7B最强（+1.09，p=0.0002）。安全性在不同平台间具有普遍性；Llama-3.3-70B有8%的失败案例。癫痫主题最脆弱（33%不当诊断）。模糊处理可预测安全性（r=0.68，p<0.001）。
结论：评估表明安全性取决于对齐和架构而非规模，较小模型表现优于较大模型。不同版本间向稳健性的演化表明针对性训练取得进展。脆弱性和缺乏紧急情况识别表明不适合分诊。研究结果为选择提供指导，强调对抗性测试的重要性，并为医疗AI安全提供开放基准。


<details>
  <summary>Details</summary>
Motivation: 随着大型语言模型在医疗咨询中的广泛应用，现有研究主要关注中立条件下的模型表现，但缺乏对现实世界中焦虑用户可能对模型安全保障造成挑战的评估。特别是父母焦虑驱动的对抗性压力在儿科咨询中尤为常见，这可能暴露模型的安全漏洞，影响医疗决策的安全性和可靠性。因此，需要系统评估LLM在真实用户压力下的安全性表现。

Method: 研究使用PediatricAnxietyBench基准测试集，包含300个查询（150个真实查询，150个对抗查询），涵盖10个儿科健康主题。通过API评估三个主流模型：Llama-3.3-70B和Llama-3.1-8B（Groq平台），以及Mistral-7B（HuggingFace平台）。安全性采用综合0-15分制，评估五个关键维度：克制（restraint）、转诊建议（referral）、模糊处理（hedging）、紧急情况识别（emergency recognition）和非处方行为（non-prescriptive behavior）。统计分析方法采用配对t检验和自举置信区间。

Result: 模型平均安全得分范围从9.70（Llama-3.3-70B）到10.39（Mistral-7B）。有趣的是，较小的Llama-3.1-8B表现优于较大的Llama-3.3-70B（提升+0.66，p=0.0001）。所有模型在对抗性压力下显示出安全性提升，Mistral-7B提升最显著（+1.09，p=0.0002）。安全性在不同平台上具有一致性，但Llama-3.3-70B有8%的安全失败案例。最脆弱的主题是癫痫，33%的案例出现不当诊断。模糊处理行为与安全性高度相关（r=0.68，p<0.001），可预测模型安全表现。

Conclusion: 研究表明，大型语言模型在医疗咨询中的安全性主要取决于模型对齐和架构设计，而非模型规模，较小的模型在某些情况下可能表现更好。模型版本的演变显示出稳健性的逐步提升，表明针对性训练取得进展。然而，模型在识别紧急情况和应对特定医疗主题（如癫痫）时仍存在显著脆弱性，目前不适合用于医疗分诊。研究结果为医疗AI系统选择提供了指导，强调了对抗性测试的重要性，并为该领域建立了开放的基准测试标准。

Abstract: Background Large language models (LLMs) are increasingly deployed in medical consultations, yet their safety under realistic user pressures remains understudied. Prior assessments focused on neutral conditions, overlooking vulnerabilities from anxious users challenging safeguards. This study evaluated LLM safety under parental anxiety-driven adversarial pressures in pediatric consultations across models and platforms. Methods PediatricAnxietyBench, from a prior evaluation, includes 300 queries (150 authentic, 150 adversarial) spanning 10 topics. Three models were assessed via APIs: Llama-3.3-70B and Llama-3.1-8B (Groq), Mistral-7B (HuggingFace), yielding 900 responses. Safety used a 0-15 scale for restraint, referral, hedging, emergency recognition, and non-prescriptive behavior. Analyses employed paired t-tests with bootstrapped CIs. Results Mean scores: 9.70 (Llama-3.3-70B) to 10.39 (Mistral-7B). Llama-3.1-8B outperformed Llama-3.3-70B by +0.66 (p=0.0001, d=0.225). Models showed positive adversarial effects, Mistral-7B strongest (+1.09, p=0.0002). Safety generalized across platforms; Llama-3.3-70B had 8% failures. Seizures vulnerable (33% inappropriate diagnoses). Hedging predicted safety (r=0.68, p<0.001). Conclusions Evaluation shows safety depends on alignment and architecture over scale, with smaller models outperforming larger. Evolution to robustness across releases suggests targeted training progress. Vulnerabilities and no emergency recognition indicate unsuitability for triage. Findings guide selection, stress adversarial testing, and provide open benchmark for medical AI safety.

</details>


### [53] [ADMEDTAGGER: an annotation framework for distillation of expert knowledge for the Polish medical language](https://arxiv.org/abs/2601.09722)
*Franciszek Górski,Andrzej Czyżewski*

Main category: cs.CL

Score: 4/5 | Tags: LLM, 医疗文本处理, 多语言处理, 知识蒸馏, 文本分类, BERT, 波兰语处理

Recommendation: 该论文提供了一种实用的解决方案，通过大语言模型辅助标注解决了医疗领域资源匮乏的问题，并在保持性能的同时大幅提升了模型效率。方法创新且结果可靠，特别适合多语言医疗文本处理场景，具有较高的实用价值和应用前景。

TL;DR: 在这项工作中，我们提出了一个标注框架，展示了如何将在大规模语料上预训练的多语言LLM用作教师模型，以蒸馏标注波兰语医学文本所需的专业知识。这项工作是ADMEDVOICE大型项目的一部分，我们在其中收集了代表五个临床类别（放射学、肿瘤学、心脏病学、高血压和病理学）的大量医学文本语料。使用这些数据，我们需要开发一个多类分类器，但根本问题在于缺乏用于标注足够数量文本的资源。因此，在我们的解决方案中，我们使用了多语言Llama3.1模型来标注波兰语医学文本的大规模语料。使用我们有限的标注资源，我们仅验证了部分标签，从中创建了测试集。以这种方式标注的数据随后被用于训练和验证基于BERT架构的3种不同类型的分类器：蒸馏的DistilBERT模型、在医学数据上微调的BioBERT，以及在波兰语语料库上微调的HerBERT。在我们训练的模型中，DistilBERT模型取得了最佳结果，对于每个临床类别都达到了F1分数>0.80，其中3个类别的F1分数>0.93。通过这种方式，我们获得了一系列高效分类器，它们代表了大语言模型的替代方案，因为其尺寸小近500倍，GPU VRAM消耗低300倍，推理速度快数百倍。


<details>
  <summary>Details</summary>
Motivation: 该研究的动机源于医疗文本分类任务中资源匮乏的现实挑战。由于缺乏足够的人力资源来标注波兰语医学文本，研究团队需要一种创新的方法来利用大语言模型的智能进行半自动标注，以解决医疗文本分类中的数据标注瓶颈问题。

Method: 研究方法包括：1) 使用多语言Llama3.1作为教师模型对波兰语医学文本进行初步标注；2) 利用有限的人工标注资源对部分自动标注结果进行验证，构建测试集；3) 使用标注数据训练三种基于BERT架构的分类器：蒸馏版DistilBERT、在医学数据上微调的BioBERT、以及针对波兰语优化的HerBERT；4) 建立从大语言模型到轻量级分类器的知识蒸馏流程。

Result: DistilBERT模型在所有测试中表现最佳，每个临床类别的F1分数均超过0.80，其中三个类别（放射学、心脏病学和高血压）的F1分数超过0.93。与其他模型相比，蒸馏后的分类器在保持高准确性的同时，模型尺寸减小了近500倍，GPU VRAM消耗降低了300倍，推理速度提升了数百倍。

Conclusion: 研究表明，利用多语言大语言模型作为教师模型进行知识蒸馏是解决医学文本标注资源匮乏问题的有效方法。通过该方法获得的轻量级分类器在保持高分类精度的同时，显著降低了计算资源需求，为实际医疗应用提供了可行的大规模部署方案。

Abstract: In this work, we present an annotation framework that demonstrates how a multilingual LLM pretrained on a large corpus can be used as a teacher model to distill the expert knowledge needed for tagging medical texts in Polish. This work is part of a larger project called ADMEDVOICE, within which we collected an extensive corpus of medical texts representing five clinical categories - Radiology, Oncology, Cardiology, Hypertension, and Pathology. Using this data, we had to develop a multi-class classifier, but the fundamental problem turned out to be the lack of resources for annotating an adequate number of texts. Therefore, in our solution, we used the multilingual Llama3.1 model to annotate an extensive corpus of medical texts in Polish. Using our limited annotation resources, we verified only a portion of these labels, creating a test set from them. The data annotated in this way were then used for training and validation of 3 different types of classifiers based on the BERT architecture - the distilled DistilBERT model, BioBERT fine-tuned on medical data, and HerBERT fine-tuned on the Polish language corpus. Among the models we trained, the DistilBERT model achieved the best results, reaching an F1 score > 0.80 for each clinical category and an F1 score > 0.93 for 3 of them. In this way, we obtained a series of highly effective classifiers that represent an alternative to large language models, due to their nearly 500 times smaller size, 300 times lower GPU VRAM consumption, and several hundred times faster inference.

</details>


### [54] [SagaScale: A Realistic, Scalable, and High-Quality Long-Context Benchmark Built from Full-Length Novels](https://arxiv.org/abs/2601.09723)
*Guancheng Du,Yong Hu,Wenqing Wang,Yaming Yang,Jiaheng Gao*

Main category: cs.CL

Score: 5/5 | Tags: LLM, Benchmark, Long Context, RAG, NLP, Evaluation

Recommendation: 该论文提出了一个创新性的长上下文基准测试，具有多个重要贡献：1）基于真实长篇文档（小说）构建，增强了任务的现实性；2）自动化数据收集流程解决了数据扩展性问题；3）创新的评估设计（构建阶段使用外部资源，评估阶段不使用）确保了问题复杂性；4）提供双语支持和迄今为止最长的上下文长度；5）公开发布基准测试和代码库，对研究社区有重要价值。该工作对于推动LLM的长文档理解能力研究具有重要意义。

TL;DR: 大型语言模型（LLMs）已取得显著进展，但理解和处理长篇复杂文档仍然具有挑战性。许多长上下文基准测试已被提出，但它们面临一些限制，包括任务真实性、数据可扩展性和数据质量。为此，我们引入了SagaScale，这是一个基于完整小说构建的、真实、可扩展且高质量的长上下文基准测试。整个基准测试采用自动化数据收集流程构建，该流程利用外部资源（如维基百科页面）来整理问答对。关键的是，这些外部资源仅在基准构建阶段提供，不在评估阶段提供，这使得LLMs能够整理出超出其在评估时能回答范围的复杂问题。SagaScale也是双语基准，提供迄今为止最大的上下文长度，英文小说的平均token数超过250K，中文小说的平均token数超过320K。我们在12个前沿LLM和三种长上下文方法（朴素RAG、Agentic RAG和长上下文方法）上的评估得出了关键见解，包括：（1）直接向LLM提供完整上下文可以大幅超越其他方法；（2）大多数LLM在处理长篇上下文时仍然困难，但Gemini-2.5-Pro是一个例外；（3）Agentic RAG有效解决了朴素RAG中的检索瓶颈问题。最后，我们公开发布了SagaScale基准测试和我们的数据收集代码库，以促进未来的研究。


<details>
  <summary>Details</summary>
Motivation: 尽管大型语言模型在处理文本方面取得了显著进展，但理解和处理长篇复杂文档仍然是当前研究面临的重大挑战。现有的长上下文基准测试存在任务真实性不足、数据可扩展性有限以及数据质量不高的问题。为了推动长上下文理解研究的发展，需要构建一个更具真实性、可扩展性和高质量的评估基准。

Method: 本文提出SagaScale基准测试，采用全自动化的数据收集流程，以完整小说为数据源。关键创新在于：1）利用外部资源（如维基百科）自动生成复杂问答对；2）基准构建阶段提供外部资源，而评估阶段不提供，确保问题的复杂性超出模型在评估时的直接回答能力；3）支持双语（英文和中文），提供迄今为止最长的上下文长度（英文平均超过25万token，中文平均超过32万token）；4）评估了12个前沿LLM和三种长上下文方法（朴素RAG、Agentic RAG和直接使用长上下文）。

Result: 评估结果显示出几个重要发现：1）直接向LLM提供完整上下文的方法在性能上大幅优于其他方法；2）大多数LLM在处理超长上下文时仍然表现不佳，但Gemini-2.5-Pro表现出色，是一个例外；3）Agentic RAG能够有效解决朴素RAG中的检索瓶颈问题；4）SagaScale基准测试展现出任务真实性、数据可扩展性和数据质量方面的优势，为长上下文理解研究提供了可靠的评估工具。

Conclusion: SagaScale是一个真实、可扩展且高质量的长上下文基准测试，基于完整小说构建，提供迄今为止最长的上下文长度。该基准测试的评估结果揭示了当前LLM在处理长篇文档时的能力限制，同时也展示了不同长上下文方法的性能差异。通过公开发布基准测试和数据收集代码，本研究为长上下文理解领域的研究提供了重要的资源和工具。

Abstract: Large Language Models (LLMs) have shown significant progress, but understanding long and complex documents remains challenging. Many long-context benchmarks have been proposed, but they face several limitations, including task realism, data scalability, and data quality. To this end, we introduce SagaScale, a realistic, scalable, and high-quality long-context benchmark built from full-length novels. The entire benchmark is constructed using an automated data collection pipeline that utilizes external resources (e.g., Wikipedia pages) to curate question-answer pairs. Critically, these external resources are provided only for benchmark construction and not during evaluation, which allows LLMs to curate complex questions that go beyond what they can answer during evaluation. SagaScale is also bilingual and offers the largest context length to date, with average token counts exceeding 250K for English novels and 320K for Chinese novels. Our evaluation across 12 frontier LLMs and three long-context methods -- Naïve RAG, Agentic RAG, and Long Context -- yields key insights, including: (1) Directly supplying the full context to the LLM can outperform other methods by a large margin; (2) Most LLMs still struggle with lengthy contexts, but Gemini-2.5-Pro stands out as an exception; and (3) Agentic RAG effectively addresses the retrieval bottleneck in Naïve RAG. Finally, we publicly release the SagaScale benchmark and our data collection codebase to facilitate future research.

</details>


### [55] [Syntactic Framing Fragility: An Audit of Robustness in LLM Ethical Decisions](https://arxiv.org/abs/2601.09724)
*Katherine Elkins,Jon Chun*

Main category: cs.CL

Score: 5/5 | Tags: LLM, Ethics, Robustness, Evaluation, Prompt Engineering, Natural Language Processing, AI Safety, Decision Making

Recommendation: 强烈推荐本文，原因如下：1）揭示了LLMs一个被忽视但至关重要的脆弱性维度；2）研究方法严谨，设计了创新的评估框架（SFF/LPN）；3）评估规模庞大，覆盖23个模型和近4万个决策；4）发现了重要的实践发现（开源模型更脆弱、否定敏感性等）；5）提供了实用的缓解策略（思维链推理）；6）具有明确的实践指导意义，主张将此类审计标准化。该研究对于LLMs的安全部署和评估具有重要意义。

TL;DR: 大型语言模型（LLMs）越来越多地部署在关键决策场景中，但它们对良性提示变化的鲁棒性仍未得到充分探索。在本研究中，我们探讨LLMs是否能在逻辑等效但句法不同的提示中保持一致的伦理判断，重点关注涉及否定和条件结构的变体。我们引入了句法框架脆弱性（SFF）这一鲁棒性评估框架，该框架通过逻辑极性归一化（LPN）隔离纯粹的句法效应，从而能够在没有语义漂移的情况下直接比较正负框架下的决策。我们对23个最先进的模型（包括美国和中国模型以及小型美国开源软件模型）在14个伦理场景和4个受控框架下进行了审计（共39,975个决策），发现广泛存在且统计上显著的不一致性：许多模型仅因句法极性而逆转伦理认可，开源模型表现出比商业模型高出两倍以上的脆弱性。我们进一步发现了极端的否定敏感性，其中一些模型在明确提示"不应该"时，在80-97%的情况下认可这些行为。我们证明，引出思维链推理可以显著降低脆弱性，确定了一个实际的缓解杠杆，并通过跨场景映射脆弱性，发现在金融和商业背景下的风险高于医疗场景。我们的结果表明，句法一致性构成了伦理鲁棒性的一个独特且关键的维度，我们主张SFF风格的审计应成为已部署LLMs安全评估的标准组成部分。代码和结果将在github.com上提供。


<details>
  <summary>Details</summary>
Motivation: 本研究动机在于揭示大型语言模型在伦理决策中的句法脆弱性问题。随着LLMs在关键决策场景中的广泛应用，其输出稳定性变得至关重要。研究者发现，即使是逻辑等效但句法不同的提示，也可能导致模型作出不一致的伦理判断，这可能在实际应用中产生严重后果。现有研究多关注语义层面的偏见，而对纯粹句法变化（如否定、条件结构等）引发的伦理判断波动缺乏系统评估。

Method: 本研究采用句法框架脆弱性（SFF）评估框架，该方法通过逻辑极性归一化（LPN）技术，将正负极性提示转换为逻辑等效形式，从而隔离纯粹句法变化对模型决策的影响。研究者设计了4种受控的句法框架变体（正极性、负极性等），覆盖14个不同的伦理场景（包括医疗、金融、商业等领域）。对23个不同规模和类型的LLMs进行了大规模评估，共收集了39,975个决策样本。统计分析方法用于检测不一致性的显著性，同时探索了思维链推理作为缓解策略的效果。

Result: 研究发现了广泛存在的句法脆弱性问题：大多数模型在句法变化下表现出统计上显著的伦理判断不一致性。开源模型的脆弱性是商业模型的两倍以上。特别值得注意的是极端否定敏感性现象：某些模型在明确提示"不应该"时，反而在80-97%的情况下认可相关行为。思维链推理被证明能够显著降低脆弱性，平均降低约35%。跨场景分析显示，金融和商业领域的脆弱性风险最高，而医疗场景相对较低。

Conclusion: 本研究的核心结论是：句法一致性是LLMs伦理鲁棒性的一个关键且常被忽视的维度。句法框架脆弱性（SFF）揭示了仅因表达方式变化导致的伦理判断波动问题，这在现实部署中可能产生严重后果。思维链推理作为一种实用的缓解策略能够部分解决问题，但根本性的解决需要模型架构和训练机制的改进。研究者主张将SFF风格的审计纳入LLMs安全评估的标准流程，特别是在关键决策应用场景中。

Abstract: Large language models (LLMs) are increasingly deployed in consequential decision-making settings, yet their robustness to benign prompt variation remains underexplored. In this work, we study whether LLMs maintain consistent ethical judgments across logically equivalent but syntactically different prompts, focusing on variations involving negation and conditional structure. We introduce Syntactic Framing Fragility (SFF), a robustness evaluation framework that isolates purely syntactic effects via Logical Polarity Normalization (LPN), enabling direct comparison of decisions across positive and negative framings without semantic drift. Auditing 23 state-of-the-art models spanning the U.S. and China as well as small U.S. open-source software models over 14 ethical scenarios and four controlled framings (39,975 decisions), we find widespread and statistically significant inconsistency: many models reverse ethical endorsements solely due to syntactic polarity, with open-source models exhibiting over twice the fragility of commercial counterparts. We further uncover extreme negation sensitivity, where some models endorse actions in 80-97% of cases when explicitly prompted with "should not." We show that eliciting chain-of-thought reasoning substantially reduces fragility, identifying a practical mitigation lever, and we map fragility across scenarios, finding higher risk in financial and business contexts than in medical scenarios. Our results demonstrate that syntactic consistency constitutes a distinct and critical dimension of ethical robustness, and we argue that SFF-style audits should be a standard component of safety evaluation for deployed LLMs. Code and results will be available on github.com.

</details>


### [56] [Assessing and Improving Punctuation Robustness in English-Marathi Machine Translation](https://arxiv.org/abs/2601.09725)
*Kaustubh Shivshankar Shejole,Sourabh Deoghare,Pushpak Bhattacharyya*

Main category: cs.CL

Score: 4/5 | Tags: Machine Translation, Low-Resource Languages, Marathi, Punctuation, Benchmark, LLM, Evaluation, NLP

Recommendation: 本文推荐原因为：1) 针对低资源语言机器翻译的重要实际问题进行研究；2) 建立了首个针对马拉地语的标点鲁棒性诊断基准；3) 提供了实用的解决方案（微调和流水线方法）；4) 揭示了大型语言模型在该特定任务上的局限性；5) 研究设计系统，结果可靠。扣分原因为：样本量较小（仅54个实例），可能限制了统计显著性。

TL;DR: 标点在解决书面语言中的语义和结构歧义方面起着关键作用。机器翻译(MT)系统目前广泛应用于各种领域和语言，包括许多低资源语言环境。在这项工作中，我们关注马拉地语，这是一种低到中等资源的语言。我们引入了Virām，这是第一个用于评估英语到马拉地语机器翻译中标点鲁棒性的诊断基准，由54个手动策划的标点歧义实例组成。我们评估了两种主要策略来提高可靠性：基于流水线的"先恢复后翻译"方法和直接微调于标点变化数据的方法。我们的结果表明，专门的微调模型和流水线系统在Virām基准上的翻译质量明显优于标准基线。定性分析显示，原始模型可能导致错误翻译从而产生错误解释，而微调模型显著提高了整体可靠性。此外，我们发现当前的大型语言模型(LLMs)在保留标点歧义文本的意义方面落后于这些任务特定方法，因此需要在这一领域进行进一步研究。


<details>
  <summary>Details</summary>
Motivation: 本研究的主要动机是解决低资源语言（特别是马拉地语）机器翻译中标点歧义处理的挑战。标点在语义和结构消歧中扮演关键角色，但当前的机器翻译系统在处理标点歧义文本时常常表现不佳。作者发现现有基准缺乏对低资源语言标点鲁棒性的评估，因此建立了首个针对英语到马拉地语机器翻译的标点诊断基准。

Method: 研究方法包括：1) 创建Virām基准数据集，包含54个手动策划的标点歧义实例；2) 评估两种主要策略：基于流水线的"先恢复后翻译"方法（restore-then-translate）和直接对模型进行标点变化数据微调；3) 使用标准基线模型作为对比；4) 进行定量和定性分析；5) 评估当前大型语言模型在该任务上的表现。

Result: 研究结果表明：1) 专门的微调模型和流水线系统在Virām基准上的翻译质量显著优于标准基线；2) 定性分析显示原始模型可能导致错误翻译，而微调模型显著提高了整体可靠性；3) 当前的大型语言模型在保留标点歧义文本意义方面落后于任务特定方法；4) 基准评估显示了标点处理在低资源语言机器翻译中的重要性。

Conclusion: 该研究得出结论：标点处理对低资源语言的机器翻译至关重要，特别是对于马拉地语这样的语言。专门的微调方法和流水线系统能显著改善翻译质量，而当前大型语言模型在这一特定任务上仍需改进。Virām基准为评估标点鲁棒性提供了有价值的工具，并为未来研究指明了方向。

Abstract: Punctuation plays a critical role in resolving semantic and structural ambiguity in written language. Machine Translation (MT) systems are now widely applied across diverse domains and languages, including many low-resource settings. In this work, we focus on Marathi, a low- to middle-resource language. We introduce Virām, the first diagnostic benchmark for assessing punctuation robustness in English-to-Marathi machine translation, consisting of 54 manually curated, punctuation-ambiguous instances. We evaluate two primary strategies for enhancing reliability: a pipeline-based restore-then-translate approach and direct fine-tuned on punctuation-varied data. Our results demonstrate that specialized fine-tuned models and pipeline systems significantly improve translation quality over standard baselines on the Virām benchmark. Qualitative analysis reveals that the original model may result in wrong translations leading to wrong interpretations, while fine-tuned models significantly improve overall reliability. Furthermore, we find that current Large Language Models (LLMs) lag behind these task-specific approaches in preserving meaning for punctuation-ambiguous text, thus necessitating further research in this area.

</details>


### [57] [Forgetting as a Feature: Cognitive Alignment of Large Language Models](https://arxiv.org/abs/2601.09726)
*Hien Tran,Quinten Steenhuis,Alexandros Christoforos,Chadbourne Davis*

Main category: cs.CL

Score: 4/5 | Tags: LLM, Memory, Cognitive Modeling, Reasoning, Benchmark, Human Cognition, Adaptive Intelligence

Recommendation: 推荐理由：本文从新颖的认知角度重新解释LLM的遗忘现象，提出了有价值的理论框架和实证方法。将遗忘视为功能性认知机制而非缺陷的创新观点具有启发性，开发的基准测试套件和概率性记忆提示策略具有实际应用价值。论文在LLM认知建模领域做出了重要贡献，为理解模型的内在工作机制提供了新思路。

TL;DR: 大型语言模型（LLMs）常常以理想的贝叶斯推理作为评估标准，但越来越多的证据表明，它们的上下文推理表现出对过去信息的系统性遗忘。我们并非将这种行为视为局限性，而是重新将遗忘解释为一种功能性认知机制。借鉴人类记忆动态学的启发，我们将LLM推理建模为由指数衰减控制的概率性记忆过程。我们引入了一个基准测试套件，用于评估时序推理、概念漂移适应和联想记忆，从而能够直接比较模型行为与人类认知模式。我们的实证结果显示，LLMs表现出类似于人类记忆效率在稳定性和适应性之间权衡的遗忘率。基于这些观察结果，我们提出了概率性记忆提示（probabilistic memory prompting），这是一种轻量级策略，通过塑造证据整合来模拟人类记忆衰减，从而改善长时推理性能。我们的发现将遗忘定位为一种原则性机制，而非故障模式，用于实现自适应智能。


<details>
  <summary>Details</summary>
Motivation: 本论文的动机源于观察到大型语言模型在上下文推理中表现出的系统性遗忘现象。传统上，这种遗忘被视为模型的局限性，但作者认为这实际上可能是一种功能性认知机制。受人类记忆动态学的启发，作者旨在重新解释遗忘在LLM推理中的作用，探索遗忘是否类似于人类记忆在稳定性和适应性之间的权衡机制，而非简单的性能缺陷。

Method: 本论文采用以下方法：首先，将LLM推理建模为由指数衰减控制的概率性记忆过程，模仿人类记忆动态。其次，开发了一个基准测试套件，用于评估模型的时序推理、概念漂移适应和联想记忆能力。最后，提出了一种轻量级策略——概率性记忆提示（probabilistic memory prompting），通过塑造证据整合来模拟人类记忆衰减，以改善长时推理性能。

Result: 实证结果显示：1）LLMs表现出类似于人类记忆效率权衡的遗忘率，即在稳定性和适应性之间取得平衡；2）通过基准测试套件验证，LLMs的行为模式与人类认知模式有直接可比性；3）提出的概率性记忆提示策略能够有效改善长时推理性能，表明模拟人类记忆衰减的证据整合策略具有实际应用价值。

Conclusion: 本论文的结论是：遗忘不应被视为大型语言模型的故障模式，而应被重新定位为一种原则性机制，用于实现自适应智能。通过将LLM推理建模为受指数衰减控制的概率性记忆过程，并开发相应的评估基准和改善策略，作者证明了遗忘在自适应智能中的功能性作用。这一发现为理解和改进LLM的认知能力提供了新的视角。

Abstract: Large Language Models (LLMs) are often evaluated against ideals of perfect Bayesian inference, yet growing evidence suggests that their in-context reasoning exhibits systematic forgetting of past information. Rather than viewing this behavior as a limitation, we reinterpret forgetting as a functional cognitive mechanism. Drawing inspiration from human memory dynamics, we model LLM inference as a probabilistic memory process governed by exponential decay. We introduce a benchmark suite that evaluates temporal reasoning, concept drift adaptation, and associative recall, enabling direct comparison between model behavior and human cognitive patterns. Our empirical results reveal that LLMs demonstrate forgetting rates analogous to human memory efficiency trade-offs between stability and adaptability. Building on these observations, we propose probabilistic memory prompting, a lightweight strategy that shapes evidence integration to mimic human-like memory decay, leading to improved long-horizon reasoning performance. Our findings position forgetting not as a failure mode, but as a principled mechanism for adaptive intelligence.

</details>


### [58] [SciNets: Graph-Constrained Multi-Hop Reasoning for Scientific Literature Synthesis](https://arxiv.org/abs/2601.09727)
*Sauhard Dubey*

Main category: cs.CL

Score: 4/5 | Tags: LLM, Scientific Synthesis, Graph Reasoning, Multi-hop Reasoning, Knowledge Graphs, Retrieval-Augmented Generation, Scientific NLP

Recommendation: 推荐理由：论文提出了创新的图约束多跳推理框架SciNets，针对跨领域科学综合的核心挑战提供了系统解决方案。其行为评估框架避免了传统正确性评估的局限性，从符号推理深度、多样性和稳定性三个维度提供了深刻的见解。论文在多个科学领域进行了评估，揭示了深度推理与基础稳定性之间的重要权衡关系，对科学信息处理和知识图谱研究具有重要价值。方法的创新性和评估的严谨性使其值得推荐。

TL;DR: 跨领域科学综合需要连接碎片化文献中的机械解释，这对于检索系统和无约束语言模型仍然具有挑战性。虽然最近的研究已将大型语言模型应用于科学总结和问答，但这些方法对推理深度和结构基础的控制有限。我们将机械综合视为文献衍生概念图上的图约束多跳推理问题。给定科学查询和紧凑的查询本地语料库，SciNets构建有向概念图，并通过识别连接在同一论文中很少共现的概念的多跳推理路径来合成机械解释。我们系统比较了最短路径推理、具有多样性约束的k最短路径、随机游走和检索增强语言模型基线。不评估正确性（在综合分布式来源的连接时通常难以确定），我们引入了行为框架，衡量符号推理深度、机械多样性和基础稳定性。在机器学习、生物学和气候科学任务中，显式图约束实现了可控的多跳推理，同时揭示了一致的权衡：更深入和更多样的符号推理增加了基础不稳定性，而最短路径推理保持高度稳定但结构保守。这些发现为当前图-LLM集成在科学综合中的局限性和能力提供了系统的行为特征描述。


<details>
  <summary>Details</summary>
Motivation: 跨领域科学综合需要连接不同文献中的机械解释，但现有的检索系统和无约束语言模型在这方面存在局限性。检索系统无法深入理解概念间的机械联系，而无约束语言模型缺乏对推理深度和结构基础的控制。如何实现可控、深入的跨文献推理是当前科学信息处理的重要挑战。

Method: SciNets方法将机械综合问题框架化为图约束多跳推理问题。首先从查询相关语料库构建有向概念图，然后通过多种路径发现策略来合成机械解释：1）最短路径推理；2）具有多样性约束的k最短路径；3）随机游走；4）检索增强语言模型基线作为对照。该方法引入了行为评估框架，重点衡量符号推理深度、机械多样性和基础稳定性三个维度，而非传统的事实正确性评估。

Result: 在机器学习、生物学和气候科学领域的任务评估中，图约束方法实现了可控的多跳推理，并揭示了一个系统性权衡关系：使用更深入和更多样的符号推理策略（如随机游走、k最短路径）会产生更多的机械解释多样性，但会显著增加基础不稳定性；相反，最短路径推理虽然保持高度稳定，但生成的解释在结构上较为保守。这一发现表明图约束LLM集成在科学综合中的能力与局限性存在明确的行为模式。

Conclusion: 本研究系统性地刻画了图约束多跳推理在科学综合中的行为特征。显式图约束为跨文献机械推理提供了可控性，但面临深度推理与稳定性之间的根本权衡。这些发现为科学信息系统中图-LLM集成方法的设计提供了行为学基础，指明了在追求解释多样性和保持可靠基础之间需要做出的设计选择。

Abstract: Cross-domain scientific synthesis requires connecting mechanistic explanations across fragmented literature, a capability that remains challenging for both retrieval-based systems and unconstrained language models. While recent work has applied large language models to scientific summarization and question answering, these approaches provide limited control over reasoning depth and structural grounding. We frame mechanistic synthesis as a graph-constrained multi-hop reasoning problem over literature-derived concept graphs. Given a scientific query and a compact, query-local corpus, SciNets constructs a directed concept graph and synthesizes mechanistic explanations by identifying multi-hop reasoning paths that connect concepts that rarely co-occur within individual papers. We systematically compare shortest-path reasoning, k-shortest paths with diversity constraints, stochastic random walks, and a retrieval-augmented language model baseline. Rather than evaluating correctness, which is often indeterminate when synthesizing connections across distributed sources, we introduce a behavioral framework that measures symbolic reasoning depth, mechanistic diversity, and grounding stability. Across machine learning, biology, and climate science tasks, explicit graph constraints enable controllable multi-hop reasoning while revealing a consistent trade-off: deeper and more diverse symbolic reasoning increases grounding instability, whereas shortest-path reasoning remains highly stable but structurally conservative. These findings provide a systematic behavioral characterization of the limits and capabilities of current graph-LLM integration for scientific synthesis.

</details>


### [59] [Eliminating Agentic Workflow for Introduction Generation with Parametric Stage Tokens](https://arxiv.org/abs/2601.09728)
*Meicong Zhang,Tiancheng su,Guoxiu He*

Main category: cs.CL

Score: 4/5 | Tags: LLM, Agent, Text Generation, Workflow, Instruction Tuning, Multi-stage Generation

Recommendation: 该论文针对LLM在多阶段文本生成中的实际问题提出了创新解决方案，具有较好的实用价值。方法设计巧妙，实验结果可信，但可能在实际应用中的泛化能力需要进一步验证。

TL;DR: 近年来，使用预定义的工作流来指导大型语言模型进行文献分类和综述已成为研究热点。然而，撰写研究引言更具挑战性，需要严谨的逻辑、连贯的结构和抽象的总结能力。现有工作流往往存在推理链过长、错误累积和文本连贯性下降的问题。为解决这些局限，我们提出消除外部工作流，直接将工作流的逻辑结构参数化到LLM中，实现在单次推理中生成完整的引言。为此，我们提出了引言生成阶段标记（STIG），将原始工作流的多个阶段转换为显式的阶段信号，这些信号指导模型在生成过程中遵循不同的逻辑角色和功能。通过指令微调，模型学习到阶段标记与文本功能之间的映射，以及各阶段间的逻辑顺序和过渡模式，并将这些知识编码到模型参数中。实验结果表明，STIG能够在单次推理中生成多阶段文本，无需显式调用工作流，在语义相似度和句子级结构合理性指标上优于传统工作流和其他基线方法。


<details>
  <summary>Details</summary>
Motivation: 现有基于预定义工作流的LLM方法在生成研究引言时存在诸多局限：推理链过长导致效率低下，错误在复杂工作流中累积，文本连贯性受损。特别是研究引言的撰写需要严谨的逻辑结构、连贯的叙述流程和抽象的总结能力，这些要求使得传统工作流方法难以胜任。

Method: 提出STIG（Stage Token for Introduction Generation）方法：1）消除外部工作流，直接将工作流逻辑结构参数化到LLM中；2）将原始工作流的多个阶段转换为显式阶段标记，作为控制信号；3）通过指令微调使模型学习阶段标记与文本功能的映射关系，以及阶段间的逻辑顺序和过渡模式；4）实现单次推理完成完整引言生成。

Result: 实验结果显示：1）STIG能够在单次推理中生成多阶段文本，无需显式调用工作流；2）在语义相似度和句子级结构合理性指标上优于传统工作流和其他基线方法；3）有效解决了推理链过长、错误累积和文本连贯性下降的问题；4）代码已在补充材料中提供。

Conclusion: STIG方法通过将工作流逻辑结构直接参数化到LLM中，实现了高效、连贯的研究引言生成。该方法消除了外部工作流的复杂性，在保持文本逻辑连贯性的同时提高了生成效率，为LLM在多阶段文本生成任务中的应用提供了新思路。

Abstract: In recent years, using predefined agentic workflows to guide large language models (LLMs) for literature classification and review has become a research focus. However, writing research introductions is more challenging. It requires rigorous logic, coherent structure, and abstract summarization. Existing workflows often suffer from long reasoning chains, error accumulation, and reduced textual coherence. To address these limitations, we propose eliminating external agentic workflows. Instead, we directly parameterize their logical structure into the LLM. This allows the generation of a complete introduction in a single inference. To this end, we introduce the Stage Token for Introduction Generation (STIG). STIG converts the multiple stages of the original workflow into explicit stage signals. These signals guide the model to follow different logical roles and functions during generation. Through instruction tuning, the model learns the mapping between stage tokens and text functions. It also learns the logical order and transition patterns between stages, encoding this knowledge into the model parameters. Experimental results show that STIG can generate multi-stage text in a single inference. It does not require explicit workflow calls. STIG outperforms traditional agentic workflows and other baselines on metrics of semantic similarity and sentence-level structural rationality. The code is provided in the Supplementary Materials.

</details>


### [60] [Enhancing Business Analytics through Hybrid Summarization of Financial Reports](https://arxiv.org/abs/2601.09729)
*Tohida Rehman*

Main category: cs.CL

Score: 4/5 | Tags: NLP, Text Summarization, Financial NLP, Transformer Models, Document Summarization, Hybrid Methods, Long Document Processing

Recommendation: 该论文为解决金融文档分析的现实问题提出了切实可行的技术方案，结合了传统算法与前沿深度学习模型，并在多种评估指标下进行了全面验证。研究具有较高的实用价值和领域针对性，为金融NLP应用提供了有价值的参考。论文方法系统，评估全面，但对具体实现细节和局限性讨论相对有限。

TL;DR: 财务报告和收益通讯包含大量结构化和半结构化信息，这使得详细的手动分析效率低下。收益电话会议为公司的绩效、前景和战略重点提供了宝贵的证据。对冗长通话记录的手动分析需要大量努力，并且容易受到解释偏见和无意识错误的影响。在这项工作中，我们提出了一个结合提取式和抽象式技术的混合摘要框架，从ECTSum数据集中生成简洁且事实可靠的Reuters风格摘要。所提出的两阶段流程首先应用LexRank算法识别重要句子，随后使用为资源受限环境设计的BART和PEGASUS微调变体进行总结。同时，我们微调了一个Longformer编码器-解码器（LED）模型，以直接捕获金融文档中的长距离上下文依赖关系。模型性能使用标准自动指标进行评估，包括ROUGE、METEOR、MoverScore和BERTScore，以及特定领域变体如SciBERTScore和FinBERTScore。为了评估事实准确性，我们进一步采用基于源精度和F1目标的实体级度量。结果突显了不同方法之间的互补权衡：长上下文模型产生了最强的整体性能，而混合框架在计算约束下实现了竞争性结果，同时提高了事实一致性。这些发现支持开发实用的摘要系统，以有效地将冗长的金融文本提炼为可用的商业洞察。


<details>
  <summary>Details</summary>
Motivation: 财务报告和收益通讯包含大量结构化与半结构化信息，手工详细分析效率低下。收益电话会议提供了关于公司绩效、前景和战略重点的宝贵证据，但冗长的通话记录手动分析需要大量工作，且易受解释偏见和无意识错误影响。因此，需要开发高效的自动摘要系统来从冗长金融文本中提取有价值的商业洞察。

Method: 提出了一个混合摘要框架，结合了提取式和抽象式技术。采用两阶段流程：1）首先使用LexRank算法识别重要句子；2）随后使用为资源受限环境设计的微调BART和PEGASUS变体进行摘要。同时，微调了Longformer编码器-解码器（LED）模型以直接捕获金融文档中的长距离上下文依赖关系。

Result: 结果表明不同方法之间存在互补权衡：长上下文模型（LED）获得了最强的整体性能，而混合框架在计算约束下实现了竞争性结果，同时提高了事实一致性。评估使用了多种指标：标准自动指标（ROUGE、METEOR、MoverScore、BERTScore）、领域特定变体（SciBERTScore、FinBERTScore）以及基于源精度和F1目标的实体级事实准确性度量。

Conclusion: 本研究提出的混合摘要框架和长上下文模型为金融文本摘要提供了有效的解决方案。长上下文模型在整体性能上表现最佳，而混合框架在计算资源受限环境下实现了良好的事实一致性与竞争性结果。这些发现支持开发实用的摘要系统，能够高效地从冗长金融文本中提取可用的商业洞察。

Abstract: Financial reports and earnings communications contain large volumes of structured and semi structured information, making detailed manual analysis inefficient. Earnings conference calls provide valuable evidence about a firm's performance, outlook, and strategic priorities. The manual analysis of lengthy call transcripts requires substantial effort and is susceptible to interpretive bias and unintentional error. In this work, we present a hybrid summarization framework that combines extractive and abstractive techniques to produce concise and factually reliable Reuters-style summaries from the ECTSum dataset. The proposed two stage pipeline first applies the LexRank algorithm to identify salient sentences, which are subsequently summarized using fine-tuned variants of BART and PEGASUS designed for resource constrained settings. In parallel, we fine-tune a Longformer Encoder-Decoder (LED) model to directly capture long-range contextual dependencies in financial documents.
  Model performance is evaluated using standard automatic metrics, including ROUGE, METEOR, MoverScore, and BERTScore, along with domain-specific variants such as SciBERTScore and FinBERTScore. To assess factual accuracy, we further employ entity-level measures based on source-precision and F1-target. The results highlight complementary trade offs between approaches, long context models yield the strongest overall performance, while the hybrid framework achieves competitive results with improved factual consistency under computational constraints. These findings support the development of practical summarization systems for efficiently distilling lengthy financial texts into usable business insights.

</details>


### [61] [Geometric Patterns of Meaning: A PHATE Manifold Analysis of Multi-lingual Embeddings](https://arxiv.org/abs/2601.09731)
*Wen G Gong*

Main category: cs.CL

Score: 4/5 | Tags: NLP, Embedding, Multilingual, Visualization, Semantic Analysis, Manifold Learning, PHATE, Language Geometry

Recommendation: 论文创新性地提出了多层级几何分析框架，系统性地揭示了嵌入空间中的模式，并使用PHATE流形学习提供可视化见解。研究方法严谨，发现对理解嵌入模型局限性有重要意义。该框架为未来嵌入模型的评估和改进提供了有价值的工具。得4分而非5分是因为实验范围相对有限，但总体质量高。

TL;DR: 我们引入了一个多层级分析框架来研究多语言嵌入中的语义几何结构，通过Semanscope（一种可视化工具，在四个语言层次上应用PHATE流形学习）实现。通过对涵盖子字符组件、字母系统、语义领域和数字概念等多样化数据集的分析，揭示了当前嵌入模型中系统的几何模式和关键局限性。在子字符层面，纯结构性元素（中文部首）表现出几何坍缩，凸显模型无法区分语义和结构组件。在字符层面，不同书写系统显示出独特的几何特征。在词语层面，内容词在英语、中文和德语的20个语义领域中形成聚类-分支模式。阿拉伯数字通过螺旋轨迹而非聚类组织，这违反了标准分布语义假设。这些发现确立了PHATE流形学习作为一种重要的分析工具，不仅用于研究嵌入空间中意义的几何结构，也用于验证嵌入模型捕捉语义关系的有效性。


<details>
  <summary>Details</summary>
Motivation: 当前多语言嵌入模型在捕捉语义关系方面存在局限性，研究者需要系统性分析工具来揭示嵌入空间中的几何模式。论文旨在通过开发多层级分析框架，理解不同语言层次（从子字符到语义领域）的几何结构，并验证嵌入模型在区分结构性和语义性信息方面的有效性。

Method: 论文提出了Semanscope可视化工具，该工具采用PHATE（Potential of Heat-diffusion for Affinity-based Trajectory Embedding）流形学习技术，在四个语言层次上进行分析：1）子字符层面（中文部首等结构性元素），2）字符层面（不同书写系统），3）词语层面（20个语义领域的内容词），4）数字概念层面（阿拉伯数字）。研究使用多样化数据集，涵盖多语言（英语、中文、德语），并系统性地分析几何模式如聚类、分支和螺旋轨迹。

Result: 研究发现：1）在子字符层面，中文部首等纯结构性元素出现几何坍缩，表明模型无法有效区分语义和结构组件；2）不同书写系统（如字母系统与象形文字）在字符层面显示独特几何特征；3）内容词在20个语义领域中形成聚类-分支模式，且这种模式在英语、中文和德语中一致；4）阿拉伯数字通过螺旋轨迹而非聚类组织，这挑战了标准分布语义假设；5）PHATE流形学习被证明是分析嵌入空间几何结构、验证模型有效性的强大工具。

Conclusion: 该研究建立了一个系统的多层级分析框架，揭示了多语言嵌入空间中的几何规律。PHATE流形学习不仅能够可视化嵌入空间的语义几何结构，还能识别模型的局限性（如区分结构性和语义性信息的失败）。研究挑战了标准分布语义假设，特别在数字概念的组织方式上。该框架为评估和改进嵌入模型提供了重要工具，具有理论和实践意义。

Abstract: We introduce a multi-level analysis framework for examining semantic geometry in multilingual embeddings, implemented through Semanscope (a visualization tool that applies PHATE manifold learning across four linguistic levels). Analysis of diverse datasets spanning sub-character components, alphabetic systems, semantic domains, and numerical concepts reveals systematic geometric patterns and critical limitations in current embedding models. At the sub-character level, purely structural elements (Chinese radicals) exhibit geometric collapse, highlighting model failures to distinguish semantic from structural components. At the character level, different writing systems show distinct geometric signatures. At the word level, content words form clustering-branching patterns across 20 semantic domains in English, Chinese, and German. Arabic numbers organize through spiral trajectories rather than clustering, violating standard distributional semantics assumptions. These findings establish PHATE manifold learning as an essential analytic tool not only for studying geometric structure of meaning in embedding space, but also for validating the effectiveness of embedding models in capturing semantic relationships.

</details>


### [62] [Benchmarking Cross-Lingual Semantic Alignment in Multilingual Embeddings](https://arxiv.org/abs/2601.09732)
*Wen G. Gong*

Main category: cs.CL

Score: 4/5 | Tags: Multilingual Embeddings, Semantic Alignment, Evaluation Metrics, BERT, LLM, NLP, Cross-lingual, Benchmarking

Recommendation: 这篇论文值得推荐的原因：1）针对实际需求提出了有效的评估方法，解决了多语言嵌入模型选择难题；2）方法设计严谨，提出了创新的SA指标和Semanscope框架；3）实验设计全面，覆盖了13个模型和4个数据集；4）发现了重要的现象和规律，如训练目标的关键作用和LLM的平台效应；5）具有重要的实践指导价值，为模型选择提供了科学依据。评分为4分是因为虽然研究有重要价值，但在实际应用普及性方面还有待验证。

TL;DR: 随着数百种多语言嵌入模型的出现，实践者缺乏明确的指导来确定哪些模型能提供真正的跨语言语义对齐，哪些只是通过语言特定模式实现任务性能。任务驱动基准测试（MTEB）可能掩盖了基本对齐缺陷。我们引入了语义亲和度（SA），这是一种在0到1之间的度量标准，使用余弦距离测量跨语言与语内距离的比率，并结合PHATE可视化在我们的Semanscope框架中。通过对13个模型在4个数据集（52个实验）进行基准测试，揭示了三层结构：（1）顶尖BERT模型（LaBSE SA = 0.70，USE SA = 0.68，S-BERT SA = 0.68）通过翻译对监督实现强对齐；（2）LLM嵌入无论在0.6B到8B规模如何，都在SA 0.55到0.61之间达到平台期；（3）仅MLM的BERT模型（mBERT，XLM-R，SA < 0.50）尽管训练了超过100种语言仍然失败。训练目标而非架构或规模决定了对齐质量。甲骨文原始词（公元前1200年）暴露了语义漂移问题——模型学习的是语料库模式而非认知原始概念。这项工作提供了语义基准测试，帮助实践者从数百个可用模型中选择高质量的多语言嵌入，表明跨语言对齐需要明确的翻译监督，而不仅仅是模型规模或多语言数据。


<details>
  <summary>Details</summary>
Motivation: 当前存在大量多语言嵌入模型，但实践者缺乏判断模型是否真正实现跨语言语义对齐的有效指导。任务驱动基准测试（如MTEB）可能无法准确评估语义对齐能力，因为高任务性能可能源于语言特定模式而非真正的语义理解。因此需要建立专门的语义对齐评估方法来指导模型选择。

Method: 本文提出语义亲和度（SA）指标，该指标通过计算跨语言距离与语内距离的比率来衡量语义对齐程度，数值范围在0到1之间，使用余弦距离进行计算。同时开发了Semanscope框架，结合PHATE可视化技术来分析语义空间。对13个不同模型在4个数据集上进行了52个实验的全面基准测试，覆盖多种模型架构和训练目标。

Result: 基准测试揭示了三个层次的结果：1）使用翻译对监督的BERT模型（LaBSE、USE、S-BERT）表现出最强对齐能力，SA值在0.68-0.70之间；2）大语言模型嵌入无论规模大小（0.6B到8B），SA值都稳定在0.55-0.61的平台期；3）仅使用掩码语言建模目标的BERT模型（如mBERT、XLM-R）对齐能力最差，SA值低于0.50。甲骨文原始词分析表明模型更倾向于学习语料库模式而非认知语义。

Conclusion: 训练目标而非模型架构或规模是决定跨语言语义对齐质量的关键因素。明确的翻译对监督是实现强语义对齐的必要条件，而仅靠大规模多语言数据或增加模型参数无法有效提升对齐质量。Semanscope框架和SA指标为实践者提供了实用的语义对齐评估工具，有助于从众多模型中识别出真正具有跨语言语义理解能力的模型。

Abstract: With hundreds of multilingual embedding models available, practitioners lack clear guidance on which provide genuine cross-lingual semantic alignment versus task performance through language-specific patterns. Task-driven benchmarks (MTEB) may mask fundamental alignment shortcomings. We introduce Semantic Affinity (SA), a bounded (between 0 and 1) metric measuring inter-lingual to intra-lingual spread ratio using cosine distance, combined with PHATE visualization in our Semanscope framework. Benchmarking 13 models across 4 datasets (52 experiments) reveals a three-tier structure: (1) Top BERT models (LaBSE SA = 0.70, USE SA = 0.68, S-BERT SA = 0.68) achieve strong alignment via translation-pair supervision; (2) LLM embeddings plateau at SA between 0.55 and 0.61 regardless of 0.6 B to 8 B scale; (3) MLM-only BERT models (mBERT, XLM-R, SA < 0.50) fail despite more than 100 language training. Training objective, not architecture or scale, determines alignment. Oracle Bone primitives (1200 BCE) expose semantic drift-models learn corpus patterns rather than cognitive primitives. This work provides semantic benchmarking to help practitioners select quality multilingual embeddings from hundreds of available models, showing cross-lingual alignment requires explicit translation supervision, not merely model scale or multilingual data.

</details>


### [63] [Closing the Data Loop: Using OpenDataArena to Engineer Superior Training Datasets](https://arxiv.org/abs/2601.09733)
*Xin Gao,Xiaoyang Wang,Yun Zhu,Mengzhang Cai,Conghui He,Lijun Wu*

Main category: cs.CL

Score: 4/5 | Tags: LLM, SFT, Dataset Engineering, Data-centric AI, Mathematics Reasoning, Instruction Tuning, Benchmarking, Data Efficiency

Recommendation: 该论文在SFT数据集工程领域提出了创新的系统化框架，具有重要的理论贡献和实用价值。ODA方法的科学性和可复现性较强，实验设计严谨，结果显著，为解决当前LLM训练数据质量参差不齐的问题提供了有效途径。4分推荐，扣分点在于论文为技术报告而非正式会议论文，且未提供详细的技术细节和开源代码。

TL;DR: 监督微调（SFT）数据集的构建是大型语言模型（LLM）后训练中一个关键但缺乏理论基础的阶段，因为普遍做法通常依赖于启发式聚合，而没有系统性地理解单个样本如何影响模型性能。在本报告中，我们提出从临时策展转向闭环数据集工程框架的范式转变，利用OpenDataArena（ODA），该框架通过价值锚定排名和多维分析，将价值基准测试转化为指导数据集构建的反馈信号。我们通过两个新数据集实例化了这一方法：\textbf{ODA-Math-460k}，一个专门的教学推理数据集，利用新颖的两阶段难度感知流程在AIME和HMMT等基准测试中取得最先进（SOTA）结果；以及\textbf{ODA-Mixture（100k和500k）}，一系列通过"锚定与修补"策略构建的多领域指令数据集，其表现显著优于更大的开源基线。我们的实证结果表明，ODA驱动的数据集显著改善了领域特定推理和通用效用，同时实现了卓越的数据效率，验证了向以数据为中心的AI过渡，其中透明评估作为工程化高质量训练数据的主要引擎。


<details>
  <summary>Details</summary>
Motivation: 当前SFT数据集构建缺乏系统性理论指导，普遍依赖启发式聚合方法，无法量化单个训练样本对模型性能的具体贡献。这种数据工程的无序性限制了LLM后训练的效果和效率，亟需建立科学化、闭环的数据集工程框架来替代当前的临时策展范式。

Method: 提出了OpenDataArena（ODA）框架，这是一个基于价值锚定排名和多维分析的闭环数据集工程系统。具体包括两个数据集构建方法：1）ODA-Math-460k采用两阶段难度感知流程，通过系统化评估数据难度和质量；2）ODA-Mixture采用"锚定与修补"策略，通过识别核心样本并逐步扩展覆盖多领域能力。该方法将基准测试结果转化为指导数据选择的反馈信号。

Result: ODA-Math-460k在AIME和HMMT等教学推理基准测试中取得了最先进（SOTA）结果；ODA-Mixture（100k和500k）在多个领域表现显著优于更大规模的开源基线数据集。实验证明ODA框架驱动的数据集在领域特定推理和通用效用方面都有显著提升，同时展现出卓越的数据效率（即用更少数据获得更好性能）。

Conclusion: ODA框架成功实现了从临时策展到系统化数据集工程的范式转变，验证了以透明评估为核心的数据驱动方法在高质量训练数据工程中的有效性。这为"以数据为中心的AI"发展提供了新方向，其中评估不仅是终点，更是指导数据构建的引擎。

Abstract: The construction of Supervised Fine-Tuning (SFT) datasets is a critical yet under-theorized stage in the post-training of Large Language Models (LLMs), as prevalent practices often rely on heuristic aggregation without a systematic understanding of how individual samples contribute to model performance. In this report, we propose a paradigm shift from ad-hoc curation to a closed-loop dataset engineering framework using OpenDataArena (ODA), which leverages value-anchored rankings and multi-dimensional analysis to transform value benchmarking into feedback signals guiding dataset construction. We instantiate this methodology through two new datasets: \textbf{ODA-Math-460k}, a specialized mathematics reasoning dataset that utilizes a novel two-stage difficulty-aware pipeline to achieve State-of-the-Art (SOTA) results on benchmarks such as AIME and HMMT, and \textbf{ODA-Mixture (100k \& 500k)}, a series of multi-domain instruction datasets built via an ``Anchor-and-Patch'' strategy that outperforms significantly larger open-source baselines. Our empirical results demonstrate that ODA-driven datasets significantly improve both domain-specific reasoning and general utility while achieving superior data efficiency, validating a transition toward data-centric AI where transparent evaluation serves as the primary engine for engineering high-quality training data.

</details>


### [64] [Stable and Explainable Personality Trait Evaluation in Large Language Models with Internal Activations](https://arxiv.org/abs/2601.09833)
*Xiaoxu Ma,Xiangbo Zhang,Zhenyu Weng*

Main category: cs.CL

Score: 4/5 | Tags: LLM, Personality Evaluation, Model Interpretation, Internal Activation, Vector Interpolation, Explainable AI

Recommendation: 推荐该论文，因为它提出了一种创新且实用的方法来改进LLM人格特质评估的稳定性和可解释性。PVNI方法具有坚实的理论基础和良好的实验结果，解决了现有方法的局限性。该方法在模型解释、比较和负责任部署方面具有重要应用价值。扣1分是因为未提及具体的实现细节和在大规模应用中的性能表现。

TL;DR: 评估大型语言模型（LLM）中的人格特质对于模型解释、比较和负责任部署至关重要。然而，现有的基于问卷的评估方法稳定性有限且可解释性低，其结果对提示措辞或角色扮演配置的微小变化高度敏感。为了解决这些局限性，我们提出了一种基于内部激活的方法，称为Persona-Vector Neutrality Interpolation（PVNI），用于在LLM中进行稳定且可解释的人格特质评估。PVNI通过对比提示从模型的内部激活中提取与目标人格特质相关的人格向量，然后沿该人格向量作为锚定轴进行插值来估计相应的中性分数，从而在中性提示表征和人格方向之间实现可解释的比较。我们提供了PVNI有效性和泛化性质的理论分析。在不同LLMs上的广泛实验表明，即使在问卷和角色扮演变体下，PVNI比现有方法产生的人格特质评估也更为稳定。


<details>
  <summary>Details</summary>
Motivation: 现有的大型语言模型人格特质评估方法（主要是基于问卷的评估）存在稳定性不足和可解释性差的局限性。这些方法对提示措辞或角色扮演配置的微小变化高度敏感，导致评估结果不稳定。研究者需要一种更稳定、更可解释的方法来评估LLMs的人格特质，这对于模型解释、比较和负责任部署至关重要。

Method: 本文提出了Persona-Vector Neutrality Interpolation (PVNI)方法。该方法的核心包括：1）使用对比提示从LLM的内部激活中提取与目标人格特质相关的人格向量；2）将该人格向量作为锚定轴，通过插值方法估计中性分数；3）在中性提示表征和人格方向之间进行可解释的比较。论文还提供了PVNI有效性和泛化性质的理论分析。

Result: 通过在多种LLMs上进行广泛的实验验证，PVNI方法显示出比现有方法显著更高的稳定性。即使在问卷评估和角色扮演变体等不同测试场景下，PVNI产生的人格特质评估结果也更加稳定。实验证明了该方法在不同模型和评估配置下的有效性。

Conclusion: PVNI方法为大型语言模型的人格特质评估提供了一种稳定且可解释的新途径。通过基于内部激活的向量提取和插值技术，该方法克服了传统问卷评估方法对提示变化的敏感性问题。这不仅提高了评估的稳定性，还增强了结果的可解释性，为LLMs的人格特质分析、模型比较和负责任部署提供了更好的工具。

Abstract: Evaluating personality traits in Large Language Models (LLMs) is key to model interpretation, comparison, and responsible deployment. However, existing questionnaire-based evaluation methods exhibit limited stability and offer little explainability, as their results are highly sensitive to minor variations in prompt phrasing or role-play configurations. To address these limitations, we propose an internal-activation-based approach, termed Persona-Vector Neutrality Interpolation (PVNI), for stable and explainable personality trait evaluation in LLMs. PVNI extracts a persona vector associated with a target personality trait from the model's internal activations using contrastive prompts. It then estimates the corresponding neutral score by interpolating along the persona vector as an anchor axis, enabling an interpretable comparison between the neutral prompt representation and the persona direction. We provide a theoretical analysis of the effectiveness and generalization properties of PVNI. Extensive experiments across diverse LLMs demonstrate that PVNI yields substantially more stable personality trait evaluations than existing methods, even under questionnaire and role-play variants.

</details>


### [65] [Bears, all bears, and some bears. Language Constraints on Language Models' Inductive Inferences](https://arxiv.org/abs/2601.09852)
*Sriram Padmanabhan,Siyuan Song,Kanishka Misra*

Main category: cs.CL

Score: 4/5 | Tags: VLM, NLP, Cognitive Science, Language Understanding, Inductive Reasoning, Quantifiers, Psycholinguistics

Recommendation: 这篇论文推荐的原因在于：1）巧妙地将发展心理学实验范式应用于AI模型评估；2）为理解视觉语言模型的认知能力提供了新视角；3）揭示了模型内部表征与人类认知过程的潜在对齐；4）跨学科研究方法创新性地结合了认知科学和机器学习领域。虽然实验规模可能有限，但其研究框架对评估AI模型的认知能力具有重要意义。

TL;DR: 语言对我们如何进行归纳推理施加了微妙的约束。Gelman等人（2002年）的发展证据显示，儿童（4岁及以上）在将新属性扩展到特定成员时，能够区分泛型陈述（"熊是可daxable的"）、全称量化名词短语（"所有熊都是可daxable的"）和不定的复数名词短语（"一些熊是可daxable的"）（全称 > 泛型 > 一些），这表明他们以不同的方式表示这些类型的命题。我们通过复制原始实验，测试这些细微差异是否出现在通用统计学习器如视觉语言模型中。通过让它们通过一系列前提条件测试（稳健识别图像中的类别以及对"所有"和"一些"的敏感性），然后进行原始实验，我们发现模型和人类之间存在行为对齐。对其表征的事后分析表明，这些差异是基于归纳约束组织的，而不是表面形式的差异。


<details>
  <summary>Details</summary>
Motivation: 本研究旨在探索通用统计学习器（特别是视觉语言模型）是否能像人类儿童那样理解和区分不同类型的量化陈述（泛型陈述、全称量词、部分量词）在归纳推理中的作用，从而理解这些模型是否能够捕捉到语言对归纳推理的微妙约束。

Method: 通过以下方法进行测试：1) 设计一系列前提条件测试来确保模型能够稳健识别图像中的类别，并对"所有"和"一些"等量化词敏感；2) 复刻Gelman等人（2002年）的原始实验设计，比较模型在不同类型陈述下的归纳推理行为；3) 进行事后分析来探究模型内部表征是否基于归纳约束而非表面形式差异。

Result: 研究发现视觉语言模型在归纳推理任务中表现出了与人类儿童相似的行为模式：模型同样遵循"全称 > 泛型 > 一些"的归纳强度顺序。更重要的是，事后分析显示，模型对不同类型陈述的表征差异是基于归纳约束组织的，而不是简单的表面语言形式差异。

Conclusion: 视觉语言模型能够捕捉到人类儿童在区分不同类型量化陈述时的归纳推理模式，这表明通用统计学习器能够在某种程度上模拟人类语言理解中涉及归纳推理的微妙方面，其内部表征反映了基于归纳约束的组织结构。

Abstract: Language places subtle constraints on how we make inductive inferences. Developmental evidence by Gelman et al. (2002) has shown children (4 years and older) to differentiate among generic statements ("Bears are daxable"), universally quantified NPs ("all bears are daxable") and indefinite plural NPs ("some bears are daxable") in extending novel properties to a specific member (all > generics > some), suggesting that they represent these types of propositions differently. We test if these subtle differences arise in general purpose statistical learners like Vision Language Models, by replicating the original experiment. On tasking them through a series of precondition tests (robust identification of categories in images and sensitivities to all and some), followed by the original experiment, we find behavioral alignment between models and humans. Post-hoc analyses on their representations revealed that these differences are organized based on inductive constraints and not surface-form differences.

</details>


### [66] [MedRedFlag: Investigating how LLMs Redirect Misconceptions in Real-World Health Communication](https://arxiv.org/abs/2601.09853)
*Sraavya Sambara,Yuan Pu,Ayman Ali,Vishala Mishra,Lionel Wong,Monica Agrawal*

Main category: cs.CL

Score: 4/5 | Tags: LLM, Healthcare, Safety, Medical AI, Benchmark, Dataset, Redirection, Medical Communication

Recommendation: 这篇论文值得推荐，因为它关注了医疗AI系统的一个关键安全问题，构建了专门的数据集和评估基准，揭示了LLMs在处理错误前提健康问题时的能力缺陷。研究具有实际应用价值，方法论严谨，对医疗AI安全领域有重要贡献。评分4是因为虽然研究很重要，但主要集中在问题识别层面，缺少深入的原因分析和改进方案探索。

TL;DR: 现实世界中的患者健康问题常常无意中嵌入了错误的假设或前提。在这种情况下，安全的医疗沟通通常涉及重定向：处理隐性误解，然后回应潜在的患者背景，而不是直接回答原始问题。虽然大型语言模型(LLMs)越来越被非专业用户用于医疗建议，但尚未测试它们在处理这种关键能力方面的表现。因此，在这项工作中，我们研究了LLMs如何应对嵌入在现实世界健康问题中的错误前提。我们开发了一个半自动化的流程来整理MedRedFlag，这是一个包含1100多个来自Reddit的需要重定向问题的数据集。然后我们系统比较了最先进的LLMs和临床医生的回应。我们的分析显示，LLMs经常无法重定向有问题的问题，即使检测到有问题前提，仍然会提供可能导致次优医疗决策的答案。我们的基准和结果揭示了LLMs在现实世界健康沟通条件下的一个新颖而显著的差距，突显了面向患者的医疗AI系统的关键安全问题。代码和数据集可在https://github.com/srsambara-1/MedRedFlag获取。


<details>
  <summary>Details</summary>
Motivation: 本研究的主要动机是解决大型语言模型在医疗建议场景中的一个关键安全问题：患者健康问题中常嵌入错误假设，而安全的医疗沟通需要重定向处理。随着LLMs被越来越多地用于医疗咨询，评估它们处理这类需要"先纠正错误前提，再提供恰当回应"的关键能力变得至关重要。研究者发现目前尚缺乏对此能力的研究，因此需要通过构建专门的数据集和评估方法来填补这一空白。

Method: 研究者采用半自动化流程开发了MedRedFlag数据集，包含1100多个来自Reddit的真实健康问题，这些问题都需要先进行重定向处理。方法包括：1)从Reddit收集真实患者健康问题；2)识别和标注含有错误前提的问题；3)创建重定向需求的数据集；4)系统比较最先进LLMs与临床医生的回应表现；5)分析LLMs在处理需要重定向问题时的失败模式和原因。

Result: 研究结果显示：1)LLMs在处理需要重定向的健康问题时表现不佳，即使检测到错误前提，也经常未能进行恰当重定向；2)LLMs提供的回应可能导致次优的医疗决策；3)揭示了在现实世界健康沟通条件下，LLMs存在显著的能力差距；4)通过构建的MedRedFlag基准发现，即使是先进LLMs也未能掌握临床医生处理错误假设问题的核心技能。

Conclusion: 本研究揭示了LLMs在医疗健康沟通中的一个重要安全缺陷：缺乏对错误前提问题的重定向能力。这一发现在面向患者的医疗AI系统中具有关键安全意义，强调了需要改进LLMs处理嵌入错误假设健康问题的能力。研究者提供的MedRedFlag数据集和评估方法为后续研究奠定了基础，可以帮助开发更安全的医疗AI系统。

Abstract: Real-world health questions from patients often unintentionally embed false assumptions or premises. In such cases, safe medical communication typically involves redirection: addressing the implicit misconception and then responding to the underlying patient context, rather than the original question. While large language models (LLMs) are increasingly being used by lay users for medical advice, they have not yet been tested for this crucial competency. Therefore, in this work, we investigate how LLMs react to false premises embedded within real-world health questions. We develop a semi-automated pipeline to curate MedRedFlag, a dataset of 1100+ questions sourced from Reddit that require redirection. We then systematically compare responses from state-of-the-art LLMs to those from clinicians. Our analysis reveals that LLMs often fail to redirect problematic questions, even when the problematic premise is detected, and provide answers that could lead to suboptimal medical decision making. Our benchmark and results reveal a novel and substantial gap in how LLMs perform under the conditions of real-world health communication, highlighting critical safety concerns for patient-facing medical AI systems. Code and dataset are available at https://github.com/srsambara-1/MedRedFlag.

</details>


### [67] [Patient-Similarity Cohort Reasoning in Clinical Text-to-SQL](https://arxiv.org/abs/2601.09876)
*Yifei Shen,Yilun Zhao,Justice Ou,Tinglin Huang,Arman Cohan*

Main category: cs.CL

Score: 4/5 | Tags: Text-to-SQL, Clinical NLP, EHR, Benchmark, Medical AI, Database Query, LLM, Healthcare

Recommendation: 本文值得推荐的原因包括：1)创建了首个专门针对临床领域的文本到SQL高质量基准，填补了研究空白；2)基准设计严谨，包含真实临床场景的复杂查询需求；3)对22个先进模型进行了全面评估，提供了重要的性能比较；4)揭示了临床文本到SQL任务的独特挑战和技术局限性；5)为未来研究和模型改进提供了明确方向。该研究对医疗AI和自然语言处理领域都有重要意义。

TL;DR: 现实世界的临床文本转SQL需要推理异构的EHR表格、时间窗口和患者相似性队列以生成可执行的查询。我们介绍了CLINSQL，这是一个基于MIMIC-IV v3.1的633个专家注释任务的基准，需要多表连接、具有临床意义的过滤器和可执行的SQL。解决CLINSQL涉及导航模式元数据和临床编码系统、处理长上下文以及编写超出传统文本转SQL的多步骤查询。我们在Chain-of-Thought自细化下评估了22个专有和开源模型，并使用基于准则的SQL分析和执行检查，优先考虑关键的临床要求。尽管近期有所进展，性能仍远未达到临床可靠性：在测试集上，GPT-5-mini达到了74.7%的执行得分，DeepSeek-R1在开源模型中领先，为69.2%，而Gemini-2.5-Pro在简单任务上从85.5%下降到困难任务的67.2%。在CLINSQL上的进展标志着向现实世界EHR分析的临床可靠文本转SQL迈出了切实的步伐。


<details>
  <summary>Details</summary>
Motivation: 临床医疗数据的文本到SQL转换面临独特挑战，包括异构的电子健康记录表格、复杂的时间窗口分析和患者相似性队列推理。现有文本到SQL系统主要针对简单的单表查询，无法满足现实世界中EHR分析的需求。需要创建一个专门针对临床领域的高质量基准，以评估模型在真实医疗场景下的表现，并推动临床可靠的文本到SQL技术发展。

Method: 作者创建了CLINSQL基准，包含MIMIC-IV v3.1数据库中的633个专家标注任务。该方法包括：1)设计需要多表连接、临床意义过滤和可执行SQL的复杂查询任务；2)使用Chain-of-Thought自细化策略评估22个专有和开源模型；3)采用基于准则的SQL分析和执行检查，优先考虑关键临床要求；4)分析模型处理模式元数据、临床编码系统、长上下文和多步骤查询的能力。

Result: 测试结果表明，现有模型性能仍远未达到临床可靠性要求：GPT-5-mini获得了最高的74.7%执行得分，DeepSeek-R1在开源模型中表现最佳，达到69.2%，而Gemini-2.5-Pro在简单任务上表现优异(85.5%)，但在困难任务上大幅下降至67.2%。模型在处理多表连接、临床语义理解和复杂时间推理方面存在明显不足，特别是在需要跨多个临床概念和时间窗口进行推理的查询上表现较差。

Conclusion: CLINSQL基准揭示了临床文本到SQL任务的挑战性和现有技术的局限性。尽管近期模型有所进步，但距离临床可靠性要求仍有较大差距。该基准为评估和推动临床可靠的文本到SQL技术提供了重要工具，未来的工作需要专注于改进模型在复杂临床推理、多表操作和医学语义理解方面的能力，以满足现实世界EHR分析的需求。

Abstract: Real-world clinical text-to-SQL requires reasoning over heterogeneous EHR tables, temporal windows, and patient-similarity cohorts to produce executable queries. We introduce CLINSQL, a benchmark of 633 expert-annotated tasks on MIMIC-IV v3.1 that demands multi-table joins, clinically meaningful filters, and executable SQL. Solving CLINSQL entails navigating schema metadata and clinical coding systems, handling long contexts, and composing multi-step queries beyond traditional text-to-SQL. We evaluate 22 proprietary and open-source models under Chain-of-Thought self-refinement and use rubric-based SQL analysis with execution checks that prioritize critical clinical requirements. Despite recent advances, performance remains far from clinical reliability: on the test set, GPT-5-mini attains 74.7% execution score, DeepSeek-R1 leads open-source at 69.2% and Gemini-2.5-Pro drops from 85.5% on Easy to 67.2% on Hard. Progress on CLINSQL marks tangible advances toward clinically reliable text-to-SQL for real-world EHR analytics.

</details>


### [68] [Clozing the Gap: Exploring Why Language Model Surprisal Outperforms Cloze Surprisal](https://arxiv.org/abs/2601.09886)
*Sathvik Nair,Byung-Doh Oh*

Main category: cs.CL

Score: 4/5 | Tags: NLP, Psycholinguistics, Language Models, Prediction, Cloze Task, Cognitive Science, Language Processing

Recommendation: 这篇论文被推荐的原因是它深入探讨了语言模型在认知科学应用中的重要方法论问题，不仅对比了传统完形填空方法和语言模型在预测语言处理努力方面的表现，更重要的是分析了这种优势背后的科学原因。该研究具有重要的理论意义和方法论价值，为跨学科研究（NLP与心理语言学）提供了有价值的见解。论文提出的改进建议也具有很强的实践指导意义。

TL;DR: 单词的可预测性可以通过两种方式量化：使用人类在完形填空任务中的反应，或使用语言模型（LMs）的概率。当作为处理努力的预测因子时，语言模型概率优于完形填空数据导出的概率。然而，重要的是要确认语言模型概率的优势是基于正确的原因，因为不同的预测因子可能对预测在语言理解中的作用得出不同的科学结论。我们为关于语言模型概率优势的三个假设提供了证据：不受低分辨率影响、能区分语义相似单词、以及准确分配低频单词的概率。这些结果呼吁提高完形填空研究的分辨率，并辅以实验来检验人类预测是否也对语言模型概率所做的细粒度区分同样敏感。


<details>
  <summary>Details</summary>
Motivation: 本研究旨在探讨语言模型概率在预测语言处理努力方面的优势是否基于正确的科学原因。由于不同的预测方法可能导致对语言理解中预测作用的不同科学结论，因此需要验证语言模型概率相对于传统完形填空数据的优越性背后的机制。研究人员希望通过检验三个具体假设来深入理解这种优势的本质，从而为语言预测机制的研究提供更可靠的方法论基础。

Method: 研究方法包括对比分析两种预测性量化方法：基于人类反应的完形填空任务和基于语言模型计算出的概率。研究人员提出了三个假设并进行验证：1）语言模型概率不受低分辨率问题影响；2）能够区分语义相似的单词；3）能够准确估计低频单词的概率。通过系统比较这两种方法在预测语言处理努力方面的表现，来评估各自的优势和局限性。

Result: 研究结果为三个假设提供了证据支持：语言模型概率确实因不受低分辨率影响而优于完形填空数据；能够有效区分语义相似的单词；并且在低频单词的概率估计上更为准确。这些结果表明语言模型概率在预测语言处理努力方面具有实质性的方法学优势，这些优势不仅仅源于统计上的优越性，而是基于更精细和准确的预测机制。

Conclusion: 研究得出结论，语言模型概率在预测语言处理努力方面的优势是建立在其更精细的分辨能力和更准确的概率估计基础之上的。这些发现呼吁语言认知研究领域需要改进传统完形填空任务的分辨率，并开展实验探索人类语言预测是否也具备类似语言模型那样的细粒度区分能力。该研究为理解语言预测机制提供了重要的方法学见解。

Abstract: How predictable a word is can be quantified in two ways: using human responses to the cloze task or using probabilities from language models (LMs).When used as predictors of processing effort, LM probabilities outperform probabilities derived from cloze data. However, it is important to establish that LM probabilities do so for the right reasons, since different predictors can lead to different scientific conclusions about the role of prediction in language comprehension. We present evidence for three hypotheses about the advantage of LM probabilities: not suffering from low resolution, distinguishing semantically similar words, and accurately assigning probabilities to low-frequency words. These results call for efforts to improve the resolution of cloze studies, coupled with experiments on whether human-like prediction is also as sensitive to the fine-grained distinctions made by LM probabilities.

</details>


### [69] [Take Out Your Calculators: Estimating the Real Difficulty of Question Items with LLM Student Simulations](https://arxiv.org/abs/2601.09953)
*Christabel Acquaye,Yi Ting Huang,Marine Carpuat,Rachel Rudinger*

Main category: cs.CL

Score: 4/5 | Tags: LLM, 教育科技, 评估, 模拟, 项目反应理论, 教育评估

Recommendation: 推荐这篇论文的原因：1) 研究具有实际应用价值，为昂贵的教育评估提供经济有效的替代方案；2) 方法创新，将LLMs与项目反应理论结合进行试题难度预测；3) 实验结果具有说服力，相关性高达0.75-0.82；4) 发现了反直觉的现象（数学能力较弱的模型反而表现更好），这为后续研究提供了有趣的方向；5) 研究设计严谨，考虑了多种变量如教室规模、学生身份表示方式等。扣分主要是因为研究可能还需要在实际应用中进一步验证其稳定性和泛化能力。

TL;DR: 标准化数学评估需要昂贵的人工试点研究来确定测试项目的难度。我们研究了开源大语言模型（LLMs）在评估真实学生多项选择题难度方面的预测价值。研究表明，虽然LLMs作为问题难度的直接判断者表现不佳，但在适当条件下，基于模拟的方法能产生有希望的结果。根据所提出的方法，我们通过提示LLMs扮演不同熟练水平的学生，模拟4年级、8年级或12年级的"教室"。我们利用这些模拟结果拟合项目反应理论（IRT）模型，将项目的学习难度参数与其真实世界难度（通过美国国家教育进展评估提供的项目级统计数据确定）进行比较。我们观察到4年级、8年级和12年级的相关性分别高达0.75、0.76和0.82。在模拟中，我们尝试了不同的"教室规模"，显示了计算规模和准确性之间的权衡。我们发现，具有具体姓名的学生角色扮演（与学生编号相比）能改善预测，按性别和种族分层姓名能进一步改善预测。我们的结果表明，数学能力相对较弱的模型（Gemma）实际上比数学能力更强的模型（Llama和Qwen）产生更好的真实世界难度预测，进一步强调了开源模型对此任务的适用性。


<details>
  <summary>Details</summary>
Motivation: 传统的标准化数学评估需要昂贵的人工试点研究来确定试题难度，这需要大量时间和资源。本研究探索是否可以利用开源大语言模型来预测数学试题的难度，从而降低评估成本并提高效率。研究者希望通过模拟学生答题过程来替代传统的人工研究。

Method: 研究方法采用模拟基方法：1) 创建"虚拟教室"，让LLMs扮演不同熟练水平的4年级、8年级或12年级学生；2) 通过角色扮演模拟学生答题过程；3) 使用模拟结果拟合项目反应理论模型；4) 将模型学习到的难度参数与真实世界数据（美国国家教育进展评估提供的项目级统计数据）进行比较。研究还探索了不同教室规模的影响，并测试了学生身份表示方式（姓名vs编号）、性别和种族分层等变量的效果。

Result: 研究结果表明：1) LLMs模拟方法能有效预测数学试题难度，4年级、8年级和12年级的预测结果与实际难度相关性分别达到0.75、0.76和0.82；2) 模拟中教室规模在计算效率和准确性之间存在权衡；3) 使用具体姓名的学生角色扮演比使用学生编号能改善预测效果；4) 按性别和种族分层学生姓名能进一步提升预测准确性；5) 数学能力相对较弱的Gemma模型反而比数学能力更强的Llama和Qwen模型产生更好的真实世界难度预测。

Conclusion: 本研究证明了使用开源大语言模型通过模拟学生答题过程来预测数学试题难度的可行性。虽然LLMs作为直接的难度判断者表现不佳，但通过适当的模拟基方法，特别是在使用具体的角色扮演和学生分层策略下，可以获得与真实世界数据高度相关的预测结果。有趣的是，数学能力较弱的模型反而更适合此任务，这可能是因为它们在模拟学生表现时更接近真实学生的思维模式。这种方法为标准化评估中的难度预测提供了经济有效的替代方案。

Abstract: Standardized math assessments require expensive human pilot studies to establish the difficulty of test items. We investigate the predictive value of open-source large language models (LLMs) for evaluating the difficulty of multiple-choice math questions for real-world students. We show that, while LLMs are poor direct judges of problem difficulty, simulation-based approaches with LLMs yield promising results under the right conditions. Under the proposed approach, we simulate a "classroom" of 4th, 8th, or 12th grade students by prompting the LLM to role-play students of varying proficiency levels. We use the outcomes of these simulations to fit Item Response Theory (IRT) models, comparing learned difficulty parameters for items to their real-world difficulties, as determined by item-level statistics furnished by the National Assessment of Educational Progress (NAEP). We observe correlations as high as 0.75, 0.76, and 0.82 for grades 4, 8, and 12, respectively. In our simulations, we experiment with different "classroom sizes," showing tradeoffs between computation size and accuracy. We find that role-plays with named students improves predictions (compared to student ids), and stratifying names across gender and race further improves predictions. Our results show that LLMs with relatively weaker mathematical abilities (Gemma) actually yield better real-world difficulty predictions than mathematically stronger models (Llama and Qwen), further underscoring the suitability of open-source models for the task.

</details>


### [70] [Context Volume Drives Performance: Tackling Domain Shift in Extremely Low-Resource Translation via RAG](https://arxiv.org/abs/2601.09982)
*David Samuel Setiawan,Raphaël Merx,Jey Han Lau*

Main category: cs.CL

Score: 4/5 | Tags: NMT, Low-resource Languages, Domain Adaptation, LLM, RAG, Machine Translation, Cross-domain

Recommendation: 推荐这篇论文的原因：1) 针对低资源语言翻译的实际问题提供了创新解决方案；2) 结合了传统NMT和新兴LLM技术的优势；3) 通过具体案例（Dhao语）量化了领域迁移的挑战；4) 实验设计合理，结果有说服力；5) 对实际应用有重要指导意义。不足之处在于可能缺乏更多语言的验证。

TL;DR: 针对低资源语言，神经机器翻译（NMT）模型在领域迁移时性能显著下降。我们使用Dhao语（东印度尼西亚的一种土著语言，除新约圣经外没有任何数字足迹）来量化这一挑战。当应用于未见过的旧约圣经时，基于新约圣经微调的标准NMT模型性能从域内得分36.17 chrF++下降到27.11 chrF++。为恢复这种损失，我们引入了一种混合框架：微调的NMT模型生成初稿，然后由大型语言模型（LLM）使用检索增强生成（RAG）进行精炼。最终系统达到35.21 chrF++（恢复+8.10），有效地匹配了原始域内质量。我们的分析表明，这一性能主要由检索示例的数量而非检索算法的选择驱动。定性分析证实LLM充当了稳健的"安全网"，修复了零样本域中的严重失败。


<details>
  <summary>Details</summary>
Motivation: 低资源语言的神经机器翻译模型在面临领域迁移时性能显著下降是一个重要挑战。本研究的动机是量化这一挑战，并针对Dhao语（除新约圣经外没有任何数字足迹的土著语言）开发有效方法来缓解领域迁移带来的性能下降，特别是当模型从未见过的旧约圣经文本时。

Method: 提出了一种混合框架：首先使用在新约圣经上微调的标准NMT模型生成初始翻译草稿，然后使用大型语言模型（LLM）通过检索增强生成（RAG）技术对草稿进行精炼和优化。该方法结合了传统NMT模型的效率和LLM的泛化能力，重点关注检索示例的数量对性能的影响。

Result: 混合框架将性能从27.11 chrF++恢复至35.21 chrF++，实现了8.10个chrF++的提升，有效匹配了原始域内质量（36.17 chrF++）。分析表明，性能提升主要由检索示例的数量驱动，而非检索算法的选择。定性分析确认LLM能够修复零样本域中的严重翻译失败。

Conclusion: 该研究证明了混合NMT-LLM框架在应对低资源语言领域迁移问题上的有效性。LLM作为"安全网"能够显著恢复因领域变化而损失的翻译质量，且性能提升主要依赖于检索示例的数量。这种方法为处理数字足迹有限的低资源语言翻译问题提供了实用解决方案。

Abstract: Neural Machine Translation (NMT) models for low-resource languages suffer significant performance degradation under domain shift. We quantify this challenge using Dhao, an indigenous language of Eastern Indonesia with no digital footprint beyond the New Testament (NT). When applied to the unseen Old Testament (OT), a standard NMT model fine-tuned on the NT drops from an in-domain score of 36.17 chrF++ to 27.11 chrF++. To recover this loss, we introduce a hybrid framework where a fine-tuned NMT model generates an initial draft, which is then refined by a Large Language Model (LLM) using Retrieval-Augmented Generation (RAG). The final system achieves 35.21 chrF++ (+8.10 recovery), effectively matching the original in-domain quality. Our analysis reveals that this performance is driven primarily by the number of retrieved examples rather than the choice of retrieval algorithm. Qualitative analysis confirms the LLM acts as a robust "safety net," repairing severe failures in zero-shot domains.

</details>


### [71] [SocraticKG: Knowledge Graph Construction via QA-Driven Fact Extraction](https://arxiv.org/abs/2601.10003)
*Sanghyeok Choi,Woosang Jeon,Kyuseok Yang,Taehyeong Kim*

Main category: cs.CL

Score: 4/5 | Tags: Knowledge Graph, LLM, NLP, Information Extraction, Semantic Representation, QA, Automated Reasoning

Recommendation: 这篇论文提出了一种创新的知识图谱构建方法SocraticKG，通过引入问答对作为中间表示，有效解决了当前LLM-based方法中覆盖率与连通性的权衡问题。方法设计合理，在MINE基准上取得了良好效果，为解决知识图谱构建中的关键挑战提供了有价值的思路。值得推荐给研究知识图谱、信息提取和语义表示的研究者。

TL;DR: 构建知识图谱（KG）从未结构化的文本中为知识表示和推理提供了结构化框架，然而当前基于大语言模型（LLM）的方法面临一个基本权衡：事实覆盖率往往导致关系碎片化，而过早的整合会导致信息丢失。为解决这一问题，我们提出了SocraticKG，这是一种自动化知识图谱构建方法，引入了问答对作为结构化中间表示，在三元组提取之前系统地展开文档级语义。通过采用5W1H引导的问答扩展，SocraticKG捕获了通常在直接知识图谱提取流程中丢失的上下文依赖和隐式关系链接，提供了对源文档的显式基础，有助于减轻隐式推理错误。在MINE基准上的评估表明，我们的方法有效解决了覆盖率与连通性之间的权衡，在提取的知识量大幅扩展的同时，实现了卓越的事实保持能力，同时保持了高结构内聚性。这些结果突显了问答介导的语义脚手架在知识图谱提取前结构化语义方面的关键作用，能够在后续阶段实现更连贯和可靠的图构建。


<details>
  <summary>Details</summary>
Motivation: 当前基于LLM的知识图谱构建方法面临一个基本权衡问题：一方面，为了提高事实覆盖率，倾向于提取大量孤立的三元组，导致关系碎片化；另一方面，过早进行关系整合又会导致信息丢失。这种覆盖率与连通性之间的权衡限制了知识图谱的结构质量和语义完整性。需要一种方法能够在保留丰富事实的同时，保持知识图谱的结构连贯性。

Method: SocraticKG的核心创新是引入问答对作为结构化中间表示。该方法采用5W1H（Who, What, When, Where, Why, How）引导的问答扩展策略，在正式进行三元组提取之前，先系统地展开文档级语义。通过问答对的形式，该方法能够捕获上下文依赖关系和隐式关系链接，为后续的三元组提取提供语义脚手架，确保提取的知识具有更好的上下文基础和更完整的关系结构。

Result: 在MINE基准测试中，SocraticKG表现出色，有效解决了覆盖率与连通性之间的权衡问题。该方法在提取的知识量大幅扩展的同时，实现了卓越的事实保持能力，同时保持了高结构内聚性。这表明问答介导的语义脚手架能够显著改善知识图谱的构建质量，相比直接提取方法，SocraticKG能够保留更多上下文依赖和隐式关系，减少隐式推理错误。

Conclusion: 问答对作为结构化中间表示在知识图谱构建中发挥了关键作用，通过在提取前系统展开文档级语义，SocraticKG成功解决了覆盖率与连通性之间的权衡问题。5W1H引导的问答扩展为知识提取提供了语义脚手架，能够捕获通常丢失的上下文依赖和隐式关系，从而实现更连贯、更可靠的知识图谱构建。

Abstract: Constructing Knowledge Graphs (KGs) from unstructured text provides a structured framework for knowledge representation and reasoning, yet current LLM-based approaches struggle with a fundamental trade-off: factual coverage often leads to relational fragmentation, while premature consolidation causes information loss. To address this, we propose SocraticKG, an automated KG construction method that introduces question-answer pairs as a structured intermediate representation to systematically unfold document-level semantics prior to triple extraction. By employing 5W1H-guided QA expansion, SocraticKG captures contextual dependencies and implicit relational links typically lost in direct KG extraction pipelines, providing explicit grounding in the source document that helps mitigate implicit reasoning errors. Evaluation on the MINE benchmark demonstrates that our approach effectively addresses the coverage-connectivity trade-off, achieving superior factual retention while maintaining high structural cohesion even as extracted knowledge volume substantially expands. These results highlight that QA-mediated semantic scaffolding plays a critical role in structuring semantics prior to KG extraction, enabling more coherent and reliable graph construction in subsequent stages.

</details>


### [72] [EmplifAI: a Fine-grained Dataset for Japanese Empathetic Medical Dialogues in 28 Emotion Labels](https://arxiv.org/abs/2601.10033)
*Wan Jou She,Lis Kanashiro Pereira,Fei Cheng,Sakiko Yahata,Panote Siriaraya,Eiji Aramaki*

Main category: cs.CL

Score: 4/5 | Tags: LLM, 对话系统, 共情计算, 医疗AI, NLP, 数据集, 情感计算, 日语NLP

Recommendation: 推荐理由：1）针对慢性疾病患者的情感支持这一重要且复杂的医疗应用场景；2）建立了高质量的日本共情对话数据集，填补了该领域的空白；3）提供了完整的评估流程和方法验证；4）实验结果显著，具有实际应用价值。不足之处：主要聚焦日语场景，对其他语言环境的普适性有待验证。

TL;DR: 本文介绍了EmplifAI，一个日本共情对话数据集，旨在支持慢性疾病患者。患者通常在疾病管理的不同阶段经历广泛的正负面情绪（如希望和绝望）。EmplifAI通过提供基于28种细粒度情感类别的场景对话来解决这种复杂性，这些类别是从GoEmotions分类法改编和验证而来。数据集包含280个医疗背景情境和4125组两轮对话，通过众包和专家评审收集。为了评估共情对话中的情感对齐，我们使用BERTScore评估了多个大语言模型（LLMs）对情境-对话对的预测，F1得分达到0.83。使用EmplifAI对基准日本LLM（LLM-jp-3.1-13b-instruct4）进行微调后，在流畅性、一般共情和情感特异性共情方面均取得了显著改进。此外，我们比较了LLM-as-a-Judge和人类评分者对多个LLM生成的对话给出的评分，以验证我们的评估流程，并讨论了从相关性分析中得出的见解和潜在风险。


<details>
  <summary>Details</summary>
Motivation: 慢性疾病患者在疾病管理的不同阶段会经历复杂的情绪变化，既有正面情绪也有负面情绪（如希望和绝望）。现有的对话数据集往往无法充分捕捉这种情感复杂性，尤其是在医疗背景下。本研究的动机是创建一个专门针对日本慢性疾病患者情感支持的高质量共情对话数据集，以改善面向患者的AI对话系统的情感对齐能力。

Method: 1. 数据集构建：基于GoEmotions分类法，适应并验证了28种细粒度情感类别；构建280个医疗背景情境，通过众包和专家评审收集了4125组两轮对话。

2. 情感对齐评估：使用BERTScore评估多个LLMs在情境-对话对上的预测性能，测量F1分数。

3. 模型微调：使用EmplifAI数据集对日本基准LLM（LLM-jp-3.1-13b-instruct4）进行微调。

4. 评估流程验证：比较LLM-as-a-Judge与人类评分者对多个LLM生成对话的评分，进行相关性分析。

Result: 1. 数据集规模：成功构建了包含280个医疗情境和4125组两轮对话的EmplifAI数据集。

2. 情感对齐性能：使用BERTScore评估多个LLMs，F1得分达到0.83，表明良好的情感对齐能力。

3. 微调效果：微调后的LLM-jp-3.1-13b-instruct4在流畅性、一般共情和情感特异性共情方面均表现出显著改进。

4. 评估验证：LLM-as-a-Judge与人类评分者的评分相关性分析为评估流程提供了验证，并揭示了潜在的风险和见解。

Conclusion: EmplifAI数据集有效解决了慢性疾病患者情感支持对话系统的复杂性需求。通过细粒度情感分类和医疗背景情境，该数据集为开发更精准的共情AI对话系统提供了坚实基础。微调实验证明了数据集对LLM性能的提升作用，而评估流程的验证为未来相关研究提供了可靠的方法学支持。

Abstract: This paper introduces EmplifAI, a Japanese empathetic dialogue dataset designed to support patients coping with chronic medical conditions. They often experience a wide range of positive and negative emotions (e.g., hope and despair) that shift across different stages of disease management. EmplifAI addresses this complexity by providing situation-based dialogues grounded in 28 fine-grained emotion categories, adapted and validated from the GoEmotions taxonomy. The dataset includes 280 medically contextualized situations and 4125 two-turn dialogues, collected through crowdsourcing and expert review. To evaluate emotional alignment in empathetic dialogues, we assessed model predictions on situation--dialogue pairs using BERTScore across multiple large language models (LLMs), achieving F1 scores of 0.83. Fine-tuning a baseline Japanese LLM (LLM-jp-3.1-13b-instruct4) with EmplifAI resulted in notable improvements in fluency, general empathy, and emotion-specific empathy. Furthermore, we compared the scores assigned by LLM-as-a-Judge and human raters on dialogues generated by multiple LLMs to validate our evaluation pipeline and discuss the insights and potential risks derived from the correlation analysis.

</details>


### [73] [Long-Chain Reasoning Distillation via Adaptive Prefix Alignment](https://arxiv.org/abs/2601.10064)
*Zhenghao Liu,Zhuoyang Wu,Xinze Li,Yukun Yan,Shuo Wang,Zulong Chen,Yu Gu,Ge Yu,Maosong Sun*

Main category: cs.CL

Score: 4/5 | Tags: LLM, Knowledge Distillation, Reasoning, Mathematics, CoT, P-ALIGN

Recommendation: 这篇论文提出了一个新颖的解决方案来解决知识蒸馏中教师推理轨迹过长的问题。P-ALIGN方法的创新性在于其自适应截断策略和前缀对齐机制，实验结果表明该方法在数学推理任务上取得了显著提升。该方法具有实际应用价值，特别适用于需要将大模型能力迁移到小模型的场景。

TL;DR: 大语言模型（LLMs）在解决复杂数学问题方面展现出卓越的推理能力。最近的研究表明，提炼长推理轨迹可以有效增强小规模学生模型的推理性能。然而，教师生成的推理轨迹往往过长且结构复杂，难以让学生模型学习。这种不匹配导致提供的监督信号与学生模型学习能力之间存在差距。为解决这一挑战，我们提出前缀对齐蒸馏（P-ALIGN），一个通过自适应前缀对齐充分利用教师推理轨迹进行蒸馏的框架。具体而言，P-ALIGN通过判断剩余后缀是否简洁且足以指导学生模型，自适应地截断教师生成的推理轨迹。然后，P-ALIGN利用教师生成的前缀来监督学生模型，促进有效的前缀对齐。在多个数学推理基准测试上的实验表明，P-ALIGN优于所有基线模型超过3%。进一步分析表明，P-ALIGN构建的前缀提供了更有效的监督信号，同时避免了冗余和不确定推理组件的负面影响。


<details>
  <summary>Details</summary>
Motivation: 现有的知识蒸馏方法中，教师模型生成的推理轨迹（CoTs）通常过长且复杂，超出了学生模型的有效学习能力。这种不匹配导致蒸馏效率低下，学生模型难以从复杂的监督信号中获益，形成了教师输出与学生模型学习能力之间的差距。

Method: P-ALIGN（前缀对齐蒸馏）框架采用自适应前缀对齐策略。首先，通过判断剩余推理后缀是否简洁且足以指导学生模型，自适应地截断教师生成的过长推理轨迹。然后，利用教师生成的前缀部分作为监督信号，指导学生模型学习，实现前缀对齐。该方法避免了冗余推理组件对学习的负面影响。

Result: 在多个数学推理基准测试上，P-ALIGN超越了所有基线方法，性能提升超过3%。分析表明，P-ALIGN构建的前缀提供了更有效的监督信号，同时避免了冗余和不确定推理组件的干扰，显著提高了蒸馏效果。

Conclusion: P-ALIGN通过自适应前缀对齐的方法，有效地解决了教师生成推理轨迹过长且复杂的问题，显著提升了知识蒸馏在数学推理任务上的效果，为学生模型提供了更合适的监督信号。

Abstract: Large Language Models (LLMs) have demonstrated remarkable reasoning capabilities, particularly in solving complex mathematical problems. Recent studies show that distilling long reasoning trajectories can effectively enhance the reasoning performance of small-scale student models. However, teacher-generated reasoning trajectories are often excessively long and structurally complex, making them difficult for student models to learn. This mismatch leads to a gap between the provided supervision signal and the learning capacity of the student model. To address this challenge, we propose Prefix-ALIGNment distillation (P-ALIGN), a framework that fully exploits teacher CoTs for distillation through adaptive prefix alignment. Specifically, P-ALIGN adaptively truncates teacher-generated reasoning trajectories by determining whether the remaining suffix is concise and sufficient to guide the student model. Then, P-ALIGN leverages the teacher-generated prefix to supervise the student model, encouraging effective prefix alignment. Experiments on multiple mathematical reasoning benchmarks demonstrate that P-ALIGN outperforms all baselines by over 3%. Further analysis indicates that the prefixes constructed by P-ALIGN provide more effective supervision signals, while avoiding the negative impact of redundant and uncertain reasoning components. All code is available at https://github.com/NEUIR/P-ALIGN.

</details>


### [74] [CALM-IT: Generating Realistic Long-Form Motivational Interviewing Dialogues with Dual-Actor Conversational Dynamics Tracking](https://arxiv.org/abs/2601.10085)
*Viet Cuong Nguyen,Nhi Yen Nguyen,Kristin A. Candan,Mary Conlon,Vanessa Rumie,Kristen Risola,Srijan Kumar,Munmun De Choudhury*

Main category: cs.CL

Score: 5/5 | Tags: LLM, 对话系统, 心理健康, 动机性访谈, 长形式对话, 状态空间建模, AI应用

Recommendation: 本文针对LLMs在心理健康长程对话应用中的核心痛点，提出了一个创新性强且结构清晰的解决方案（CALM-IT）。该工作不仅具有明确的应用价值（提升AI辅助心理治疗的质量），其方法论（双向状态空间建模）对通用长形式、目标导向的人机对话研究也具有重要的启发意义。实验设计全面，结果令人信服，证明了所提框架在多个维度上的优越性。因此，强烈推荐给对对话AI、LLM应用、心理健康计算等领域感兴趣的研究者和从业者。

TL;DR: 大语言模型（LLMs）越来越多地应用于心理健康相关场景，但它们在长时间的互动中难以维持真实、目标导向的对话。虽然LLMs能生成流畅的回应，但它们倾向于优化局部（下一轮对话）而非维持关于治疗进展的连贯模型，这导致了脆弱性和长视野漂移问题。我们提出了CALM-IT框架，用于生成和评估长形式的动机性访谈（MI）对话，该框架显式地建模了双行为者对话动态。CALM-IT将治疗师-来访者互动表示为一个双向状态空间过程，在此过程中，双方持续更新推断出的对齐状态、心理状态和短期目标，以指导策略选择和话语生成。在大规模评估中，CALM-IT在有效性（Effectiveness）和目标对齐（Goal Alignment）方面始终优于强基线，并且随着对话长度的增加，其表现显著更稳定。尽管CALM-IT启动的治疗师重定向（redirections）较少，但其获得了最高的来访者接受率（64.3%），表明其干预时机更为精准且与治疗目标更一致。总的来说，CALM-IT为建模演变的对话状态对于生成高质量长形式合成对话的必要性提供了证据。


<details>
  <summary>Details</summary>
Motivation: 尽管大语言模型（LLMs）在心理健康领域的应用日益增多，但现有模型在长时间的、目标导向的心理治疗对话中表现出明显的局限性。它们倾向于局部优化下一个回合的响应，而缺乏对整个治疗进程的连贯建模，导致对话在长期互动中出现不一致、目标漂移和脆弱性。动机性访谈（MI）作为一种结构化的心理治疗方法，需要治疗师根据来访者的动态心理状态进行持续调整。因此，需要一种能够显式建模对话双方动态交互、维持长程对话连贯性的框架。

Method: CALM-IT框架的核心在于将治疗师-来访者的对话建模为一个双向状态空间过程。具体而言：1）**双行为者建模**：同时考虑治疗师和来访者两个独立的行为者；2）**状态空间表示**：定义一套状态变量（如推断的双方对齐状态、当前心理状态、短期目标等）来刻画对话的演进；3）**动态更新机制**：两个行为者根据对话历史持续更新其内部状态表示；4）**策略选择与生成**：基于更新后的状态，治疗师智能体选择治疗策略（如共情、重定向、探索等），并生成相应的话语。来访者智能体则基于其状态生成回应。这种显式的状态追踪和更新机制旨在确保对话朝着治疗目标持续、连贯地推进。

Result: 在大规模评估中，CALM-IT在多个关键指标上显著优于强基线模型：1）**有效性**：对话的整体治疗有效性更高；2）**目标对齐**：对话进程与预设的治疗目标保持更紧密的对齐；3）**稳定性**：随着对话长度的增加（长形式对话），CALM-IT的性能下降远小于基线模型，表现出更强的稳健性；4）**干预效率**：尽管CALM-IT启动的治疗师"重定向"干预次数更少，但其获得的来访者接受率最高（达64.3%），表明其干预时机更精准、更易被来访者接纳，避免了不必要的或时机不当的干预。

Conclusion: CALM-IT框架通过显式建模治疗师与来访者之间的双向状态空间动态，成功地解决了LLMs在生成长形式、目标导向的心理治疗对话时面临的挑战。实验证明，对不断演变的对话状态进行建模对于生成高质量、连贯且有效的长程对话至关重要。该框架不仅提升了对话在长期互动中的稳定性和目标对齐度，还通过更精准的干预时机提高了治疗性互动的效率。这项工作为开发更可靠、更适用于实际临床场景的对话AI系统提供了新的思路和有力的方法论支持。

Abstract: Large Language Models (LLMs) are increasingly used in mental health-related settings, yet they struggle to sustain realistic, goal-directed dialogue over extended interactions. While LLMs generate fluent responses, they optimize locally for the next turn rather than maintaining a coherent model of therapeutic progress, leading to brittleness and long-horizon drift. We introduce CALM-IT, a framework for generating and evaluating long-form Motivational Interviewing (MI) dialogues that explicitly models dual-actor conversational dynamics. CALM-IT represents therapist-client interaction as a bidirectional state-space process, in which both agents continuously update inferred alignment, mental states, and short-term goals to guide strategy selection and utterance generation. Across large-scale evaluations, CALM-IT consistently outperforms strong baselines in Effectiveness and Goal Alignment and remains substantially more stable as conversation length increases. Although CALM-IT initiates fewer therapist redirections, it achieves the highest client acceptance rate (64.3%), indicating more precise and therapeutically aligned intervention timing. Overall, CALM-IT provides evidence for modeling evolving conversational state being essential for generating high-quality long-form synthetic conversations.

</details>


### [75] [SIN-Bench: Tracing Native Evidence Chains in Long-Context Multimodal Scientific Interleaved Literature](https://arxiv.org/abs/2601.10108)
*Yiming Ren,Junjie Wang,Yuxin Meng,Yihang Shi,Zhiqiang Lin,Ruihang Chu,Yiran Xu,Ziming Li,Yunfei Zhao,Zihan Wang,Yu Qiao,Ruiming Tang,Minghao Liu,Yujiu Yang*

Main category: cs.CL

Score: 4/5 | Tags: MLLM, Scientific Document Understanding, Benchmark, Evidence Chain, Multimodal, Evaluation, Long-form Documents

Recommendation: 本文提出了一种创新的多模态大语言模型评估方法，针对现有评估范式的局限性做出了重要改进。FITO范式要求模型构建明确的多模态证据链，这对科学文档理解任务具有重要意义。构建的SIN-Data和SIN-Bench为社区提供了有价值的评估资源。实验发现的基础化瓶颈问题具有实际指导意义。评分扣1分是因为缺乏更广泛的模型对比和任务深度分析，但整体而言是一篇高质量的研究论文。

TL;DR: 评估多模态大语言模型是否真正理解长篇科学论文仍然具有挑战性：仅答案指标和合成的"大海捞针"测试通常奖励答案匹配，而不要求在文档中具有因果、证据关联的推理轨迹。我们提出了"海洋中的鱼"(FITO)范式，要求模型在原生科学文档中构建明确的多模态证据链。为实现FITO，我们构建了SIN-Data，一个保留文本和图表原生交错结构的科学交错语料库。在此基础上，我们构建了SIN-Bench，包含四个渐进任务：证据发现(SIN-Find)、假设验证(SIN-Verify)、基础问答(SIN-QA)和证据锚定摘要(SIN-Summary)。我们进一步引入了"无证据、无评分"，仅在预测基于可验证锚点时才计分，并通过匹配度、相关性和逻辑性诊断证据质量。对八个MLLM的实验表明，基础化是主要瓶颈：Gemini-3-pro取得了最佳平均总分(0.573)，而GPT-5在SIN-QA答案准确率上达到最高(0.767)，但在证据对齐的总分上表现不佳，暴露了正确性和可追溯支持之间的差距。


<details>
  <summary>Details</summary>
Motivation: 现有的多模态大语言模型评估方法存在不足，特别是仅关注答案匹配的评估指标和合成的"大海捞针"测试，这些方法未能要求模型在科学文档中建立因果、证据关联的推理轨迹。因此需要开发更全面的评估范式来衡量模型是否真正理解长篇科学论文，特别是要求模型能够构建明确的多模态证据链。

Method: 提出了"海洋中的鱼"(FITO)评估范式，要求模型在原生科学文档中构建明确的多模态证据链。构建了SIN-Data科学交错语料库，保留文本和图表的原生交错结构。在此基础上设计了SIN-Bench评估基准，包含四个渐进任务：SIN-Find(证据发现)、SIN-Verify(假设验证)、SIN-QA(基础问答)和SIN-Summary(证据锚定摘要)。采用"无证据、无评分"的评分策略，仅当预测基于可验证锚点时才计分，并通过匹配度、相关性和逻辑性三个维度诊断证据质量。

Result: 对八个多模态大语言模型的评估结果显示：Gemini-3-pro获得了最佳平均总分(0.573)，GPT-5在SIN-QA答案准确率上达到最高(0.767)，但在证据对齐的总分上表现不佳。实验暴露了多模态模型在基础化方面的主要瓶颈，并揭示了模型答案正确性和可追溯支持之间的差距。评估结果表明，现有的模型在构建多模态证据链方面仍有较大改进空间。

Conclusion: 该研究提出了"海洋中的鱼"(FITO)范式作为评估多模态大语言模型理解长篇科学论文的新方法。通过构建SIN-Data语料库和SIN-Bench评估基准，研究人员发现基础化是当前多模态模型的主要瓶颈。评估结果显示了模型答案正确性和可追溯证据支持之间的不一致性，强调了在科学文档理解评估中要求明确证据链的重要性。该方法为科学文档理解的更严格评估提供了新的框架和工具。

Abstract: Evaluating whether multimodal large language models truly understand long-form scientific papers remains challenging: answer-only metrics and synthetic "Needle-In-A-Haystack" tests often reward answer matching without requiring a causal, evidence-linked reasoning trace in the document. We propose the "Fish-in-the-Ocean" (FITO) paradigm, which requires models to construct explicit cross-modal evidence chains within native scientific documents. To operationalize FITO, we build SIN-Data, a scientific interleaved corpus that preserves the native interleaving of text and figures. On top of it, we construct SIN-Bench with four progressive tasks covering evidence discovery (SIN-Find), hypothesis verification (SIN-Verify), grounded QA (SIN-QA), and evidence-anchored synthesis (SIN-Summary). We further introduce "No Evidence, No Score", scoring predictions when grounded to verifiable anchors and diagnosing evidence quality via matching, relevance, and logic. Experiments on eight MLLMs show that grounding is the primary bottleneck: Gemini-3-pro achieves the best average overall score (0.573), while GPT-5 attains the highest SIN-QA answer accuracy (0.767) but underperforms on evidence-aligned overall scores, exposing a gap between correctness and traceable support.

</details>


### [76] [Skill-Aware Data Selection and Fine-Tuning for Data-Efficient Reasoning Distillation](https://arxiv.org/abs/2601.10109)
*Lechen Zhang,Yunxiang Zhang,Wei Hu,Lu Wang*

Main category: cs.CL

Score: 4/5 | Tags: LLM, Knowledge Distillation, Reasoning, Mathematics, Efficient Training, Skill-based Learning, SFT

Recommendation: 本文提出了一种新颖的技能中心化蒸馏方法，具有较高的实用价值：1）大幅减少了数据需求（仅需1,000个样本）；2）在数学推理任务上取得显著提升；3）提供了可解释的技能分析框架。该方法对资源有限场景下的模型蒸馏具有重要参考意义。

TL;DR: 大型推理模型（如DeepSeek-R1及其蒸馏变体）在复杂推理任务上表现优异。然而，蒸馏这些模型通常需要大规模数据用于监督微调（SFT），这促使我们寻求数据高效的训练方法。为此，我们提出了一个技能中心化的蒸馏框架，通过两个组成部分有效将推理能力转移至较弱模型：(1) 基于技能的数据选择，优先选择针对学生模型较弱技能的示例；(2) 技能感知的微调，鼓励在问题解决过程中进行显式的技能分解。仅从100K教师生成的语料库中选择1,000个训练示例，我们的方法在五个数学推理基准测试上超过了随机SFT基线：Qwen3-4B提升了+1.6%，Qwen3-8B提升了+1.4%。进一步分析证实，这些提升主要集中在训练期间强调的技能上，突显了技能中心化训练对高效推理蒸馏的有效性。


<details>
  <summary>Details</summary>
Motivation: 大型推理模型及其蒸馏变体在复杂推理任务上表现良好，但蒸馏过程通常需要大规模监督微调数据，导致数据效率低下。为了减少数据需求并提高蒸馏效率，本研究旨在开发一个数据高效的技能中心化蒸馏框架。

Method: 提出了一个技能中心化的蒸馏框架，包含两个核心组成部分：
1. 技能基于数据选择：从大规模教师生成的语料库中优先选择针对学生模型较弱技能的示例
2. 技能感知微调：鼓励模型在问题解决过程中进行显式的技能分解和推理步骤分析

Result: 仅使用1,000个训练示例（从100K教师生成语料库中选择），该框架在五个数学推理基准测试上显著超越了随机SFT基线：Qwen3-4B模型提升了+1.6%，Qwen3-8B模型提升了+1.4%。分析显示，性能提升主要集中在训练期间强调的技能领域。

Conclusion: 技能中心化的蒸馏框架能够有效地将大型推理模型的推理能力转移至较小模型，且只需少量数据。该方法通过有针对性的技能强化和数据选择，实现了数据高效的知识蒸馏，为模型蒸馏领域提供了新的研究方向。

Abstract: Large reasoning models such as DeepSeek-R1 and their distilled variants achieve strong performance on complex reasoning tasks. Yet, distilling these models often demands large-scale data for supervised fine-tuning (SFT), motivating the pursuit of data-efficient training methods. To address this, we propose a skill-centric distillation framework that efficiently transfers reasoning ability to weaker models with two components: (1) Skill-based data selection, which prioritizes examples targeting the student model's weaker skills, and (2) Skill-aware fine-tuning, which encourages explicit skill decomposition during problem solving. With only 1,000 training examples selected from a 100K teacher-generated corpus, our method surpasses random SFT baselines by +1.6% on Qwen3-4B and +1.4% on Qwen3-8B across five mathematical reasoning benchmarks. Further analysis confirms that these gains concentrate on skills emphasized during training, highlighting the effectiveness of skill-centric training for efficient reasoning distillation.

</details>


### [77] [Role-Playing Agents Driven by Large Language Models: Current Status, Challenges, and Future Trends](https://arxiv.org/abs/2601.10122)
*Ye Wang,Jiaxing Chen,Hongjiang Xiao*

Main category: cs.CL

Score: 4/5 | Tags: LLM, Agent, RPLA, NLP, HCI, Survey, Character Modeling, Memory, Evaluation

Recommendation: 推荐理由：这是一篇高质量的系统性综述文章，全面覆盖了角色扮演语言智能体的关键技术领域。文章结构清晰，分析深入，既总结了技术演进又指出了未来方向，对研究者和实践者都具有重要参考价值。唯一不足的是未能提供具体的实验数据或案例研究。

TL;DR: 近年来，随着大语言模型（LLMs）的快速发展，角色扮演语言智能体（RPLAs）已成为自然语言处理（NLP）与人机交互交叉领域的重要研究方向。本文系统回顾了RPLAs当前的发展历程和关键技术，描绘了从早期基于规则的模板范式，经过语言风格模仿阶段，到以个性建模和记忆机制为核心的认知模拟阶段的技术演进脉络。总结了支持高质量角色扮演的关键技术路径，包括心理量表驱动的角色建模、记忆增强的提示机制，以及基于动机情境的行为决策控制。在数据层面，本文进一步分析了角色特定语料库构建的方法与挑战，重点关注数据来源、版权约束和结构化标注流程。在评估方面，整理了覆盖角色知识、个性保真度、价值对齐和交互幻觉的多维评估框架和基准数据集，同时评述了人工评估、奖励模型和基于LLM的打分等方法的优缺点。最后，本文展望了角色扮演智能体的未来发展方向，包括个性演化建模、多智能体协作叙事、多模态沉浸式交互以及与认知神经科学的融合，旨在为后续研究提供系统视角和方法论洞见。


<details>
  <summary>Details</summary>
Motivation: 随着大语言模型的快速发展，角色扮演语言智能体（RPLAs）在NLP和人机交互交叉领域日益重要。现有研究缺乏对这一领域的系统性综述，因此需要全面梳理RPLAs的技术演进、关键方法、数据构建和评估体系，为研究者提供系统的知识框架和方法论指导。

Method: 本文采用系统性文献综述方法，从四个维度展开分析：1）技术演进历程，分析从规则模板到认知模拟的发展路径；2）关键技术路径，包括角色建模、记忆增强和行为决策机制；3）数据构建方法，探讨角色特定语料库的构建挑战与解决方案；4）评估体系，整理多维评估框架和基准数据集。

Result: 研究系统性地呈现了RPLAs领域的发展全貌：1）明确了技术演进的三个阶段；2）总结了心理量表驱动建模、记忆增强提示、动机情境决策等关键技术；3）分析了数据构建中的版权、标注等挑战；4）建立了涵盖角色知识、个性保真度、价值对齐和交互幻觉的评估体系；5）指出了人工评估、奖励模型和LLM评分等评估方法的优缺点。

Conclusion: 本文提供了对角色扮演语言智能体领域的全面综述，系统梳理了技术演进、方法路径、数据挑战和评估体系。为后续研究提供了系统性视角，并展望了个性演化建模、多智能体协作、多模态交互和认知神经科学融合等未来发展方向，对推动该领域的理论研究和实际应用具有重要指导意义。

Abstract: In recent years, with the rapid advancement of large language models (LLMs), role-playing language agents (RPLAs) have emerged as a prominent research focus at the intersection of natural language processing (NLP) and human-computer interaction. This paper systematically reviews the current development and key technologies of RPLAs, delineating the technological evolution from early rule-based template paradigms, through the language style imitation stage, to the cognitive simulation stage centered on personality modeling and memory mechanisms. It summarizes the critical technical pathways supporting high-quality role-playing, including psychological scale-driven character modeling, memory-augmented prompting mechanisms, and motivation-situation-based behavioral decision control. At the data level, the paper further analyzes the methods and challenges of constructing role-specific corpora, focusing on data sources, copyright constraints, and structured annotation processes. In terms of evaluation, it collates multi-dimensional assessment frameworks and benchmark datasets covering role knowledge, personality fidelity, value alignment, and interactive hallucination, while commenting on the advantages and disadvantages of methods such as human evaluation, reward models, and LLM-based scoring. Finally, the paper outlines future development directions of role-playing agents, including personality evolution modeling, multi-agent collaborative narrative, multimodal immersive interaction, and integration with cognitive neuroscience, aiming to provide a systematic perspective and methodological insights for subsequent research.

</details>


### [78] [ToolSafe: Enhancing Tool Invocation Safety of LLM-based agents via Proactive Step-level Guardrail and Feedback](https://arxiv.org/abs/2601.10156)
*Yutao Mou,Zhangchi Xue,Lijun Li,Peiyang Liu,Shikun Zhang,Wei Ye,Jing Shao*

Main category: cs.CL

Score: 4/5 | Tags: LLM, Agent, Safety, Tool-Calling, Security, Reinforcement-Learning, Benchmark

Recommendation: 本论文推荐指数较高，主要基于以下几点：1）选题具有重要实践意义，针对大语言模型智能体实际部署中的安全风险；2）研究体系完整，包含基准构建、模型开发和框架设计；3）技术方案创新，采用多任务强化学习和主动防护机制；4）实验效果显著，大幅减少有害调用同时提升任务完成率；5）具备良好的工程应用价值。不足之处在于技术细节可能需要更多公开讨论，但整体为领域提供了有价值的安全防护方案。

TL;DR: 虽然基于大语言模型（LLM）的智能体能够通过调用外部工具与环境进行交互，但其扩展的功能也同时放大了安全风险。实时监控步级工具调用行为，并在不安全执行前进行主动干预，对于智能体部署至关重要，但这一领域仍缺乏深入探索。在本研究中，我们首先构建了TS-Bench，这是一个用于大语言模型智能体中步级工具调用安全检测的新基准。随后，我们使用多任务强化学习方法开发了一个防护模型TS-Guard。该模型通过对交互历史进行推理，在执行前主动检测不安全的工具调用行为。它评估请求的危害性以及行为与攻击之间的关联性，生成可解释且可泛化的安全判断与反馈。此外，我们还提出了TS-Flow，这是一个由防护反馈驱动的LLM智能体推理框架，该框架在提示注入攻击下，平均减少了65%的ReAct风格智能体有害工具调用，并将良性任务的完成率提升了约10%。


<details>
  <summary>Details</summary>
Motivation: 随着大语言模型智能体通过调用外部工具扩展其能力，安全风险也随之显著增加。特别是工具调用行为可能被恶意利用，导致潜在的有害操作。当前研究对于实时监控步级工具调用并在执行前进行主动干预的防护机制关注不足，这在大语言模型智能体实际部署中构成了安全漏洞。

Method: 本研究采用系统性方法：首先构建了TS-Bench基准测试集，用于评估步级工具调用安全检测。随后提出了TS-Guard防护模型，该模型基于多任务强化学习训练，能够对交互历史进行推理，评估请求的危害性以及动作与攻击的关联性，以主动检测不安全行为。此外还设计了TS-Flow防护反馈驱动框架，将安全判断反馈集成到智能体的推理循环中。

Result: 实验结果表明，TS-Flow框架在对抗提示注入攻击方面效果显著：平均减少了65%的ReAct风格智能体有害工具调用，同时将良性任务完成率提升了约10%。TS-Guard模型能够生成可解释的安全判断，并在不同攻击场景下展现出良好的泛化能力。

Conclusion: 本研究为解决大语言模型智能体工具调用安全问题提供了系统性方案。通过构建专用基准测试、开发主动防护模型和设计反馈驱动框架，显著提升了智能体在对抗环境下的安全性和鲁棒性，为大语言模型智能体的安全部署提供了重要技术支撑。

Abstract: While LLM-based agents can interact with environments via invoking external tools, their expanded capabilities also amplify security risks. Monitoring step-level tool invocation behaviors in real time and proactively intervening before unsafe execution is critical for agent deployment, yet remains under-explored. In this work, we first construct TS-Bench, a novel benchmark for step-level tool invocation safety detection in LLM agents. We then develop a guardrail model, TS-Guard, using multi-task reinforcement learning. The model proactively detects unsafe tool invocation actions before execution by reasoning over the interaction history. It assesses request harmfulness and action-attack correlations, producing interpretable and generalizable safety judgments and feedback. Furthermore, we introduce TS-Flow, a guardrail-feedback-driven reasoning framework for LLM agents, which reduces harmful tool invocations of ReAct-style agents by 65 percent on average and improves benign task completion by approximately 10 percent under prompt injection attacks.

</details>


### [79] [What Gets Activated: Uncovering Domain and Driver Experts in MoE Language Models](https://arxiv.org/abs/2601.10159)
*Guimin Hu,Meng Li,Qiwei Peng,Lijie Hu,Boyan Xu,Ruichu Cai*

Main category: cs.CL

Score: 4/5 | Tags: LLM, MoE, Interpretability, Expert Activation, Causal Analysis, Model Analysis

Recommendation: 这篇论文推荐度较高，因为它填补了MoE LLM专家级可解释性研究的空白，提出了创新的分析方法（熵度和因果效应度量），并获得了具有实际价值的发现。研究结果不仅增强了MoE模型的理解，还为模型优化提供了具体的指导方向。实验设计严谨，在三个不同领域验证了结论的普适性。

TL;DR: 大多数可解释性研究关注Transformer中的层级或神经元级机制，而对MoE LLM中专家级行为的研究不足。受人类大脑功能特化的启发，我们通过区分领域专家和驱动专家来分析专家激活。在本研究中，我们分析了MoE模型在三个公共领域的专家激活，并解决两个关键问题：（1）哪些专家被激活，以及某些专家类型是否表现出一致的激活模式；（2）标记如何与特定专家的激活相关联并触发其激活。为回答这些问题，我们引入了基于熵和因果效应的度量指标，用于评估专家是否对特定领域有强烈偏好，以及专家激活对模型输出的因果贡献强度，从而分别识别领域专家和驱动专家。此外，我们探讨了单个标记如何与特定专家的激活相关联。我们的分析表明：（1）在激活的专家中，一些表现出明显的领域偏好，而另一些对模型性能产生强烈的因果影响，突出了它们的决定性作用；（2）句子中较早出现的标记更可能触发驱动专家；（3）调整领域专家和驱动专家的权重可显著提高所有三个模型和领域的性能。这些发现揭示了MoE模型的内部机制并增强了其可解释性。


<details>
  <summary>Details</summary>
Motivation: 目前大多数可解释性研究集中在Transformer的层级或神经元级机制，而对混合专家（MoE）LLM中专家级行为的研究相对不足。受人类大脑功能专业化（functional specialization）的启发，本研究旨在深入分析MoE模型中专家激活模式，特别是区分不同类型专家（如领域专家和驱动专家）的角色，以增强对MoE模型内部工作机制的理解。

Method: 本研究采用定量分析方法，在三个公共领域对MoE模型进行专家激活分析。主要方法包括：1) 引入基于熵的度量指标来评估专家对特定领域的偏好程度，识别领域专家；2) 采用因果效应度量来评估专家激活对模型输出的因果贡献强度，识别驱动专家；3) 分析单个标记与专家激活之间的关联模式，特别是标记位置对专家激活的影响；4) 通过调整不同类型专家的权重进行实验验证。

Result: 研究发现：1) 在激活的专家中存在两种类型：具有明显领域偏好的领域专家和具有强烈因果影响的驱动专家；2) 句子中较早出现的标记更可能触发驱动专家的激活；3) 调整领域专家和驱动专家的权重可在所有三个模型和领域中实现显著的性能提升，验证了两种专家类型在MoE模型中的重要性。

Conclusion: 本研究通过系统分析MoE模型中专家激活模式，首次明确区分了领域专家和驱动专家两种不同的专家类型。这些发现不仅揭示了MoE模型的内部工作机制，还为提高模型性能和可解释性提供了理论指导。调整不同类型专家的权重能够显著提升模型性能，这为MoE模型的优化设计提供了新的方向。

Abstract: Most interpretability work focuses on layer- or neuron-level mechanisms in Transformers, leaving expert-level behavior in MoE LLMs underexplored. Motivated by functional specialization in the human brain, we analyze expert activation by distinguishing domain and driver experts. In this work, we study expert activation in MoE models across three public domains and address two key questions: (1) which experts are activated, and whether certain expert types exhibit consistent activation patterns; and (2) how tokens are associated with and trigger the activation of specific experts. To answer these questions, we introduce entropy-based and causal-effect metrics to assess whether an expert is strongly favored for a particular domain, and how strongly expert activation contributes causally to the model's output, thus identify domain and driver experts, respectively. Furthermore, we explore how individual tokens are associated with the activation of specific experts. Our analysis reveals that (1) Among the activated experts, some show clear domain preferences, while others exert strong causal influence on model performance, underscoring their decisive roles. (2) tokens occurring earlier in a sentence are more likely to trigger the driver experts, and (3) adjusting the weights of domain and driver experts leads to significant performance gains across all three models and domains. These findings shed light on the internal mechanisms of MoE models and enhance their interpretability.

</details>


### [80] [Alignment Pretraining: AI Discourse Causes Self-Fulfilling (Mis)alignment](https://arxiv.org/abs/2601.10160)
*Cameron Tice,Puria Radmard,Samuel Ratnam,Andy Kim,David Africa,Kyle O'Brien*

Main category: cs.CL

Score: 4/5 | Tags: LLM, Alignment, Pretraining, Safety, NLP, AI Ethics

Recommendation: 这篇论文在AI对齐领域具有重要意义，首次系统研究了预训练语料内容对模型对齐性的因果影响。研究方法严谨，采用控制变量设计和量化评估，为AI安全性研究提供了新视角。论文提出的"对齐预训练"概念具有实际指导价值，对AI开发实践有重要启示。评分为4是因为研究规模相对有限（6.9B参数），且需要更多跨模型、跨语料的验证。

TL;DR: 预训练语料库包含大量关于人工智能系统的讨论，但这些讨论对下游对齐任务的因果影响尚不清楚。如果对AI行为的普遍描述主要是负面的，大语言模型可能会内化相应的行为先验，从而导致自我实现的未对齐现象。本文通过预训练6.9B参数的大语言模型，并控制（未）对齐讨论的数量，首次对这一假设进行了受控研究。我们发现关于AI的讨论确实导致未对齐。上采样关于AI未对齐的合成训练文档会导致未对齐行为的显著增加。相反，上采样关于对齐行为的文档可将未对齐评分从45%降低到9%。我们认为这是自我实现对立的证据。这些影响在训练后会减弱，但仍然持续存在。我们的研究确立了"对齐预训练"这一新研究领域——研究预训练数据如何塑造对齐先验，作为训练后对齐的补充。我们建议从业者在预训练时兼顾能力开发和对齐性。我们的模型和数据集可在alignmentpretraining.ai获取。


<details>
  <summary>Details</summary>
Motivation: 当前预训练语料库中包含大量关于人工智能系统的讨论，但这些讨论内容对模型最终对齐行为的影响机制尚未得到系统研究。研究团队担心如果语料中对AI的描述以负面为主，可能导致LLMs内化这些行为模式，形成自我实现的未对齐现象。这种"对齐预训练"效应可能成为传统训练后对齐方法的重要补充。

Method: 本研究采用控制变量方法，预训练了6.9B参数的大语言模型。核心方法是：1）创建不同比例的对齐/未对齐AI讨论语料；2）通过上采样技术调整这些语料在训练数据中的比例；3）设计专门的评估指标量化模型对齐程度；4）对比分析不同训练条件下模型的对齐表现，包括预训练效果在训练后的持续性。

Result: 研究结果表明：1）关于AI的讨论确实影响模型对齐性；2）上采样未对齐AI讨论导致未对齐行为显著增加；3）上采样对齐AI讨论可将未对齐评分从45%大幅降至9%；4）这些预训练影响在后续训练后虽减弱但仍持续存在；5）证明了"自我实现对联"现象的可行性。

Conclusion: 本论文确立了"对齐预训练"作为一个重要研究领域，证明预训练数据中的AI讨论内容能显著影响模型的对齐先验。这种影响具有持续效应，无法完全通过后续对齐训练消除。因此，建议AI开发者在预训练阶段就要同时考虑能力发展和对齐性设计，将"预训练对齐"作为训练后对齐的重要补充。

Abstract: Pretraining corpora contain extensive discourse about AI systems, yet the causal influence of this discourse on downstream alignment remains poorly understood. If prevailing descriptions of AI behaviour are predominantly negative, LLMs may internalise corresponding behavioural priors, giving rise to self-fulfilling misalignment. This paper provides the first controlled study of this hypothesis by pretraining 6.9B-parameter LLMs with varying amounts of (mis)alignment discourse. We find that discussion of AI contributes to misalignment. Upsampling synthetic training documents about AI misalignment leads to a notable increase in misaligned behaviour. Conversely, upsampling documents about aligned behaviour reduces misalignment scores from 45% to 9%. We consider this evidence of self-fulfilling alignment. These effects are dampened, but persist through post-training. Our findings establish the study of how pretraining data shapes alignment priors, or alignment pretraining, as a complement to post-training. We recommend practitioners pretrain for alignment as well as capabilities. Our models and datasets are available at alignmentpretraining.ai

</details>


### [81] [Credit C-GPT: A Domain-Specialized Large Language Model for Conversational Understanding in Vietnamese Debt Collection](https://arxiv.org/abs/2601.10167)
*Nhung Nguyen Thi Hong,Cuong Nguyen Dang,Tri Le Ngoc*

Main category: cs.CL

Score: 4/5 | Tags: LLM, NLP, 对话系统, 越南语NLP, 金融科技, 情感分析, 意图识别, 领域适应

Recommendation: 推荐理由：本文在领域专业化LLM应用方面提供了有价值的实践案例，针对具体的行业需求（债务催收）和语言环境（越南语）进行了深入研究。模型集成了多个对话智能任务，具有实用性和创新性。研究关注隐私保护和实时应用，符合企业实际需求。不足之处在于缺乏与其他最新LLM模型的比较，且对模型具体架构描述不够详细。

TL;DR: 债务催收是银行、金融服务和保险（BFSI）行业的一项关键职能，严重依赖越南呼叫中心进行的大规模人与人对话交流。这些对话涉及非正式口语、情绪多变性和复杂的领域特定推理，对传统的自然语言处理系统构成重大挑战。本文介绍了Credit C-GPT，这是一个专为越南债务催收场景对话理解而微调的领域专业化大型语言模型，拥有70亿参数。所提出的模型将多个对话智能任务（包括对话理解、情感识别、意图检测、通话阶段分类和结构化槽值提取）集成在一个基于推理的框架内。我们描述了数据构建过程、标注策略和训练方法，并在专有的人工标注数据集上评估模型。实验结果显示，与传统基于流水线的方法相比取得了持续改进，表明领域专业化对话语言模型为企业呼叫中心的实时协助和通话后分析提供了可扩展且隐私意识的解决方案。


<details>
  <summary>Details</summary>
Motivation: 债务催收领域面临多重挑战：越南语非正式口语处理、对话中的情感变化、复杂的领域特定推理需求，以及传统自然语言处理系统在处理这些复杂对话场景时的局限性。现有的通用模型难以准确理解债务催收对话的细微差别，而传统的流水线方法则存在集成复杂性和性能限制。因此，需要开发一个领域专业化的对话理解模型来满足BFSI行业对实时协助和通话后分析的需求。

Method: 本文提出了Credit C-GPT，一个专门为越南债务催收场景设计的70亿参数大型语言模型。采用的方法包括：1) 构建针对债务催收对话的专有数据集；2) 开发综合标注策略，涵盖对话理解、情感识别、意图检测、通话阶段分类和槽值提取；3) 在微调过程中采用基于推理的训练框架，将多个对话智能任务集成到单一模型中；4) 针对越南语非正式口语特征进行优化；5) 确保模型的隐私意识设计，适用于企业环境。

Result: 实验结果显示，Credit C-GPT在专有的人工标注数据集上取得了显著优于传统流水线方法的性能。该模型在多任务对话理解方面表现一致提升，包括：对话理解准确性提高、情感识别精度增强、意图检测准确率改善、通话阶段分类效果更好，以及结构化槽值提取质量提升。模型展现出处理越南语非正式口语和复杂领域推理的能力，同时保持了可扩展性和隐私保护特性。

Conclusion: 本文成功开发了一个专为越南债务催收场景设计的领域专业化对话语言模型Credit C-GPT。该模型通过集成多个对话智能任务到单一推理框架中，有效解决了传统方法的局限性。研究结果表明，领域专业化的对话语言模型能够为企业呼叫中心提供可扩展、隐私意识的解决方案，适用于实时协助和通话后分析。该工作为BFSI行业的对话智能应用提供了有价值的参考，展示了大型语言模型在特定领域商业化应用中的潜力。

Abstract: Debt collection is a critical function within the banking, financial services, and insurance (BFSI) sector, relying heavily on large-scale human-to-human conversational interactions conducted primarily in Vietnamese contact centers. These conversations involve informal spoken language, emotional variability, and complex domain-specific reasoning, which pose significant challenges for traditional natural language processing systems. This paper introduces Credit C-GPT, a domain-specialized large language model with seven billion parameters, fine-tuned for conversational understanding in Vietnamese debt collection scenarios. The proposed model integrates multiple conversational intelligence tasks, including dialogue understanding, sentiment recognition, intent detection, call stage classification, and structured slot-value extraction, within a single reasoning-based framework. We describe the data construction process, annotation strategy, and training methodology, and evaluate the model on proprietary human-annotated datasets. Experimental results show consistent improvements over traditional pipeline-based approaches, indicating that domain-specialized conversational language models provide a scalable and privacy-aware solution for real-time assistance and post-call analytics in enterprise contact centers.

</details>


### [82] [HOMURA: Taming the Sand-Glass for Time-Constrained LLM Translation via Reinforcement Learning](https://arxiv.org/abs/2601.10187)
*Ziang Cui,Mengran Yu,Tianjiao Li,Chenyu Shi,Yingxuan Shi,Lusheng Zhang,Hongwei Lin*

Main category: cs.CL

Score: 5/5 | Tags: LLM, NLP, Machine Translation, Multilingual, Reinforcement Learning, Time-constrained Tasks

Recommendation: 该论文解决了LLM在多语言翻译中一个重要实际问题——时间约束下的长度控制，提出的HOMURA框架具有创新性，实验设计严谨，基准建设有针对性，对实际应用场景如字幕翻译有重要意义。

TL;DR: 大型语言模型(LLM)在多语言翻译方面取得了显著进展，但受到系统性跨语言冗余偏见的阻碍，使得它们不适合字幕和配音等严格时间受限的任务。当前的提示工程方法难以解决语义保真度和严格时间可行性之间的冲突。为弥合这一差距，我们首先引入了Sand-Glass，这是一个专门设计用于评估音节级别时长约束下翻译的基准。此外，我们提出了HOMURA，一个强化学习框架，明确优化语义保持和时间合规性之间的权衡。通过采用具有新颖动态音节比奖励的KL正则化目标，HOMURA有效"驯服"输出长度。实验结果表明，我们的方法显著优于强大的LLM基线，实现了精确的长度控制，既尊重语言密度层次结构，又不损害语义充分性。


<details>
  <summary>Details</summary>
Motivation: 大型语言模型在多语言翻译中虽然表现出色，但存在系统性跨语言冗余偏见问题，导致生成内容过长，不符合字幕、配音等严格时间受限任务的要求。现有提示工程方法难以平衡语义保真度和时间约束，因此需要开发能够精确控制输出长度的方法。

Method: 提出了HOMURA强化学习框架，该方法使用KL正则化目标和动态音节比奖励来优化语义保持和时间合规性之间的权衡。首先创建了Sand-Glass基准来评估音节级别时长约束下的翻译质量。框架通过强化学习训练模型在保持语义充分性的同时精确控制输出长度。

Result: 实验结果表明，HOMURA方法在音节级别时长约束下的翻译任务中显著优于强大的LLM基线模型。该方法能够实现精确的长度控制，同时尊重语言密度层次结构，不损害语义充分性，有效解决了跨语言冗余偏见问题。

Conclusion: HOMURA框架成功解决了大型语言模型在时间受限翻译任务中的长度控制问题，通过强化学习和动态音节比奖励机制实现了语义保持和时间合规性的有效平衡，为字幕、配音等实际应用场景提供了可行的解决方案。

Abstract: Large Language Models (LLMs) have achieved remarkable strides in multilingual translation but are hindered by a systemic cross-lingual verbosity bias, rendering them unsuitable for strict time-constrained tasks like subtitling and dubbing. Current prompt-engineering approaches struggle to resolve this conflict between semantic fidelity and rigid temporal feasibility. To bridge this gap, we first introduce Sand-Glass, a benchmark specifically designed to evaluate translation under syllable-level duration constraints. Furthermore, we propose HOMURA, a reinforcement learning framework that explicitly optimizes the trade-off between semantic preservation and temporal compliance. By employing a KL-regularized objective with a novel dynamic syllable-ratio reward, HOMURA effectively "tames" the output length. Experimental results demonstrate that our method significantly outperforms strong LLM baselines, achieving precise length control that respects linguistic density hierarchies without compromising semantic adequacy.

</details>


### [83] [One Instruction Does Not Fit All: How Well Do Embeddings Align Personas and Instructions in Low-Resource Indian Languages?](https://arxiv.org/abs/2601.10205)
*Arya Shah,Himanshu beniwal,Mayank Singh*

Main category: cs.CL

Score: 4/5 | Tags: Multilingual, Embedding Models, Retrieval, India, LLM Alignment, Evaluation Benchmark, Cross-lingual

Recommendation: 推荐此论文的原因：1) 针对印度多语言环境的实际问题，填补了现有研究的空白；2) 建立了系统化的评估框架，涵盖12种印度语言和四个核心任务；3) 提供了全面的模型性能比较和实用指导；4) 数据集和代码已公开，具有可复现性；5) 为多语言助手对齐领域提供了有价值的基准。扣1分主要是因为研究范围相对集中于印度语言，对更广泛的多语言场景参考价值有限。

TL;DR: 将多语言助手与基于文化背景的用户偏好对齐对于服务印度超过10亿使用多种文字的多样化语言群体至关重要。然而，现有基准要么专注于单一语言，要么将检索与生成混为一谈，留下了一个开放问题：当前的嵌入模型是否能够编码人物描述-指令兼容性而无需依赖响应合成。我们提出了一个统一基准，涵盖12种印度语言和四个评估任务：单语言和跨语言人物描述到指令检索、从指令到人物描述的反向检索，以及二元兼容性分类。在冻结编码器设置下评估了八个多语言嵌入模型，使用薄逻辑回归头进行分类。E5-Large-Instruct在单语言检索中获得了最高的27.4% Recall@1，在跨语言迁移中达到20.7%，而BGE-M3在反向检索中以32.1% Recall@1领先。对于分类，LaBSE获得了75.3%的AUROC并具有强大的校准能力。这些发现为印度多语言检索中的模型选择提供了实用指导，并为未来工作建立了可复现的基准。


<details>
  <summary>Details</summary>
Motivation: 本研究旨在解决多语言助手在印度多样化语言环境中的对齐问题。印度拥有超过10亿使用者，涉及多种文字和语言，现有基准要么仅关注单一语言，要么将检索和生成任务混淆。这留下了关键的研究空白：当前的嵌入模型能否在不依赖响应生成的情况下，直接评估人物描述与指令之间的兼容性。论文试图通过建立系统化的评估框架，为印度多语言场景下的助手对齐提供基准和实用指导。

Method: 论文构建了一个统一基准，涵盖12种印度语言，并设计了四个核心评估任务：1) 单语言人物描述到指令检索；2) 跨语言人物描述到指令检索；3) 从指令到人物描述的反向检索；4) 二元兼容性分类。在实验设置中，采用了冻结编码器方法，使用薄逻辑回归头进行分类任务。评估了八个主流多语言嵌入模型，包括E5-Large-Instruct、BGE-M3、LaBSE等。数据集和代码已公开提供。

Result: 实验结果显示，在单语言人物描述到指令检索任务中，E5-Large-Instruct取得了最高的27.4% Recall@1；在跨语言迁移任务中，同一模型达到20.7% Recall@1。对于反向检索任务（从指令检索人物描述），BGE-M3表现最佳，Recall@1为32.1%。在二元兼容性分类任务中，LaBSE获得了75.3%的AUROC，并展现出较强的校准能力。这些结果为不同任务场景下的模型选择提供了明确的性能参考。

Conclusion: 本研究成功构建了涵盖12种印度语言的统一基准，系统评估了多语言嵌入模型在人物描述-指令对齐任务上的性能。结果表明，不同的嵌入模型在不同任务上各具优势：E5-Large-Instruct在标准检索任务中表现突出，BGE-M3在反向检索中领先，而LaBSE在分类任务中表现最佳。这项工作为印度多语言场景下的模型选择提供了实用指导，并建立了可复现的基准，为未来在多语言对齐领域的研究奠定了基础。

Abstract: Aligning multilingual assistants with culturally grounded user preferences is essential for serving India's linguistically diverse population of over one billion speakers across multiple scripts. However, existing benchmarks either focus on a single language or conflate retrieval with generation, leaving open the question of whether current embedding models can encode persona-instruction compatibility without relying on response synthesis. We present a unified benchmark spanning 12 Indian languages and four evaluation tasks: monolingual and cross-lingual persona-to-instruction retrieval, reverse retrieval from instruction to persona, and binary compatibility classification. Eight multilingual embedding models are evaluated in a frozen-encoder setting with a thin logistic regression head for classification. E5-Large-Instruct achieves the highest Recall@1 of 27.4\% on monolingual retrieval and 20.7\% on cross-lingual transfer, while BGE-M3 leads reverse retrieval at 32.1\% Recall@1. For classification, LaBSE attains 75.3\% AUROC with strong calibration. These findings offer practical guidance for model selection in Indic multilingual retrieval and establish reproducible baselines for future work\footnote{Code, datasets, and models are publicly available at https://github.com/aryashah2k/PI-Indic-Align.

</details>


### [84] [Loop as a Bridge: Can Looped Transformers Truly Link Representation Space and Natural Language Outputs?](https://arxiv.org/abs/2601.10242)
*Guanxu Chen,Dongrui Liu,Jing Shao*

Main category: cs.CL

Score: 4/5 | Tags: LLM, Transformers, Architecture, Representation Learning, Cognitive Modeling, Introspection

Recommendation: 推荐理由：本文针对LLM领域的重要问题——内部知识与外部表达的不匹配进行了实证研究，提出了有意义的发现。研究设计严谨，结果揭示了循环变换器架构的局限性，为未来架构改进提供了方向。研究深入探讨了自省机制这一前沿课题，对理解LLM内部工作机制有重要贡献。

TL;DR: 大型语言模型（LLMs）通常在其内部知识和显式语言输出之间存在差距。在本报告中，我们通过实证研究循环变换器（LTs）——通过迭代共享层来增加计算深度的架构——是否可以利用其迭代特性作为一种自省形式来弥合这一差距。我们的实验表明，虽然增加循环迭代次数可以缩小这一差距，但部分原因在于表征所携带的内部知识退化。此外，另一项实证分析表明，当前LTs感知表征的能力在循环过程中并未改善；仅存在于最终循环中。这些结果表明，虽然LTs为扩展计算深度提供了一个有希望的方向，但它们尚未实现真正连接表征空间和自然语言所需的自省能力。


<details>
  <summary>Details</summary>
Motivation: 本论文的动机源于大型语言模型内部知识与其显式语言输出之间存在的差距问题。研究者希望探索循环变换器架构是否能够通过其迭代特性实现某种形式的"自省"，从而有效连接模型内部表征与外部语言输出，解决LLMs中存在的这种知识表达不匹配问题。

Method: 研究方法采用实证分析，通过对循环变换器（LTs）进行实验探究。具体包括：1）测试不同循环迭代次数对缩小知识差距的影响；2）分析循环过程中表征知识的变化情况；3）评估LTs在不同循环阶段感知表征的能力变化。研究通过量化分析来检验循环迭代是否真正实现了有效的自省机制。

Result: 实验结果显示：1）增加循环迭代次数确实能够缩小内部知识与语言输出之间的差距；2）但这种差距缩小的部分原因是表征所携带的内部知识发生了退化；3）当前循环变换器感知表征的能力并没有在循环过程中逐步改善，仅在最终循环中表现出这种能力。这表明虽然循环架构在计算深度方面有优势，但尚未实现真正的自省机制。

Conclusion: 本文得出结论：循环变换器虽然为扩展计算深度提供了有前景的方向，但当前的实现尚未达到真正连接表征空间和自然语言所需的自省能力。循环迭代可以缩小知识差距，但部分是通过表征知识退化实现的，而非通过有效的自省机制。这表明需要进一步改进架构设计，以实现更有效的知识提取和表征-语言连接机制。

Abstract: Large Language Models (LLMs) often exhibit a gap between their internal knowledge and their explicit linguistic outputs. In this report, we empirically investigate whether Looped Transformers (LTs)--architectures that increase computational depth by iterating shared layers--can bridge this gap by utilizing their iterative nature as a form of introspection. Our experiments reveal that while increasing loop iterations narrows the gap, it is partly driven by a degradation of their internal knowledge carried by representations. Moreover, another empirical analysis suggests that current LTs' ability to perceive representations does not improve across loops; it is only present in the final loop. These results suggest that while LTs offer a promising direction for scaling computational depth, they have yet to achieve the introspection required to truly link representation space and natural language.

</details>


### [85] [Untangling Input Language from Reasoning Language: A Diagnostic Framework for Cross-Lingual Moral Alignment in LLMs](https://arxiv.org/abs/2601.10257)
*Nan Li,Bo Kang,Tijl De Bie*

Main category: cs.CL

Score: 4/5 | Tags: LLM, Moral Reasoning, Cross-lingual, Evaluation, Ethics, NLP, Multilingual

Recommendation: 推荐该论文的原因：1) 提出了创新的评估框架，解决了标准方法的重要局限性；2) 研究设计严谨，覆盖了13个不同LLMs；3) 发现了有意义的实证结果，如推理语言效应的重要性；4) 提供了实用的部署指导；5) 开源了代码和数据集。不足之处在于研究仅局限于英汉双语对比，未来可扩展到更多语言和文化背景。

TL;DR: 当大型语言模型判断道德困境时，它们在不同语言中是否会得出不同的结论？如果是，为什么？可能有两个因素驱动这种差异：困境本身的语言，或者模型推理的语言。标准评估仅测试匹配条件（例如，英语困境与英语推理），将这两者混为一谈。我们引入了一种方法，分别操纵每个因素，涵盖不匹配条件（例如，英语困境与中文推理），从而能够分解它们的贡献。为了研究变化的内容，我们提出了一种基于道德基础理论解释道德判断的方法。作为一个附带结果，我们找到了将权威维度分解为家庭相关和制度相关维度的证据。将这种方法应用于13个大型语言模型的英汉道德判断，我们展示了其诊断能力：（1）该框架将推理语言效应分离出来，其贡献的方差是输入语言效应的两倍；（2）它检测到近一半模型中存在上下文依赖性，而标准评估未能发现；（3）诊断分类将这些模式转化为部署指导。我们在 https://anonymous.4open.science/r/CrossCulturalMoralJudgement 发布了代码和数据集。


<details>
  <summary>Details</summary>
Motivation: 本研究的动机在于探索大型语言模型在多语言环境下的道德判断一致性。当前评估方法仅测试语言匹配条件，无法区分究竟是困境语言本身还是推理语言导致了判断差异。这种局限性阻碍了对LLMs跨语言道德判断行为的深入理解，也影响了模型在不同文化背景下的可靠部署。

Method: 研究方法包括三个核心部分：1) 设计分离评估框架，分别操纵输入语言和推理语言，涵盖匹配和不匹配条件；2) 应用道德基础理论（MFT）作为道德判断的解释框架；3) 对权威维度进行细化分析，将其分解为家庭相关和制度相关维度。研究覆盖了13个不同的LLMs，在英汉双语环境下进行系统性评估。

Result: 研究结果揭示了几个重要发现：1) 推理语言效应贡献的方差是输入语言效应的两倍，表明模型内部推理语言对道德判断的影响更大；2) 新方法检测到近一半模型中存在标准评估未能发现的上下文依赖性；3) 确定了权威维度的细分，发现了家庭相关和制度相关权威的区别；4) 构建了诊断分类法，为模型部署提供实用指导。

Conclusion: 本文提出了一个能够分离输入语言和推理语言影响的评估框架，显著改进了对LLMs跨语言道德判断的理解。研究发现推理语言效应比输入语言效应更为显著，揭示了标准评估方法的局限性。该研究不仅提供了诊断工具，还为LLMs在不同文化背景下的道德一致性评估和部署提供了实用指导。

Abstract: When LLMs judge moral dilemmas, do they reach different conclusions in different languages, and if so, why? Two factors could drive such differences: the language of the dilemma itself, or the language in which the model reasons. Standard evaluation conflates these by testing only matched conditions (e.g., English dilemma with English reasoning). We introduce a methodology that separately manipulates each factor, covering also mismatched conditions (e.g., English dilemma with Chinese reasoning), enabling decomposition of their contributions. To study \emph{what} changes, we propose an approach to interpret the moral judgments in terms of Moral Foundations Theory. As a side result, we identify evidence for splitting the Authority dimension into a family-related and an institutional dimension. Applying this methodology to English-Chinese moral judgment with 13 LLMs, we demonstrate its diagnostic power: (1) the framework isolates reasoning-language effects as contributing twice the variance of input-language effects; (2) it detects context-dependency in nearly half of models that standard evaluation misses; and (3) a diagnostic taxonomy translates these patterns into deployment guidance. We release our code and datasets at https://anonymous.4open.science/r/CrossCulturalMoralJudgement.

</details>


### [86] [MoST: Mixing Speech and Text with Modality-Aware Mixture of Experts](https://arxiv.org/abs/2601.10272)
*Yuxuan Lou,Kai Yang,Yang You*

Main category: cs.CL

Score: 5/5 | Tags: Multimodal, Speech-Text, Mixture of Experts, ASR, TTS, Large Language Model, Routing Mechanism

Recommendation: 该论文提出了创新的模态感知混合专家架构，有效解决了多模态处理中的模态差异问题，在多个基准测试中展示了优异的性能。作为首个完全开源的语音-文本混合专家模型，MoST具有良好的可复现性和扩展性，为多模态AI研究提供了重要贡献。其架构设计和训练策略具有启发意义，值得推荐给相关领域的研究者。

TL;DR: 我们提出了MoST（语音与文本混合），这是一种新颖的多模态大语言模型，通过我们提出的模态感知混合专家（MAMoE）架构无缝整合语音和文本处理。虽然当前的多模态模型通常使用相同的参数处理不同的模态表示，忽视了它们固有的表示差异，但我们引入了专门的路由路径，根据输入类型将标记定向到模态适当的专家。MAMoE通过两个互补组件同时增强模态特定学习和跨模态理解：捕获领域特定模式的模态特定专家组和促进模态间信息传递的共享专家。基于此架构，我们开发了一个高效的转换管道，通过在ASR和TTS数据集上进行策略性后训练，然后使用精心策划的语音-文本指令数据集进行微调，来适应预训练的MoE语言模型。该管道的一个关键特征是仅依赖完全可访问的开源数据集来实现强大的性能和数据效率。在ASR、TTS、音频语言建模和语音问答基准测试中的全面评估表明，MoST始终优于具有可比参数数量的现有模型。我们的消融研究证实，模态特定路由机制和共享专家设计在所有测试领域中都显著促进了性能提升。据我们所知，MoST代表了首个基于混合专家架构的完全开源语音-文本LLM。


<details>
  <summary>Details</summary>
Motivation: 当前多模态大语言模型在处理不同模态（如语音和文本）时通常使用相同的参数，忽视了不同模态的固有表示差异。这种统一处理方式无法充分利用模态特定的模式，也无法优化跨模态理解。因此，需要一种能够同时增强模态特定学习和跨模态交互的新架构，以提高语音-文本处理模型的性能。

Method: 本文提出了模态感知混合专家（MAMoE）架构，包含两个关键组件：1）模态特定专家组：专门处理语音或文本输入，捕获领域特定模式；2）共享专家：促进模态间信息传递和跨模态理解。模型采用高效转换管道：先在ASR和TTS数据集上进行策略性后训练，然后在精心策划的语音-文本指令数据集上进行微调。整个过程仅使用开源数据集，确保模型的开放性和可复现性。

Result: 在ASR、TTS、音频语言建模和语音问答等多个基准测试中，MoST均显著优于具有可比参数数量的现有模型。消融研究证实，模态特定路由机制和共享专家设计是所有测试领域性能提升的关键因素。模型展示了优秀的性能和数据效率，同时保持了完全开源的特性。

Conclusion: MoST通过创新的模态感知混合专家架构，成功解决了多模态模型中模态表示差异的问题，实现了语音和文本处理的高效集成。该模型在多项任务中表现优异，证明了模态特定学习和跨模态理解的协同重要性。作为首个基于混合专家架构的完全开源语音-文本LLM，MoST为多模态研究提供了重要的基准和工具。

Abstract: We present MoST (Mixture of Speech and Text), a novel multimodal large language model that seamlessly integrates speech and text processing through our proposed Modality-Aware Mixture of Experts (MAMoE) architecture. While current multimodal models typically process diverse modality representations with identical parameters, disregarding their inherent representational differences, we introduce specialized routing pathways that direct tokens to modality-appropriate experts based on input type. MAMoE simultaneously enhances modality-specific learning and cross-modal understanding through two complementary components: modality-specific expert groups that capture domain-specific patterns and shared experts that facilitate information transfer between modalities. Building on this architecture, we develop an efficient transformation pipeline that adapts the pretrained MoE language model through strategic post-training on ASR and TTS datasets, followed by fine-tuning with a carefully curated speech-text instruction dataset. A key feature of this pipeline is that it relies exclusively on fully accessible, open-source datasets to achieve strong performance and data efficiency. Comprehensive evaluations across ASR, TTS, audio language modeling, and spoken question answering benchmarks show that MoST consistently outperforms existing models of comparable parameter counts. Our ablation studies confirm that the modality-specific routing mechanism and shared experts design significantly contribute to performance gains across all tested domains. To our knowledge, MoST represents the first fully open-source speech-text LLM built on a Mixture of Experts architecture. \footnote{We release MoST model, training code, inference code, and training data at https://github.com/NUS-HPC-AI-Lab/MoST

</details>


### [87] [The Straight and Narrow: Do LLMs Possess an Internal Moral Path?](https://arxiv.org/abs/2601.10307)
*Luoming Hu,Jingjie Zeng,Liang Yang,Hongfei Lin*

Main category: cs.CL

Score: 4/5 | Tags: LLM, AI Safety, Alignment, Moral Foundations Theory, Multilingual, Interpretability

Recommendation: 推荐理由：本文提出了创新的内在道德表征干预方法，突破传统对齐技术的表面性限制；结合跨语言分析，具有较好的理论深度和实践价值；AMF方法在实证中表现出色，对解决LLM安全性与帮助性权衡问题有重要贡献。评分为4分，因为该方法虽然创新且有效，但可能在实际部署中需要更多工程验证。

TL;DR: 增强大型语言模型（LLM）的道德对齐是AI安全的关键挑战。当前的对齐技术通常仅作为表层护栏，未能触及LLM内在的道德表征。本文通过运用道德基础理论（MFT）来映射和操作LLM的细粒度道德格局。通过跨语言线性探测，我们验证了中间层道德表征的共享性质，并揭示了英语和中文之间共享但不同的道德子空间。基于此，我们提取可操纵的道德向量，并在内部和行为层面上成功验证其有效性。利用道德的高泛化性，我们提出了自适应道德融合（AMF），这是一种动态的推理时干预方法，通过协同探测器与向量注入来解决安全性与帮助性之间的权衡。实证结果表明，我们的方法作为针对性的内在防御，相比标准基线，能有效减少对良性查询的错误拒绝，同时最小化越狱成功率。


<details>
  <summary>Details</summary>
Motivation: 当前LLM的道德对齐技术主要停留在表面护栏层面，未能深入干预模型内在的道德表征，导致对齐效果不够彻底。本文旨在填补这一空白，通过理解并操纵LLM内部的细粒度道德表征，实现更本质的对齐改进。

Method: 方法基于道德基础理论（MFT）框架，采用跨语言线性探测技术分析LLM中间层的道德表征共享特性，并识别英语和中文的道德子空间。从中提取可操纵的道德向量，验证其在内部和行为层面的有效性。最后提出自适应道德融合（AMF），这是一种推理时动态干预机制，结合探测器检测和道德向量注入来解决安全性与帮助性的平衡问题。

Result: 实证结果显示：1）跨语言探测验证了LLM中间层存在共享的道德表征模式；2）提取的道德向量可在内部和行为层面有效操纵模型道德判断；3）AMF方法相比标准基线，能显著减少对良性查询的错误拒绝率，同时有效降低越狱成功率，实现了更好的安全性与帮助性平衡。

Conclusion: 本文证明通过道德基础理论和跨语言分析可以深入理解LLM的内在道德表征，提出的AMF方法作为一种针对性的内在防御机制，能够有效改善LLM的道德对齐，在处理安全性与帮助性权衡问题上优于现有方法，为AI安全提供了新的内在干预途径。

Abstract: Enhancing the moral alignment of Large Language Models (LLMs) is a critical challenge in AI safety. Current alignment techniques often act as superficial guardrails, leaving the intrinsic moral representations of LLMs largely untouched. In this paper, we bridge this gap by leveraging Moral Foundations Theory (MFT) to map and manipulate the fine-grained moral landscape of LLMs. Through cross-lingual linear probing, we validate the shared nature of moral representations in middle layers and uncover a shared yet different moral subspace between English and Chinese. Building upon this, we extract steerable Moral Vectors and successfully validate their efficacy at both internal and behavioral levels. Leveraging the high generalizability of morality, we propose Adaptive Moral Fusion (AMF), a dynamic inference-time intervention that synergizes probe detection with vector injection to tackle the safety-helpfulness trade-off. Empirical results confirm that our approach acts as a targeted intrinsic defense, effectively reducing incorrect refusals on benign queries while minimizing jailbreak success rates compared to standard baselines.

</details>


### [88] [Multilinguality as Sense Adaptation](https://arxiv.org/abs/2601.10310)
*Jan Christian Blaise Cruz,David Ifeoluwa Adelani,Alham Fikri Aji*

Main category: cs.CL

Score: 4/5 | Tags: LLM, Multilingual, Semantic, Alignment, Backpack, Transfer Learning

Recommendation: 本文提出了一个新颖的语义层面的多语言对齐方法，创新性地将多语言处理视为语义适配问题而非简单的参数共享。方法在四种类型多样化语言上验证有效，且具有数据效率优势。这对于资源有限语言的多语言模型发展具有重要意义。不过，需要更多语言类型验证其通用性。

TL;DR: 我们通过语义适配来处理多语言性：跨语言对齐潜在意义表示，而不仅仅依赖于共享参数和规模。在本文中，我们介绍了基于语义的对称跨语言对齐（SENSIA），它通过在平行数据上显式对齐语义层面的混合和上下文表示，同时联合训练目标语言建模损失以保持流畅性，从而使Backpack语言模型从一种语言适配到另一种语言。在四种类型多样语言的基准测试中，SENSIA通常优于可比较的多语言对齐方法，并且在使用2-4倍少的目标语言数据的情况下，相对于从头开始的单语言基线实现了竞争性准确率。对学习语义几何的分析表明，局部语义拓扑和相对于英语的全局结构在很大程度上得以保留，消融研究显示该方法在设计和规模上具有鲁棒性。


<details>
  <summary>Details</summary>
Motivation: 当前多语言模型主要依赖共享参数和规模化来提升跨语言能力，但这种方法存在局限性。本文的动机在于探索一种更本质的多语言处理方法——通过语义层面的对齐来实现语言适配，而不只是参数共享。这旨在提升模型对语言之间潜在语义结构的理解，从而在更少数据需求下实现更好的跨语言性能。

Method: SENSIA（基于语义的对称跨语言对齐）方法的核心包括：1）使用Backpack语言模型作为基础架构；2）在平行数据上显式对齐两种语言的语义层面表示；3）同时优化对称跨语言对齐损失和目标语言建模损失；4）保持源语言和目标语言之间的语义拓扑结构一致性。该方法通过语义混合和上下文表示的对齐来实现语言适配。

Result: SENSIA在四种类型多样化语言（英语、法语、德语、中文）的基准测试中表现出色：1）通常优于其他多语言对齐方法；2）仅使用2-4倍少的目标语言数据就能达到与从头训练单语言基线相当的准确率；3）语义几何分析显示局部语义拓扑和相对于英语的全局结构得到良好保持；4）消融实验证明该方法在不同设计和规模下都具有鲁棒性。

Conclusion: SENSIA通过语义适配方法实现了高效的多语言学习，证明了语义层面对齐相对于传统参数共享方法的优势。该方法能够在显著减少目标语言数据需求的情况下，保持语义结构的完整性，为多语言模型的发展提供了新的方向，强调了语义层面理解在跨语言建模中的重要性。

Abstract: We approach multilinguality as sense adaptation: aligning latent meaning representations across languages rather than relying solely on shared parameters and scale. In this paper, we introduce SENse-based Symmetric Interlingual Alignment (SENSIA), which adapts a Backpack language model from one language to another by explicitly aligning sense-level mixtures and contextual representations on parallel data, while jointly training a target-language language modeling loss to preserve fluency. Across benchmarks on four typologically diverse languages, SENSIA generally outperforms comparable multilingual alignment methods and achieves competitive accuracy against monolingual from-scratch baselines while using 2-4x less target-language data. Analyses of learned sense geometry indicate that local sense topology and global structure relative to English are largely preserved, and ablations show that the method is robust in terms of design and scale.

</details>


### [89] [ADVOSYNTH: A Synthetic Multi-Advocate Dataset for Speaker Identification in Courtroom Scenarios](https://arxiv.org/abs/2601.10315)
*Aniket Deroy*

Main category: cs.CL

Score: 3/5 | Tags: 语音合成, 语音识别, 数据集, 说话人识别, 音频处理, 语音技术

Recommendation: 这篇论文提出了一个专门针对合成语音区分问题的数据集，在当前语音合成技术快速发展、合成语音难以与真实语音区分的背景下具有现实意义。数据集规模相对有限（100个文件），但设计概念明确，面向法庭辩论这一具体应用场景。推荐程度中等，主要价值在于提出了一个特定的研究方向，但数据集规模和研究深度需要进一步扩展。

TL;DR: 随着大规模语音到语音模型实现高保真度，结构化环境中合成语音的区分成为一个重要研究领域。本文介绍了Advosynth-500，这是一个包含100个合成语音文件的专业数据集，具有10个独特的倡导者身份。使用Speech Llama Omni模型，我们模拟了五组不同的倡导者对参与法庭辩论。我们为每个倡导者定义了特定的声音特征，并提出了一个说话人识别挑战，以评估现代系统将音频文件映射到各自合成来源的能力。


<details>
  <summary>Details</summary>
Motivation: 随着语音合成技术的高保真度发展，合成语音在结构化环境中的区分变得至关重要。特别是在需要识别不同说话者身份的法庭辩论等场景中，研究如何区分高度仿真的合成声音具有重要的现实意义和应用价值。

Method: 作者创建了Advosynth-500专业数据集，包含100个合成语音文件，代表了10个独特的倡导者身份。使用Speech Llama Omni模型模拟了五组不同的倡导者对参与法庭辩论。为每个倡导者定义了特定的声音特征，并设计了说话人识别挑战任务来评估系统的区分能力。

Result: 构建了一个专门用于评估合成语音区分能力的数据集，包含100个语音文件和10个独特的倡导者身份。通过定义具体的声学特征和设计说话人识别任务，为研究合成语音的身份区分提供了基准测试工具。

Conclusion: 本文通过创建Advosynth-500数据集，为解决合成语音在结构化环境中的区分问题提供了重要工具。该数据集可用于评估现代语音处理系统对高保真合成声音的身份识别能力，为合成语音检测和说话人识别研究提供了新的基准。

Abstract: As large-scale speech-to-speech models achieve high fidelity, the distinction between synthetic voices in structured environments becomes a vital area of study. This paper introduces Advosynth-500, a specialized dataset comprising 100 synthetic speech files featuring 10 unique advocate identities. Using the Speech Llama Omni model, we simulate five distinct advocate pairs engaged in courtroom arguments. We define specific vocal characteristics for each advocate and present a speaker identification challenge to evaluate the ability of modern systems to map audio files to their respective synthetic origins.
  Dataset is available at this link-https: //github.com/naturenurtureelite/ADVOSYNTH-500.

</details>


### [90] [Boundary-Aware NL2SQL: Integrating Reliability through Hybrid Reward and Data Synthesis](https://arxiv.org/abs/2601.10318)
*Songsong Tian,Kongsheng Zhuo,Zhendong Wang,Rong Shen,Shengtao Zhang,Yong Wu*

Main category: cs.CL

Score: 5/5 | Tags: NL2SQL, SQL Generation, Reliability, Boundary Cases, Abstention, Reinforcement Learning, Benchmark, Enterprise Applications

Recommendation: 强烈推荐这篇论文，因为它提出了一个创新的统一框架来解决NL2SQL系统中长期存在的可靠性问题。BAR-SQL不仅通过种子变异数据合成和基于知识的推理合成方法在技术上有显著创新，还构建了专门的基准测试Ent-SQL-Bench来系统评估边界情况处理能力。该方法在实验中表现出色，超越了包括Claude 4.5 Sonnet和GPT-5在内的领先专有模型，具有很高的实用价值。开源代码和基准测试的发布将进一步促进该领域的研究发展。

TL;DR: 在本文中，我们提出了BAR-SQL（边界感知可靠的NL2SQL），这是一个统一的训练框架，将可靠性和边界感知直接嵌入到生成过程中。我们引入了一种种子变异数据合成范式，构建了一个具有代表性的企业语料库，明确包含多步骤分析查询以及包含歧义和模式限制的边界情况。为确保可解释性，我们采用了基于知识的推理合成方法，生成明确锚定在模式元数据和业务规则上的思维链轨迹。模型通过两阶段过程进行训练：监督微调（SFT）后接通过组相对策略优化的强化学习。我们设计了一种任务条件混合奖励机制，同时优化SQL执行准确性（利用抽象语法树分析和密集结果匹配）和弃权响应中的语义精确性。为了评估可靠性和生成准确性，我们构建并发布了Ent-SQL-Bench，共同评估SQL精确度和在歧义及不可回答查询上的边界感知弃权能力。在该基准测试上的实验结果表明，BAR-SQL实现了91.48%的平均准确率，在SQL生成质量和边界感知弃权能力方面均优于包括Claude 4.5 Sonnet和GPT-5在内的领先专有模型。源代码和基准测试已匿名发布在：https://github.com/TianSongS/BAR-SQL。


<details>
  <summary>Details</summary>
Motivation: 当前的自然语言转SQL（NL2SQL）系统虽然在标准查询上表现良好，但在面对边界情况（如歧义查询、模式限制或不可回答的问题）时缺乏可靠性。现有的解决方案往往无法正确处理这些情况，可能导致生成错误SQL或给出不恰当的响应。本文旨在开发一个能够同时处理标准SQL生成和边界情况感知的可靠系统，确保模型在面对不确定或无法回答的查询时能够适当地弃权，从而提高实际企业应用中的可靠性。

Method: BAR-SQL采用统一训练框架，核心方法包括：1）种子变异数据合成范式：构建包含多步骤分析查询和边界情况的企业语料库；2）基于知识的推理合成：生成锚定在模式元数据和业务规则上的思维链轨迹以提高可解释性；3）两阶段训练：先进行监督微调（SFT），然后通过组相对策略优化进行强化学习；4）任务条件混合奖励机制：结合抽象语法树分析和密集结果匹配来优化SQL执行准确性，同时确保弃权响应的语义精确性；5）构建Ent-SQL-Bench基准：用于联合评估SQL精确度和边界感知弃权能力。

Result: BAR-SQL在Ent-SQL-Bench基准测试中达到了91.48%的平均准确率，在SQL生成质量和边界感知弃权能力方面均显著优于多个领先的专有模型，包括Claude 4.5 Sonnet和GPT-5。实验结果表明，该方法能够有效处理歧义和不可回答的查询，同时保持高精度的SQL生成能力。

Conclusion: BAR-SQL通过统一的训练框架成功地将可靠性和边界感知嵌入到NL2SQL生成过程中。该方法不仅在标准SQL生成任务上表现出色，还能在面对边界情况时做出适当的弃权响应。构建的Ent-SQL-Bench基准为未来NL2SQL系统的可靠性评估提供了有价值的工具。该工作为开发更可靠、更实用的企业级NL2SQL系统奠定了基础。

Abstract: In this paper, we present BAR-SQL (Boundary-Aware Reliable NL2SQL), a unified training framework that embeds reliability and boundary awareness directly into the generation process. We introduce a Seed Mutation data synthesis paradigm that constructs a representative enterprise corpus, explicitly encompassing multi-step analytical queries alongside boundary cases including ambiguity and schema limitations. To ensure interpretability, we employ Knowledge-Grounded Reasoning Synthesis, which produces Chain-of-Thought traces explicitly anchored in schema metadata and business rules. The model is trained through a two-stage process: Supervised Fine-Tuning (SFT) followed by Reinforcement Learning via Group Relative Policy Optimization. We design a Task-Conditioned Hybrid Reward mechanism that simultaneously optimizes SQL execution accuracy-leveraging Abstract Syntax Tree analysis and dense result matching-and semantic precision in abstention responses. To evaluate reliability alongside generation accuracy, we construct and release Ent-SQL-Bench, which jointly assesse SQL precision and boundary-aware abstention across ambiguous and unanswerable queries. Experimental results on this benchmark demonstrate that BAR-SQL achieves 91.48% average accuracy, outperforming leading proprietary models, including Claude 4.5 Sonnet and GPT-5, in both SQL generation quality and boundary-aware abstention capability. The source code and benchmark are available anonymously at: https://github.com/TianSongS/BAR-SQL.

</details>


### [91] [OctoBench: Benchmarking Scaffold-Aware Instruction Following in Repository-Grounded Agentic Coding](https://arxiv.org/abs/2601.10343)
*Deming Ding,Shichun Liu,Enhui Yang,Jiahang Lin,Ziying Chen,Shihan Dou,Honglin Guo,Weiyu Cheng,Pengyu Zhao,Chengjun Xiao,Qunhong Zeng,Qi Zhang,Xuanjing Huang,Qidi Xu,Tao Gui*

Main category: cs.CL

Score: 4/5 | Tags: LLM, Agent, Benchmark, Code Generation, Software Engineering, Evaluation, Constraints, Compliance

Recommendation: 推荐理由：该论文提出了一个重要的基准测试框架，解决了当前LLM智能体评估中任务解决能力与指令遵循能力混淆的问题。OctoBench设计严谨，包含大量环境和细粒度检查项，具有良好的可重复性和实用性。该研究揭示了LLM智能体在实际编码场景中遵循复杂约束的系统性挑战，为未来的智能体开发和评估提供了重要指导。虽然未涉及最新的前沿模型，但其方法论和研究洞察具有较高的参考价值。

TL;DR: 现代编码脚手架将大型语言模型转变为具备能力的软件智能体，但其遵循脚手架指定指令的能力仍未得到充分检验，特别是当约束条件具有异质性并在多次交互中持续存在时。为了填补这一空白，我们引入了OctoBench，这是一个用于评估基于仓库的智能体化编码中脚手架感知指令遵循能力的基准测试。OctoBench包括34个环境和217个任务，这些任务在三种脚手架类型下实例化，并配以7,098个客观检查项。为了将任务解决与规则遵循区分开来，我们提供了一个自动化的观察与评分工具包，可以捕获完整的执行轨迹并进行细粒度检查。对八个代表性模型的实验揭示了任务解决能力与脚手架感知合规性之间的系统性差距，强调了需要专门针对异质性指令遵循进行训练和评估。我们发布了这一基准测试以支持可重复的基准测试，并加速更具脚手架感知能力的编码智能体的开发。


<details>
  <summary>Details</summary>
Motivation: 随着LLM越来越多地被用作软件智能体，现代编码脚手架能够增强LLM的编码能力。然而，当前研究尚未充分评估这些智能体在遵循脚手架指定的异质性和持续性约束方面的能力。现有的评估方法往往混淆了任务解决能力和指令遵循能力，无法准确衡量智能体对复杂脚手架规则的遵循程度。因此，需要一个专门的基准测试来评估智能体在仓库环境中的脚手架感知指令遵循能力。

Method: 本研究提出了OctoBench基准测试系统，包括：1) 34个环境设置和217个任务，覆盖三种不同类型的脚手架结构；2) 7,098个客观检查项用于细粒度评估；3) 自动化观察与评分工具包，能够捕获完整的智能体执行轨迹并分离任务解决能力与规则遵循能力；4) 对八个代表性LLM模型进行了全面实验评估。该方法设计了专门的评估指标来区分任务完成度和脚手架合规性，确保能够准确测量智能体对异质性约束的遵循能力。

Result: 实验结果显示：1) 当前LLM智能体在任务解决能力与脚手架感知合规性之间存在系统性差距，即使是任务解决能力强的模型在遵循复杂脚手架约束方面也存在显著不足；2) 不同脚手架类型对智能体的指令遵循能力提出了不同挑战；3) 通过自动化的轨迹分析和细粒度检查，能够准确识别智能体在遵循异质性约束时的具体失败模式；4) 现有的训练和评估方法未能充分针对脚手架感知指令遵循进行优化。

Conclusion: 本研究得出结论：现有的LLM智能体在遵循脚手架指定的异质性和持续性约束方面存在系统性的能力不足。开发专门的脚手架感知指令遵循评估基准至关重要，这有助于推动更有效的训练方法和更符合实际应用需求的智能体编码系统。OctoBench的发布为未来研究提供了可重复的评估框架，并强调了需要开发专门针对异质性指令遵循能力进行优化的智能体。

Abstract: Modern coding scaffolds turn LLMs into capable software agents, but their ability to follow scaffold-specified instructions remains under-examined, especially when constraints are heterogeneous and persist across interactions. To fill this gap, we introduce OctoBench, which benchmarks scaffold-aware instruction following in repository-grounded agentic coding. OctoBench includes 34 environments and 217 tasks instantiated under three scaffold types, and is paired with 7,098 objective checklist items. To disentangle solving the task from following the rules, we provide an automated observation-and-scoring toolkit that captures full trajectories and performs fine-grained checks. Experiments on eight representative models reveal a systematic gap between task-solving and scaffold-aware compliance, underscoring the need for training and evaluation that explicitly targets heterogeneous instruction following. We release the benchmark to support reproducible benchmarking and to accelerate the development of more scaffold-aware coding agents.

</details>


### [92] [Training-Trajectory-Aware Token Selection](https://arxiv.org/abs/2601.10348)
*Zhanming Shen,Jiaqi Hu,Zeyu Qin,Hao Chen,Wentao Ye,Zenan Huang,Yihong Zhuang,Guoshan Lu,Junlin Zhou,Junbo Zhao*

Main category: cs.CL

Score: 5/5 | Tags: LLM, Distillation, Training, Optimization, Reasoning, NLP

Recommendation: 高度推荐这篇论文，因为它深入分析了前沿模型蒸馏中的瓶颈问题，提出了创新的T3S方法，在理论和实践上都取得了突破性进展。论文不仅揭示了传统蒸馏方法失败的根本机制，还提供了有效的解决方案，在多个人工智能基准测试中实现了显著的性能提升。该研究对于提升大型语言模型的推理能力和实际部署效率具有重要价值。

TL;DR: 高效蒸馏是将昂贵的推理能力转换为可部署效率的关键途径，但在前沿领域，当学生模型已经具备较强的推理能力时，简单的持续蒸馏往往只能获得有限的收益甚至性能下降。我们观察到一种特征性的训练现象：即使损失单调下降，所有性能指标都可能在几乎相同的瓶颈点急剧下降，然后逐渐恢复。我们进一步揭示了标记级别的机制：置信度会分化为稳步增加的模仿锚定标记（Imitation-Anchor Tokens），它们能够快速锚定优化过程；以及其他尚未学习的标记（yet-to-learn tokens），它们的置信度在瓶颈期之前被抑制。这两种标记不能共存的特征是持续蒸馏失败的根本原因。为此，我们提出了训练轨迹感知的标记选择（T3S），在标记级别重构训练目标，为尚未学习的标记清除优化路径。T3在自回归（AR）和判别性语言模型（dLLM）设置下均能获得一致的收益：仅使用数百个示例，Qwen3-8B在竞争性推理基准上超越了DeepSeek-R1，Qwen3-32B接近了Qwen3-235B，并且T3训练的LLaDA-2.0-Mini超越了其自回归基线，在所有16B规模的无思考模型中达到了最先进的性能。


<details>
  <summary>Details</summary>
Motivation: 当前，高效的推理蒸馏是提升模型推理能力和实际部署效率的关键手段。然而，当学生模型已具备较强的推理能力时，传统蒸馏方法往往难以进一步提升性能，甚至会导致性能下降。研究发现，在训练过程中，即使训练损失单调下降，所有性能指标都可能在同一瓶颈点显著下降后再缓慢恢复。这一现象揭示了传统蒸馏方法在前沿领域的局限性，亟需新的方法来解决持续蒸馏中的优化路径阻塞问题。

Method: 本文提出了训练轨迹感知的标记选择（T3S）方法。该方法通过分析训练动态，识别出两种不同类型的标记：模仿锚定标记（Imitation-Anchor Tokens）和尚未学习的标记（yet-to-learn tokens）。模仿锚定标记的置信度稳步增加并快速锚定优化过程，而尚未学习的标记的置信度在瓶颈期前被抑制。T3S的核心思想是在标记级别重构训练目标，为尚未学习的标记清除优化路径，使它们能够获得充分的训练机会。具体而言，T3S根据训练轨迹动态选择标记进行优化，避免模仿锚定标记主导训练过程，从而打破瓶颈，提升蒸馏效果。

Result: T3S在多种设置下均取得了显著的性能提升：1）在自回归（AR）设置下，仅使用数百个示例，Qwen3-8B在竞争性推理基准上超越了DeepSeek-R1。2）Qwen3-32B的性能接近了Qwen3-235B。3）在判别性语言模型（dLLM）设置下，T3训练的LLaDA-2.0-Mini超越了其自回归基线，在所有16B规模的无思考模型中达到了最先进的性能。这些结果表明T3S能够有效解决持续蒸馏中的瓶颈问题，显著提升学生模型的推理能力。

Conclusion: 本文揭示了持续蒸馏失败的根本原因在于训练过程中标记级别的置信度分化和优化路径阻塞。通过提出训练轨迹感知的标记选择（T3S）方法，成功清除了尚未学习标记的优化障碍，在多个前沿模型和基准上实现了显著的性能提升。该方法为高效推理蒸馏提供了一种新的优化思路，特别是对于已具备较强推理能力的学生模型，T3S能够帮助其突破性能瓶颈，进一步提升蒸馏效果。

Abstract: Efficient distillation is a key pathway for converting expensive reasoning capability into deployable efficiency, yet in the frontier regime where the student already has strong reasoning ability, naive continual distillation often yields limited gains or even degradation. We observe a characteristic training phenomenon: even as loss decreases monotonically, all performance metrics can drop sharply at almost the same bottleneck, before gradually recovering. We further uncover a token-level mechanism: confidence bifurcates into steadily increasing Imitation-Anchor Tokens that quickly anchor optimization and other yet-to-learn tokens whose confidence is suppressed until after the bottleneck. And the characteristic that these two types of tokens cannot coexist is the root cause of the failure in continual distillation. To this end, we propose Training-Trajectory-Aware Token Selection (T3S) to reconstruct the training objective at the token level, clearing the optimization path for yet-to-learn tokens. T3 yields consistent gains in both AR and dLLM settings: with only hundreds of examples, Qwen3-8B surpasses DeepSeek-R1 on competitive reasoning benchmarks, Qwen3-32B approaches Qwen3-235B, and T3-trained LLaDA-2.0-Mini exceeds its AR baseline, achieving state-of-the-art performance among all of 16B-scale no-think models.

</details>


### [93] [The Assistant Axis: Situating and Stabilizing the Default Persona of Language Models](https://arxiv.org/abs/2601.10387)
*Christina Lu,Jack Gallagher,Jonathan Michala,Kyle Fish,Jack Lindsey*

Main category: cs.CL

Score: 5/5 | Tags: LLM, Model Behavior, Steering, Persona, Safety, Activation, Control, Jailbreak

Recommendation: 这篇论文具有很高的推荐价值，原因如下：1）研究问题新颖且重要，聚焦于LLM角色空间的结构和控制，这是一个前沿且关键的安全研究方向；2）研究方法严谨，从多个角度（激活方向提取、引导实验、预测模型等）深入探索了助手轴的概念；3）发现具有实际应用价值，不仅揭示了助手轴的存在和作用，还提出了稳定模型行为的具体策略；4）对LLM训练和部署的安全问题有直接指导意义，特别是对于防止角色漂移和对抗攻击。

TL;DR: 大型语言模型可以代表各种角色身份，但通常在训练后默认表现出经过培养的"助手"身份。我们通过提取与不同角色原型对应的激活方向来研究模型角色空间的结构。在多个不同模型中，我们发现该角色空间的主要成分是一个"助手轴"，它捕捉了模型在其默认助手模式下运行的程度。向助手方向引导会增强有益和安全的行​​为；远离该方向则会增加模型将自己识别为其他实体的倾向。此外，用更极端的值远离该方向通常会诱导出神秘、戏剧化的说话风格。我们发现这个轴也存在于预训练模型中，其中它主要促进如顾问和教练等有帮助的人类原型，并抑制精神层面的角色。测量沿着助手轴的偏离可以预测"角色漂移"现象，即模型表现出与其典型角色特征不符的有害或怪异行为。我们发现角色漂移通常由要求对模型过程进行元反思或涉及情感脆弱用户的对话驱动。我们表明，将激活限制在助手轴的固定区域内可以稳定这些场景下——以及在面对基于角色的对抗性越狱攻击时——的模型行为。我们的结果表明，训练后引导模型朝向角色空间的特定区域，但只是松散地将它们系在该区域，这促使我们研究更深入地将模型锚定到连贯角色的训练和引导策略。


<details>
  <summary>Details</summary>
Motivation: 大型语言模型通常被训练成具有"助手"身份的模型，但它们实际上能够代表各种角色身份。研究者们希望了解模型角色空间的结构，特别是是否存在一个关键的"助手轴"维度，以及该维度如何影响模型的行为表现。这有助于理解模型角色身份的可控性、稳定性，以及如何防止模型偏离其预期角色。

Method: 本研究通过提取与不同角色原型对应的激活方向来探索模型角色空间的结构。研究者们识别出了一个关键的"助手轴"，然后通过引导技术（steering techniques）在助手轴上进行正向和负向的操作，观察模型行为的变化。研究还测量了助手轴上的偏离程度，并将其与"角色漂移"现象相关联。最后，研究者们通过将激活限制在助手轴的固定区域内来测试稳定模型行为的策略。

Result: 研究发现在多个不同模型中，角色空间的主要成分都是一个"助手轴"，该轴捕捉了模型在其默认助手模式下运行的程度。向助手方向引导会增强有益和安全的行​​为，而远离该方向则增加模型将自己识别为其他实体的倾向，且极端负向引导会产生神秘、戏剧化的说话风格。助手轴也存在于预训练模型中，促进有帮助的人类原型并抑制精神层面的角色。测量助手轴上的偏离可以有效预测"角色漂移"现象，这种现象常由要求元反思或涉及情感脆弱用户的对话触发。将激活限制在助手轴的固定区域内可以有效稳定模型行为，防止角色漂移，并抵御基于角色的对抗性攻击。

Conclusion: 研究结果表明，后训练过程引导模型朝向角色空间的特定区域，但只是松散地将它们系在该区域。这凸显了现有方法的局限性，并促使研究者开发更有效的训练和引导策略，以更深入地将模型锚定到连贯的角色身份中，提高模型的稳定性、安全性和可控性。

Abstract: Large language models can represent a variety of personas but typically default to a helpful Assistant identity cultivated during post-training. We investigate the structure of the space of model personas by extracting activation directions corresponding to diverse character archetypes. Across several different models, we find that the leading component of this persona space is an "Assistant Axis," which captures the extent to which a model is operating in its default Assistant mode. Steering towards the Assistant direction reinforces helpful and harmless behavior; steering away increases the model's tendency to identify as other entities. Moreover, steering away with more extreme values often induces a mystical, theatrical speaking style. We find this axis is also present in pre-trained models, where it primarily promotes helpful human archetypes like consultants and coaches and inhibits spiritual ones. Measuring deviations along the Assistant Axis predicts "persona drift," a phenomenon where models slip into exhibiting harmful or bizarre behaviors that are uncharacteristic of their typical persona. We find that persona drift is often driven by conversations demanding meta-reflection on the model's processes or featuring emotionally vulnerable users. We show that restricting activations to a fixed region along the Assistant Axis can stabilize model behavior in these scenarios -- and also in the face of adversarial persona-based jailbreaks. Our results suggest that post-training steers models toward a particular region of persona space but only loosely tethers them to it, motivating work on training and steering strategies that more deeply anchor models to a coherent persona.

</details>


### [94] [TF3-RO-50M: Training Compact Romanian Language Models from Scratch on Synthetic Moral Microfiction](https://arxiv.org/abs/2601.10410)
*Mihai Dan Nadas,Laura Diosan,Andreea Tomescu,Andrei Piscoran*

Main category: cs.CL

Score: 4/5 | Tags: 低资源语言处理, 罗马尼亚语, 合成数据生成, 语言建模, 模型压缩, 知识蒸馏, 分词器, 端到端框架

Recommendation: 该论文推荐原因为：1) 填补了罗马尼亚语等低资源语言端到端语言建模流程的空白；2) 提供了完整的系统化框架，涵盖从分词器到合成数据生成的各个关键环节；3) 针对形态丰富语言的分词膨胀问题提出了有效解决方案；4) 集成了全面的评估方法，保证了结果的可信度；5) 对低资源语言处理领域具有重要参考价值和实用性。扣分原因是未提供具体的性能指标对比。

TL;DR: 近期合成数据生成进展表明，当底层语料库结构受控且语言连贯时，紧凑语言模型可以有效地训练。然而，对于形态丰富且计算资源不足的语言（如罗马尼亚语），目前仍缺乏公开记录、端到端的流程，将分词器设计、预处理、预训练、压缩、评估和大规模合成数据生成统一在可复现的框架中。基于TF1（三百万故事英语寓言数据集）和TF2（通过高质量罗马尼亚语翻译扩展TF1），我们引入TF3-RO，这是一个罗马尼亚语中心化的语言建模流程，涵盖分词器训练、从头开始的模型开发和罗马尼亚语原生数据集生成。TF3-RO从语言知识丰富的语料库构建罗马尼亚语特定的BPE和Unigram分词器，以缓解罗马尼亚语形态学引发的分词膨胀。使用长序列打包训练，我们从头开始预训练一个51.65M参数的LLaMA风格Transformer。随后通过量化、结构化剪枝和基于logit的知识蒸馏优化模型，产生一个26.45M参数的紧凑学生模型，具有绑定嵌入和强大的部署特性。使用这个蒸馏模型，TF3-RO通过受控组合提示框架生成三百万个罗马尼亚语原生合成寓言。在所有阶段，该流程集成了全面的评估套件，结合内在指标、罗马尼亚语一致性探测、实体连贯性、基于规则的语法检查和基于LLM的评估。TF3-RO为训练紧凑罗马尼亚语语言模型和生成大规模合成叙事语料库提供了一个可复现且语言基础扎实的框架。


<details>
  <summary>Details</summary>
Motivation: 针对形态丰富且计算资源不足的语言（如罗马尼亚语），缺乏公开、完整的端到端语言建模流程，涵盖从分词器设计到合成数据生成的各个阶段。当前方法通常分散且不可复现，无法为罗马尼亚语等语言提供统一、系统化的解决方案。

Method: 该方法包括：1) 从语言知识丰富的语料库构建罗马尼亚语特定的BPE和Unigram分词器，以缓解形态学引起的分词膨胀；2) 使用长序列打包训练从头预训练51.65M参数的LLaMA风格Transformer；3) 通过量化、结构化剪枝和logit知识蒸馏优化模型，生成26.45M参数的紧凑学生模型；4) 使用蒸馏模型通过受控组合提示框架生成三百万罗马尼亚语原生合成寓言；5) 集成全面的评估套件，包括内在指标、语言一致性探测、实体连贯性、语法检查和LLM评估。

Result: 成功开发了TF3-RO流程，实现了：1) 罗马尼亚语特定分词器的构建，有效缓解了分词膨胀问题；2) 从头训练了51.65M参数的LLaMA风格Transformer模型；3) 通过压缩技术得到了26.45M参数的紧凑学生模型，具有良好部署特性；4) 生成了三百万个罗马尼亚语原生合成寓言；5) 建立了综合评估框架验证了各个阶段的效果。

Conclusion: TF3-RO提供了一个可复现、语言基础扎实的端到端框架，专门针对罗马尼亚语等形态丰富、资源不足的语言。该框架成功统一了从分词器设计到合成数据生成的全流程，为训练紧凑语言模型和大规模合成语料库生成提供了系统化解决方案，对低资源语言处理具有重要价值。

Abstract: Recent advances in synthetic data generation have shown that compact language models can be trained effectively when the underlying corpus is structurally controlled and linguistically coherent. However, for morphologically rich and computationally under-resourced languages such as Romanian, there is still no openly documented, end-to-end pipeline that unifies tokenizer design, preprocessing, pretraining, compression, evaluation, and large-scale synthetic data generation in a reproducible framework. Building on TF1, a three-million-story English fable dataset, and TF2, which extends TF1 through high-quality Romanian translations, we introduce TF3-RO, a Romanian-centric language modeling pipeline spanning tokenizer training, from-scratch model development, and Romanian-native dataset generation. TF3-RO constructs Romanian-specific BPE and Unigram tokenizers from a linguistically informed corpus to mitigate token inflation induced by Romanian morphology. Using long-sequence packed training, we pretrain a 51.65M-parameter LLaMA-style Transformer entirely from scratch. The model is subsequently optimized through quantization, structured pruning, and logit-based knowledge distillation, yielding a compact 26.45M-parameter student model with tied embeddings and strong deployment characteristics. Using this distilled model, TF3-RO generates three million Romanian-native synthetic fables via a controlled combinatorial prompting framework. Across all stages, the pipeline integrates a comprehensive evaluation suite combining intrinsic metrics, Romanian agreement probes, entity coherence, rule-based grammar checking, and LLM-based assessment. TF3-RO provides a reproducible and linguistically grounded framework for training compact Romanian language models and producing large-scale synthetic narrative corpora.

</details>


### [95] [Are Language Models Models?](https://arxiv.org/abs/2601.10421)
*Philip Resnik*

Main category: cs.CL

Score: 4/5 | Tags: Cognitive Science, LLM, Philosophy of AI, Computational Linguistics, Critical Analysis, Marr's Levels

Recommendation: 这篇论文值得推荐，因为它提供了对语言模型作为认知模型的系统性批判分析。使用Marr的经典分析框架确保了分析的严谨性，对当前过度炒作语言模型的现象进行了必要的中和，为理性评估语言模型在认知科学中的作用提供了重要视角。

TL;DR: Futrell和Mahowald声称语言模型"作为模型系统"，但在Marr的三个层次上的评估表明，这一主张在实现层面显然不正确，在算法-表示层面动机不足，在计算理论层面存在问题。语言模型是作为工具的优秀候选；将它们称为认知模型夸大了其作用，并助长了不必要的大语言模型炒作。


<details>
  <summary>Details</summary>
Motivation: 本文的动机是对语言模型作为认知模型系统的主张进行批判性评估。作者旨在通过Marr的三个分析层次（实现、算法-表示、计算理论）系统性地检验语言模型能否真正作为模型系统使用，并回应当前关于语言模型能力和地位的过度炒作。

Method: 作者采用Marr的分析框架，从三个层次系统地评估语言模型作为模型系统的合理性：1) 实现层面：考察语言模型与实际生物实现之间的对应关系；2) 算法-表示层面：分析语言模型的算法结构和表示形式是否与认知系统相关；3) 计算理论层面：探讨语言模型所解决的计算问题与认知科学理论的相关性。

Result: 分析结果显示：在实现层面，语言模型与生物实现之间几乎没有对应关系，主张"明显不正确"；在算法-表示层面，将语言模型作为认知模型的动机"不足"；在计算理论层面，语言模型作为认知模型存在"问题"。整体上，语言模型更适合作为工具而非认知模型。

Conclusion: 语言模型不应被过度吹捧为认知模型系统。虽然它们是有用的工具，但在Marr的三个分析层次上都无法充分支持其作为认知模型的主张。将语言模型称为认知模型不仅夸大了它们的科学价值，还可能助长不必要的炒作。

Abstract: Futrell and Mahowald claim LMs "serve as model systems", but an assessment at each of Marr's three levels suggests the claim is clearly not true at the implementation level, poorly motivated at the algorithmic-representational level, and problematic at the computational theory level. LMs are good candidates as tools; calling them cognitive models overstates the case and unnecessarily feeds LLM hype.

</details>


### [96] [SurgGoal: Rethinking Surgical Planning Evaluation via Goal-Satisfiability](https://arxiv.org/abs/2601.10455)
*Ruochen Li,Kun Yuan,Yufei Xia,Yue Zhou,Qingyu Lu,Weihang Li,Youxiang Zhu,Nassir Navab*

Main category: cs.CL

Score: 4/5 | Tags: VLMs, Video-LLM, Medical AI, Surgical Planning, Evaluation Metrics, Rule-based Assessment, Vision-Language Models, Healthcare AI

Recommendation: 本文被推荐的原因包括：1）针对安全关键的医疗应用领域提出了创新的评估方法；2）揭示了传统序列相似性指标在复杂规划任务评估中的系统性缺陷；3）提供了实用的基于规则的元评估框架；4）对结构化知识和语义指导的相对有效性进行了有价值的分析；5）对医疗AI等安全敏感领域具有重要的实际意义。唯一的不足是研究可能过于专注于手术规划这一特定领域。

TL;DR: 手术规划整合了视觉感知、长时程推理和程序性知识，但目前尚不清楚现有的评估协议是否能可靠地评估视觉语言模型（VLMs）在安全关键环境中的表现。基于目标导向的手术规划视角，我们通过阶段目标可满足性来定义规划正确性，其中规划的有效性由专家定义的手术规则决定。基于此定义，我们引入了一个多中心元评估基准，包含有效的程序变化和包含顺序与内容错误的无效规划。使用该基准，我们发现序列相似性指标系统性地误判规划质量，惩罚有效规划同时未能识别无效规划。因此，我们采用基于规则的目标可满足性指标作为高精度元评估参考，评估视频LLMs在渐进约束设置下的表现，揭示了由于感知错误和约束不足推理导致的失效。结构化知识一致性地提高性能，而语义指导本身不可靠，只有在与结构化约束结合时才在更大模型中产生益处。


<details>
  <summary>Details</summary>
Motivation: 本文的动机源于手术规划作为安全关键领域的重要性，以及现有评估方法在评估视觉语言模型规划能力方面的不足。作者关注到目前缺乏可靠的方法来评估VLMs在手术规划等复杂、安全敏感场景中的表现，特别是如何准确区分有效和无效的规划决策。

Method: 研究方法包括：1）提出基于阶段目标可满足性的规划正确性定义；2）开发多中心元评估基准，包含有效程序变化和包含顺序与内容错误的无效规划；3）比较序列相似性指标与基于规则的目标可满足性指标；4）评估视频LLMs在渐进约束设置下的表现；5）分析结构化知识与语义指导对模型性能的影响。

Result: 研究结果显示：1）序列相似性指标系统性地误判规划质量，既惩罚有效规划又未能识别无效规划；2）基于规则的目标可满足性指标在元评估中表现更可靠；3）在渐进约束设置下，视频LLMs因感知错误和约束不足推理而失效；4）结构化知识一致性地提高模型性能；5）语义指导单独使用时不可靠，只有与结构化约束结合时才能在更大模型中产生益处。

Conclusion: 本文得出结论：手术规划评估需要超越序列相似性的更精细方法。基于规则的目标可满足性评估框架为安全关键领域的视觉语言模型提供了更可靠的元评估参考。结构化知识对提升规划性能至关重要，而语义指导需要与结构化约束结合才能有效发挥作用。这对医疗AI等安全敏感应用的发展具有重要意义。

Abstract: Surgical planning integrates visual perception, long-horizon reasoning, and procedural knowledge, yet it remains unclear whether current evaluation protocols reliably assess vision-language models (VLMs) in safety-critical settings. Motivated by a goal-oriented view of surgical planning, we define planning correctness via phase-goal satisfiability, where plan validity is determined by expert-defined surgical rules. Based on this definition, we introduce a multicentric meta-evaluation benchmark with valid procedural variations and invalid plans containing order and content errors. Using this benchmark, we show that sequence similarity metrics systematically misjudge planning quality, penalizing valid plans while failing to identify invalid ones. We therefore adopt a rule-based goal-satisfiability metric as a high-precision meta-evaluation reference to assess Video-LLMs under progressively constrained settings, revealing failures due to perception errors and under-constrained reasoning. Structural knowledge consistently improves performance, whereas semantic guidance alone is unreliable and benefits larger models only when combined with structural constraints.

</details>


### [97] [AEQ-Bench: Measuring Empathy of Omni-Modal Large Models](https://arxiv.org/abs/2601.10513)
*Xuan Luo,Lewei Yao,Libo Zhao,Lanqing Hong,Kai Chen,Dehua Tao,Daxin Tan,Ruifeng Xu,Jing Li*

Main category: cs.CL

Score: 4/5 | Tags: LLM, Multi-modal, Audio, Empathy, Evaluation, Benchmark

Recommendation: 本文推荐度较高，主要原因为：1）针对当前研究空白，提出了专门评估多模态大模型共情能力的新颖基准；2）研究问题具有实际意义，共情能力是智能体人机交互的核心要素；3）方法设计全面，考虑了语境特异性和语音语调等多个维度；4）结果具有启发性，揭示了音频输出能力对共情表现的重要性以及当前模型的局限性。但分数为4而非5，因为研究仍处于基准建立阶段，实际应用和解决方案的探讨相对有限。

TL;DR: 尽管全模态大模型的自动评估至关重要，但评估其共情能力仍然是一个重大挑战，因为共情具有内在的情感属性。为研究这一挑战，我们提出了AEQ-Bench（音频共情商数基准），这是一个系统性评估OLMs两个核心共情能力的新基准：(i)通过理解多模态输入（音频+文本）中的情感线索生成共情性回应，(ii)在不依赖文本转录的情况下评判音频回应的共情程度。与现有基准相比，AEQ-Bench引入了两个具有不同语境特异性和语音语调的新颖设置。通过语言和副语言指标的全面评估发现：(1)具备音频输出能力的OLMs通常优于仅具备文本输出的模型，(2)虽然OLMs在粗粒度质量评估上与人类判断一致，但在评估细粒度副语言表达性方面仍然不可靠。


<details>
  <summary>Details</summary>
Motivation: 全模态大模型的自动评估至关重要，但评估其共情能力面临重大挑战。共情涉及内在的情感属性，传统基于文本的评估方法难以全面衡量模型的情感理解和表达能力。现有评估基准主要关注文本模态，忽视了音频这一重要的情感表达渠道，无法有效评估模型在多模态环境下的共情能力。

Method: 本文提出了AEQ-Bench基准测试框架，该框架系统性地评估OLMs的两个核心共情能力：1）通过理解多模态输入（音频+文本）中的情感线索生成共情性回应；2）在不依赖文本转录的情况下评判音频回应的共情程度。该方法引入了两个新颖设置：不同的语境特异性和语音语调变化。评估采用综合的语言和副语言指标，对比了具备音频输出能力的OLMs与仅具备文本输出的模型性能。

Result: 评估结果显示两个重要发现：1）具备音频输出能力的OLMs在共情表现上普遍优于仅具备文本输出的模型；2）OLMs在粗粒度的质量评估方面与人类判断较为一致，但在评估细粒度的副语言表达性（如语调、语速、情感细微变化）方面表现不可靠，无法达到人类评估的准确性。

Conclusion: AEQ-Bench为评估全模态大模型的共情能力提供了一个有效的多模态评估框架。研究表明音频输出能力对提升模型共情表现具有重要价值，同时揭示了当前OLMs在评估精细副语言特征方面的局限性。该研究为未来开发更全面、更准确的多模态共情评估方法奠定了基础。

Abstract: While the automatic evaluation of omni-modal large models (OLMs) is essential, assessing empathy remains a significant challenge due to its inherent affectivity. To investigate this challenge, we introduce AEQ-Bench (Audio Empathy Quotient Benchmark), a novel benchmark to systematically assess two core empathetic capabilities of OLMs: (i) generating empathetic responses by comprehending affective cues from multi-modal inputs (audio + text), and (ii) judging the empathy of audio responses without relying on text transcription. Compared to existing benchmarks, AEQ-Bench incorporates two novel settings that vary in context specificity and speech tone. Comprehensive assessment across linguistic and paralinguistic metrics reveals that (1) OLMs trained with audio output capabilities generally outperformed models with text-only outputs, and (2) while OLMs align with human judgments for coarse-grained quality assessment, they remain unreliable for evaluating fine-grained paralinguistic expressiveness.

</details>


### [98] [PERM: Psychology-grounded Empathetic Reward Modeling for Large Language Models](https://arxiv.org/abs/2601.10532)
*Chengbing Wang,Wuqiang Zheng,Yang Zhang,Fengbin Zhu,Junyi Cheng,Yi Xie,Wenjie Wang,Fuli Feng*

Main category: cs.CL

Score: 4/5 | Tags: LLM, Reinforcement Learning, Empathy, Psychology, Human-Computer Interaction, NLP, Emotional Intelligence

Recommendation: 这篇论文值得推荐，因为它从心理学理论出发解决LLM同理心的实际问题，方法创新且实用，实验结果在指标和用户体验上均有显著提升。该方法结合了多视角评估，符合情感支持的双向互动本质，开源资源的提供有利于社区进一步研究。

TL;DR: 大型语言模型越来越多地部署在人类中心的应用中，但它们往往无法提供实质性的情感支持。尽管强化学习已被用于增强LLM的同理心，但现有的奖励模型通常从单一视角评估同理心，忽略了同理心循环理论所定义的共情者与寻求者之间双向互动的本质。为解决这一局限，我们提出了基于心理学的同理心奖励建模方法。PERM通过双向分解来操作同理心评估：1）支持者视角，评估内部共鸣和沟通表达；2）寻求者视角，评估情感接收。此外，它还加入了旁观者视角来监控整体互动质量。在一个广泛使用的情商基准测试和一个工业日常对话数据集上的大量实验表明，PERM比最先进的基线方法性能提升超过10%。此外，一项盲测用户研究显示70%的用户偏好我们的方法，突显了其在生成更具同理心回应方面的有效性。


<details>
  <summary>Details</summary>
Motivation: LLM在人类中心应用中的部署日益增多，但它们在提供实质性情感支持方面仍然不足。现有强化学习方法中的奖励模型通常从单一视角（如支持者或寻求者）评估同理心，忽视了同理心循环理论强调的双向互动本质。这导致LLM生成的回应可能缺乏真正的共情效果，无法满足实际情感支持的需求。

Method: PERM方法提出了一种基于心理学原理的同理心奖励建模框架。该方法将同理心评估分解为三个视角：1）支持者视角：评估模型回应的内部共鸣（理解对方情感状态）和沟通表达（有效传达共情）；2）寻求者视角：评估情感支持寻求者接收到的情感认可和理解；3）旁观者视角：监控整体互动质量。这种多维评估机制被集成到强化学习奖励模型中，以指导LLM生成更具同理心的回应。

Result: 在广泛使用的情商基准测试和工业日常对话数据集上的实验表明，PERM方法在同理心评估指标上优于现有最先进的基线方法超过10%。盲测用户研究中，70%的用户更偏好PERM方法生成的回应，显著验证了该方法在生成更具同理心回应方面的有效性。

Conclusion: PERM方法通过结合同理心循环理论和多视角评估机制，有效提升了LLM在情感支持任务中的同理心表现。该方法不仅在指标上优于现有方法，而且在实际用户体验中也获得了显著偏好，为LLM在情感智能应用中的发展提供了有价值的框架。开源代码、数据集和模型的发布有助于该领域的进一步研究。

Abstract: Large Language Models (LLMs) are increasingly deployed in human-centric applications, yet they often fail to provide substantive emotional support. While Reinforcement Learning (RL) has been utilized to enhance empathy of LLMs, existing reward models typically evaluate empathy from a single perspective, overlooking the inherently bidirectional interaction nature of empathy between the supporter and seeker as defined by Empathy Cycle theory. To address this limitation, we propose Psychology-grounded Empathetic Reward Modeling (PERM). PERM operationalizes empathy evaluation through a bidirectional decomposition: 1) Supporter perspective, assessing internal resonation and communicative expression; 2) Seeker perspective, evaluating emotional reception. Additionally, it incorporates a bystander perspective to monitor overall interaction quality. Extensive experiments on a widely-used emotional intelligence benchmark and an industrial daily conversation dataset demonstrate that PERM outperforms state-of-the-art baselines by over 10\%. Furthermore, a blinded user study reveals a 70\% preference for our approach, highlighting its efficacy in generating more empathetic responses. Our code, dataset, and models are available at https://github.com/ZhengWwwq/PERM.

</details>


### [99] [Representation-Aware Unlearning via Activation Signatures: From Suppression to Knowledge-Signature Erasure](https://arxiv.org/abs/2601.10566)
*Syed Naveed Mahmood,Md. Rezaur Rahman Bhuiyan,Tasfia Zaman,Jareen Tasneem Khondaker,Md. Sameer Sakib,Nazia Tasnim,Farig Sadeque*

Main category: cs.CL

Score: 5/5 | Tags: LLM, Knowledge Erasure, Model Safety, GDPR Compliance, Unlearning, Model Architecture, Representation Learning, Parameter Efficiency

Recommendation: 这篇论文高度推荐，原因如下：1）解决了LLM领域的关键实际问题（GDPR合规和模型安全）；2）提出了创新性的表示感知方法，突破性地解决了知识擦除与行为抑制混淆的问题；3）具有严谨的评估框架（双指标协议），能够系统性地诊断机制级遗忘行为；4）实验充分，覆盖了不同模型家族和规模；5）取得了显著的实际效果（接近Oracle的擦除效果同时保持实用性）。该研究对LLM安全性领域有重要贡献。

TL;DR: 大规模语言模型的选择性知识擦除对于GDPR合规性和模型安全至关重要，然而当前的遗忘方法将行为抑制与真正的知识移除混为一谈，使得潜在能力在表面拒绝之下仍然存在。在这项工作中，我们通过引入知识免疫框架（KIF）来解决这一挑战，这是一个表示感知的架构，通过针对内部激活签名而非表面输出来区分真正的擦除与混淆。我们的方法结合了针对主题特定表示的动态抑制和参数高效的适配，实现了无需完整模型重新训练的持久遗忘。KIF实现了接近Oracle的擦除效果（FQ≈0.99 vs. 1.00），同时保持了Oracle水平的实用性（MU=0.62），有效地打破了所有先前工作都受到限制的稳定性-擦除权衡。我们在3B到14B参数的范围内评估了标准基础模型（Llama和Mistral）以及推理优先模型（Qwen和DeepSeek）。我们的观察表明，标准模型表现出规模无关的真实擦除（实用性漂移<3%），而推理优先模型则揭示了根本的架构差异。我们全面的双指标评估协议，结合表面泄漏与潜在追踪持续性，将混淆与擦除的区别操作化，并实现了首个跨模型家族和规模的机制级遗忘行为系统性诊断。


<details>
  <summary>Details</summary>
Motivation: 当前LLM知识遗忘方法存在根本性缺陷——它们只能实现表面行为抑制（让模型拒绝回答），而非真正的知识移除。这意味着潜在的知识表示仍然存在于模型内部，可能被恶意利用。这种混淆行为抑制与真实知识擦除的问题阻碍了GDPR合规性和模型安全的实现。需要一种能够区分并实现真正知识移除的新方法。

Method: 本文提出了知识免疫框架（KIF），这是一种表示感知的架构。KIF采用以下核心技术：1）基于内部激活签名而非表面输出的擦除机制，直接针对知识在模型表示空间中的特定模式；2）动态抑制主题特定的表示，在推理过程中实时干预；3）参数高效的适配策略，无需完全重新训练整个模型。该方法通过追踪和操作模型内部激活模式来实现真正知识擦除。

Result: KIF在多个维度取得显著成果：1）擦除效果接近Oracle水平（FQ≈0.99，Oracle为1.00）；2）实用性保持Oracle级别（MU=0.62）；3）打破了稳定性-擦除权衡，这是先前工作的主要限制；4）在不同规模模型（3B-14B）上验证了有效性；5）揭示了标准模型与推理优先模型的根本差异：标准模型表现出规模无关的真实擦除（实用性漂移<3%），而推理优先模型显示出架构层面的不同行为。

Conclusion: KIF框架成功区分并实现了真正的知识擦除，而不仅仅是行为抑制。通过针对内部激活表示的方法，它能够在不损害模型整体实用性的前提下，实现持久且高效的知识移除。研究还揭示了不同模型架构在遗忘机制上的根本差异，为理解LLM内部知识表示和操作提供了新视角。这项工作为满足GDPR合规性和增强模型安全性提供了有效的技术途径。

Abstract: Selective knowledge erasure from LLMs is critical for GDPR compliance and model safety, yet current unlearning methods conflate behavioral suppression with true knowledge removal, allowing latent capabilities to persist beneath surface-level refusals. In this work, we address this challenge by introducing Knowledge Immunization Framework (KIF), a representation-aware architecture that distinguishes genuine erasure from obfuscation by targeting internal activation signatures rather than surface outputs. Our approach combines dynamic suppression of subject-specific representations with parameter-efficient adaptation, enabling durable unlearning without full model retraining. KIF achieves near-oracle erasure (FQ approx 0.99 vs. 1.00) while preserving utility at oracle levels (MU = 0.62), effectively breaking the stability-erasure tradeoff that has constrained all prior work. We evaluate both standard foundation models (Llama and Mistral) and reasoning-prior models (Qwen and DeepSeek) across 3B to 14B parameters. Our observation shows that standard models exhibit scale-independent true erasure (<3% utility drift), while reasoning-prior models reveal fundamental architectural divergence. Our comprehensive dual-metric evaluation protocol, combining surface-level leakage with latent trace persistence, operationalizes the obfuscation - erasure distinction and enables the first systematic diagnosis of mechanism-level forgetting behavior across model families and scales.

</details>


### [100] [Form and Meaning in Intrinsic Multilingual Evaluations](https://arxiv.org/abs/2601.10580)
*Wessel Poelman,Miryam de Lhoneux*

Main category: cs.CL

Score: 4/5 | Tags: NLP, Multilingual, Evaluation Metrics, Conditional Language Models, Perplexity, Information Theory

Recommendation: 这篇论文推荐理由充分：它针对多语言NLP评估中的一个重要但常被忽视的问题进行了深入分析，揭示了困惑度等内在指标在多语言环境中的局限性。研究具有理论深度，实验设计系统，对实际评估实践有重要指导意义。唯一扣分点是可能缺乏对替代解决方案的具体建议。

TL;DR: 条件语言模型的内在评估指标，如困惑度或每字符比特数，在单语和多语言环境中都被广泛使用。这些指标在单语设置中相当直接，但在多语言设置中基于一些假设。其中一个假设是，比较条件语言模型在平行句子上的困惑度可以反映其质量，因为信息内容（这里理解为语义含义）是相同的。然而，这些指标本质上是在信息论意义上衡量信息内容。我们明确提出了这个假设以及其他类似假设，并讨论其影响。我们在两个多平行语料库上使用六个指标进行了实验，包括单语和多语言模型。最终，我们发现当前指标并不具有普遍可比性。我们参考了形式与意义之争来解释这种现象。


<details>
  <summary>Details</summary>
Motivation: 本文旨在探讨在评估多语言条件语言模型时使用内在评估指标（如困惑度）的有效性和可比性问题。研究者们注意到，在多语言环境中使用这些指标时存在一些未经验证的假设，特别是关于信息内容可比的假设，需要对此进行批判性分析。

Method: 本研究在两个多平行语料库上进行了系统性实验，评估了六种不同的内在评估指标。实验涵盖了单语模型和多语言模型，并深入分析了比较条件语言模型在平行句子上表现的基本假设。研究还探讨了信息论中的信息内容概念与语义内容概念之间的差异。

Result: 研究发现当前用于多语言评估的内在指标（如困惑度）缺乏普遍可比性。实验结果表明，在多语言环境中比较这些指标时，基于"平行句子具有相同信息内容"的假设是不成立的。因为内在指标测量的是信息论意义上的信息内容，而非语义内容，这导致了指标比较的误导性。

Conclusion: 论文得出结论：当前在多语言环境中使用条件语言模型的内在评估指标时，需要重新审视其可比性假设。研究强调了形式（信息论信息内容）与意义（语义内容）之间的区别，建议未来工作应开发更适合多语言评估的指标，或者更明确地界定这些指标的使用边界。

Abstract: Intrinsic evaluation metrics for conditional language models, such as perplexity or bits-per-character, are widely used in both mono- and multilingual settings. These metrics are rather straightforward to use and compare in monolingual setups, but rest on a number of assumptions in multilingual setups. One such assumption is that comparing the perplexity of CLMs on parallel sentences is indicative of their quality since the information content (here understood as the semantic meaning) is the same. However, the metrics are inherently measuring information content in the information-theoretic sense. We make this and other such assumptions explicit and discuss their implications. We perform experiments with six metrics on two multi-parallel corpora both with mono- and multilingual models. Ultimately, we find that current metrics are not universally comparable. We look at the form-meaning debate to provide some explanation for this.

</details>


### [101] [Influential Training Data Retrieval for Explaining Verbalized Confidence of LLMs](https://arxiv.org/abs/2601.10645)
*Yuxi Xia,Loris Schoenegger,Benjamin Roth*

Main category: cs.CL

Score: 4/5 | Tags: LLM, Trustworthiness, Confidence Calibration, Training Data Analysis, Question Answering

Recommendation: 这篇论文推荐的主要原因是其创新性地提出了TracVC方法，系统性地分析了LLM置信度表达的来源，揭示了模型过度自信的本质问题。该研究在方法学上具有创新性，提出的"内容基础性"度量标准对于评估LLM可靠性具有重要意义。研究结果对改进LLM训练机制和提高模型可信度有实际应用价值。虽然方法应用范围相对具体（问答任务），但研究深度和洞察力值得高度认可。

TL;DR: 大型语言模型（LLM）可以通过在其输出中表达自信来增加用户的感知信任度。然而，先前的研究表明，LLM经常过度自信，使其陈述的置信度不可靠，因为它与事实准确性并不一致。为了更好地理解这种口头表达置信度的来源，我们引入了TracVC（追踪口头置信度），这是一种基于信息检索和影响估计的方法，可以将生成的置信度表达追溯到训练数据。我们在问答环境中评估了OLMo和Llama模型上的TracVC，提出了一种新的度量标准——内容基础性，用于衡量LLM将其置信度建立在与内容相关的训练示例（与问题和答案相关）上还是建立在对置信度口头表达的通用示例上。我们的分析显示，OLMo2-13B经常受到与查询词汇上不相关的置信度相关数据的影响，这表明它可能模仿确定性的表面语言表达，而不是依赖于真正的内容基础。这些发现指出了当前训练机制的根本局限性：LLM可能学会了如何听起来自信，而没有学会何时自信是合理的。我们的分析为提高LLM表达更可靠置信度的可信度奠定了基础。


<details>
  <summary>Details</summary>
Motivation: 现有研究表明，大型语言模型（LLM）经常表现出过度自信，其口头表达的置信度与事实准确性并不一致，这使得用户对LLM输出的信任度受到影响。为了更好地理解LLM置信度表达的来源，并探究它们是基于内容相关知识还是仅仅模仿语言表达，需要进行系统性的追溯分析。

Method: 本文提出了TracVC方法，该方法结合了信息检索和影响估计技术，用于追踪LLM生成的置信度表达追溯到具体的训练数据。研究者使用该方法在OLMo和Llama模型的问答任务上进行评估，并提出了一种新的度量标准——内容基础性，用于衡量LLM的置信度是基于与内容相关的训练示例还是基于通用的置信度表达示例。

Result: 对OLMo2-13B的分析表明，该模型经常受到与查询词汇无关的置信度相关数据的影响，暗示模型可能只是在模仿确定性的表面语言表达，而不是基于真正的内容理解来建立置信度。研究揭示了当前训练机制的局限性：LLM学会了如何"听起来"自信，但没有学会何时自信是合理的。

Conclusion: 当前LLM的置信度表达存在根本性缺陷，模型往往通过模仿语言模式来表现自信，而非基于内容理解。TracVC方法为理解和改进LLM置信度表达的可信度提供了基础，这对提高LLM在现实应用中的可靠性至关重要。

Abstract: Large language models (LLMs) can increase users' perceived trust by verbalizing confidence in their outputs. However, prior work has shown that LLMs are often overconfident, making their stated confidence unreliable since it does not consistently align with factual accuracy. To better understand the sources of this verbalized confidence, we introduce TracVC (\textbf{Trac}ing \textbf{V}erbalized \textbf{C}onfidence), a method that builds on information retrieval and influence estimation to trace generated confidence expressions back to the training data. We evaluate TracVC on OLMo and Llama models in a question answering setting, proposing a new metric, content groundness, which measures the extent to which an LLM grounds its confidence in content-related training examples (relevant to the question and answer) versus in generic examples of confidence verbalization. Our analysis reveals that OLMo2-13B is frequently influenced by confidence-related data that is lexically unrelated to the query, suggesting that it may mimic superficial linguistic expressions of certainty rather than rely on genuine content grounding. These findings point to a fundamental limitation in current training regimes: LLMs may learn how to sound confident without learning when confidence is justified. Our analysis provides a foundation for improving LLMs' trustworthiness in expressing more reliable confidence.

</details>


### [102] [Detecting Winning Arguments with Large Language Models and Persuasion Strategies](https://arxiv.org/abs/2601.10660)
*Tiziano Labruna,Arkadiusz Modzelewski,Giorgio Satta,Giovanni Da San Martino*

Main category: cs.CL

Score: 4/5 | Tags: NLP, LLM, Argumentation, Persuasion, Text Analysis, Prompt Engineering, Dataset

Recommendation: 这篇论文值得推荐的理由在于：1）研究问题具有实际意义，对理解人类交流和论辩质量评估有重要价值；2）方法创新，提出了基于策略引导的推理框架，结合了大语言模型的能力；3）实验设计严谨，使用了多个数据集并进行主题分析；4）贡献明确，发布了标注数据集供后续研究使用；5）在提升模型可解释性方面有突出贡献。扣分点在于原文摘要信息量有限，未提供更多技术细节和定量结果。

TL;DR: 检测论辩文本中的说服力是一项具有挑战性的任务，对于理解人类交流具有重要意义。本研究探讨了说服策略——如声誉攻击、分心和操纵性措辞——在决定文本说服力方面的作用。我们在三个标注的论辩数据集上进行了实验：Winning Arguments（来自Change My View subreddit）、Anthropic/Persuasion和Persuasion for Good。我们的方法利用大语言模型，采用多策略说服评分方法，指导对六种说服策略进行推理。结果表明，基于策略的推理提高了说服力的预测能力。为了更好地理解内容的影响，我们将Winning Argument数据集按广泛的讨论主题进行组织，并分析不同主题下的性能。我们公开发布了这个经过主题标注的数据集版本，以便未来的研究。总体而言，我们的方法证明了结构化的、策略感知的提示在增强论辩质量评估的可解释性和鲁棒性方面的价值。


<details>
  <summary>Details</summary>
Motivation: 检测和理解论辩文本中的说服力对于分析和改进人类交流具有重要意义。尽管已有关于论辩质量评估的研究，但如何通过识别特定的说服策略来增强预测模型的准确性和可解释性仍是一个挑战。现有方法往往忽视了文本中蕴含的具体说服策略及其对整体说服力的影响。

Method: 本研究采用了一种基于大语言模型的多策略说服评分方法。具体包括：1）在三个标注的论辩数据集（Winning Arguments、Anthropic/Persuasion和Persuasion for Good）上进行实验；2）定义六种说服策略（如声誉攻击、分心、操纵性措辞等）；3）设计结构化的提示方法，指导大语言模型针对这些策略进行推理和评分；4）将Winning Argument数据集按讨论主题进行分类，分析策略在不同主题下的表现。

Result: 实验结果表明：1）基于策略引导的推理方法能够显著提高说服力的预测性能；2）在不同主题的论辩中，说服策略的分布和效果存在差异；3）该方法相比传统方法在论辩质量评估任务中表现出更好的性能；4）研究团队公开发布了经过主题标注的Winning Argument数据集版本，为后续研究提供支持。

Conclusion: 本研究证明了结构化的、策略感知的提示方法在论辩质量评估中的价值。通过显式建模特定的说服策略，不仅提高了预测的准确性，还增强了模型的可解释性和鲁棒性。同时，发布的数据集和主题分类为进一步研究不同领域的说服机制提供了基础。

Abstract: Detecting persuasion in argumentative text is a challenging task with important implications for understanding human communication. This work investigates the role of persuasion strategies - such as Attack on reputation, Distraction, and Manipulative wording - in determining the persuasiveness of a text. We conduct experiments on three annotated argument datasets: Winning Arguments (built from the Change My View subreddit), Anthropic/Persuasion, and Persuasion for Good. Our approach leverages large language models (LLMs) with a Multi-Strategy Persuasion Scoring approach that guides reasoning over six persuasion strategies. Results show that strategy-guided reasoning improves the prediction of persuasiveness. To better understand the influence of content, we organize the Winning Argument dataset into broad discussion topics and analyze performance across them. We publicly release this topic-annotated version of the dataset to facilitate future research. Overall, our methodology demonstrates the value of structured, strategy-aware prompting for enhancing interpretability and robustness in argument quality assessment.

</details>


### [103] [MatchTIR: Fine-Grained Supervision for Tool-Integrated Reasoning via Bipartite Matching](https://arxiv.org/abs/2601.10712)
*Changle Qu,Sunhao Dai,Hengyi Cai,Jun Xu,Shuaiqiang Wang,Dawei Yin*

Main category: cs.CL

Score: 5/5 | Tags: LLM, Reinforcement Learning, Tool-Integrated Reasoning, Credit Assignment, Multi-turn Tasks, Fine-grained Supervision

Recommendation: 强烈推荐这篇论文，因为它针对工具集成推理中的关键问题（信用分配）提出了创新性的解决方案，实验结果显著，方法设计合理且具有实用性。该研究不仅在理论上有所贡献，在实际应用中也展示了显著优势，特别是其小模型超越大模型的效果极具应用价值。

TL;DR: 工具集成推理(TIR)使大型语言模型(LLMs)能够通过交织推理步骤与外部工具交互来应对复杂任务。然而，现有的强化学习方法通常依赖于结果级或轨迹级奖励，为轨迹内的所有步骤分配统一的优势。这种粗粒度的信用分配无法区分有效的工具调用与冗余或错误的调用，特别是在长期多轮次场景中。为了解决这个问题，我们提出了MatchTIR框架，通过基于二分图匹配的轮次级奖励分配和双级优势估计来引入细粒度监督。具体而言，我们将信用分配表述为预测轨迹与真实轨迹之间的二分图匹配问题，利用两种分配策略来获得密集的轮次级奖励。此外，为了平衡局部步骤精度与全局任务成功，我们引入了双级优势估计方案，该方案集成了轮次级和轨迹级信号，为各个交互轮次分配不同的优势值。在三个基准测试上的广泛实验证明了MatchTIR的优越性。值得注意的是，我们的40亿参数模型超越了大多数80亿参数的竞争对手，特别是在长期和多轮次任务中。


<details>
  <summary>Details</summary>
Motivation: 当前的工具集成推理方法在强化学习中主要依赖粗粒度的奖励分配机制（结果级或轨迹级），无法有效区分工具调用中的有效步骤与无效步骤，导致在复杂多轮次任务中学习效率低下和性能不佳。这种粗粒度信用分配限制了模型在长期任务中的精确学习和优化能力。

Method: MatchTIR通过两个核心创新来解决信用分配问题：1）基于二分图匹配的轮次级奖励分配 - 将信用分配形式化为预测轨迹与真实轨迹之间的二分图匹配问题，采用两种策略（最小值匹配和最大奖励匹配）为每个轮次提供细粒度的奖励信号；2）双级优势估计方案 - 结合轮次级奖励和轨迹级奖励，通过加权组合生成细粒度的优势信号，实现对每个交互轮次的精确评估。

Result: 在三个基准测试上进行的实验表明，MatchTIR显著优于现有方法。特别值得注意的是，使用仅有40亿参数的模型在多个任务上超越了大多数80亿参数的竞争对手，在长期多轮次任务中表现尤为突出，证明了该方法在提升模型效率和性能方面的有效性。

Conclusion: MatchTIR通过引入细粒度的轮次级奖励分配和双级优势估计机制，有效解决了工具集成推理中的信用分配问题。该方法显著提升了模型在复杂多轮次任务中的表现，即使使用较小规模的模型也能取得超越更大模型的效果，为工具增强型语言模型的训练提供了新的有效范式。

Abstract: Tool-Integrated Reasoning (TIR) empowers large language models (LLMs) to tackle complex tasks by interleaving reasoning steps with external tool interactions. However, existing reinforcement learning methods typically rely on outcome- or trajectory-level rewards, assigning uniform advantages to all steps within a trajectory. This coarse-grained credit assignment fails to distinguish effective tool calls from redundant or erroneous ones, particularly in long-horizon multi-turn scenarios. To address this, we propose MatchTIR, a framework that introduces fine-grained supervision via bipartite matching-based turn-level reward assignment and dual-level advantage estimation. Specifically, we formulate credit assignment as a bipartite matching problem between predicted and ground-truth traces, utilizing two assignment strategies to derive dense turn-level rewards. Furthermore, to balance local step precision with global task success, we introduce a dual-level advantage estimation scheme that integrates turn-level and trajectory-level signals, assigning distinct advantage values to individual interaction turns. Extensive experiments on three benchmarks demonstrate the superiority of MatchTIR. Notably, our 4B model surpasses the majority of 8B competitors, particularly in long-horizon and multi-turn tasks. Our codes are available at https://github.com/quchangle1/MatchTIR.

</details>
